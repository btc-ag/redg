{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"RedG User Documentation \u00b6 This is the user documentation for \"RedG\" (Ridiculously easy data Generation), a framework that simplifies and revolutionizes test data generation. If you are looking for the Javadoc, see here . Overview \u00b6 Take a look at our landing page for a quick overview. Quick start \u00b6 See here for a quick guide on how to setup RedG and integrate it into a Maven project. See here for other ways of integration RedG into your workflow. Read up on how to specify your test data with RedG.","title":"RedG User Documentation"},{"location":"#redg-user-documentation","text":"This is the user documentation for \"RedG\" (Ridiculously easy data Generation), a framework that simplifies and revolutionizes test data generation. If you are looking for the Javadoc, see here .","title":"RedG User Documentation"},{"location":"#overview","text":"Take a look at our landing page for a quick overview.","title":"Overview"},{"location":"#quick-start","text":"See here for a quick guide on how to setup RedG and integrate it into a Maven project. See here for other ways of integration RedG into your workflow. Read up on how to specify your test data with RedG.","title":"Quick start"},{"location":"compatibility/","text":"Compatibility \u00b6 RedG is able to work with the most common database systems. All you need is a JDBC driver. The Code Generator internally uses SchemaCrawler which supports a wide range of database systems . You'll probably need an extra SchemaCrawler plugin, so consult the table below or see Maven Central for a full list. DBMS Necessary extra dependency Example project H2 Dependency included in RedG redg-examples/redg-example-h2 Oracle us.fatehi:schemacrawler-oracle:15.01.06 redg-examples/redg-example-oracle IBM DB2 us.fatehi:schemacrawler-db2:15.01.06 No example, support untested MS SQL Server\u00b9 us.fatehi:schemacrawler-sqlserver:15.01.06 No example, support untested MySQL\u00b2 us.fatehi:schemacrawler-mysql:15.01.06 redg-examples/redg-example-mysql MariaDB\u00b2 us.fatehi:schemacrawler-mariadb:15.01.06 No example, untested, probably like MySQL PostgreSQL us.fatehi:schemacrawler-postgresql:15.01.06 redg-examples/redg-example-postgres Sybase IQ us.fatehi:schemacrawler-sybaseiq:15.01.06 No example, support untested \u00b9 You need to turn QUOTED_IDENTIFIER on or change the character to escape identifiers from double quotes to backticks by customizing the JavaSqlStringEscapeMap . \u00b2 You need to either enable ANSI mode for the database or the connection or change the character to escape identifiers from double quotes to backticks by customizing the JavaSqlStringEscapeMap . After the code is generated, it can be used to insert data into basically every DBMS with proper SQL support. When you insert the data directly with JDBC, the driver needs proper support for setObject , when generating SQL statements you might have to implement your own InsertValuesFormatter , so RedG uses the correct functions for e.g. string to date conversion. If you run into issues with a certain DBMS or just want to tell us that it works, feel free to open an issue or contact us.","title":"Compatibility"},{"location":"compatibility/#compatibility","text":"RedG is able to work with the most common database systems. All you need is a JDBC driver. The Code Generator internally uses SchemaCrawler which supports a wide range of database systems . You'll probably need an extra SchemaCrawler plugin, so consult the table below or see Maven Central for a full list. DBMS Necessary extra dependency Example project H2 Dependency included in RedG redg-examples/redg-example-h2 Oracle us.fatehi:schemacrawler-oracle:15.01.06 redg-examples/redg-example-oracle IBM DB2 us.fatehi:schemacrawler-db2:15.01.06 No example, support untested MS SQL Server\u00b9 us.fatehi:schemacrawler-sqlserver:15.01.06 No example, support untested MySQL\u00b2 us.fatehi:schemacrawler-mysql:15.01.06 redg-examples/redg-example-mysql MariaDB\u00b2 us.fatehi:schemacrawler-mariadb:15.01.06 No example, untested, probably like MySQL PostgreSQL us.fatehi:schemacrawler-postgresql:15.01.06 redg-examples/redg-example-postgres Sybase IQ us.fatehi:schemacrawler-sybaseiq:15.01.06 No example, support untested \u00b9 You need to turn QUOTED_IDENTIFIER on or change the character to escape identifiers from double quotes to backticks by customizing the JavaSqlStringEscapeMap . \u00b2 You need to either enable ANSI mode for the database or the connection or change the character to escape identifiers from double quotes to backticks by customizing the JavaSqlStringEscapeMap . After the code is generated, it can be used to insert data into basically every DBMS with proper SQL support. When you insert the data directly with JDBC, the driver needs proper support for setObject , when generating SQL statements you might have to implement your own InsertValuesFormatter , so RedG uses the correct functions for e.g. string to date conversion. If you run into issues with a certain DBMS or just want to tell us that it works, feel free to open an issue or contact us.","title":"Compatibility"},{"location":"getting_started/","text":"Getting started \u00b6 This chapter will guide you through your first project with RedG. You'll use RedG via the RedG Maven Plugin and integrate it into a unit test. Installation and configuration \u00b6 If your project can process Maven artifacts, the installation is quite straightforward. RedG is available on Maven Central. The newest stable version is 2.0 See here for an overview of all RedG Maven artifacts and the newest versions. Maven \u00b6 Add the dependency for the redg-runtime . If you want to use the visualization feature to debug your application, include jackson-core and jackson-databind . Include junit for the unit tests. <dependencies> <dependency> <groupId> com.btc-ag.redg </groupId> <artifactId> redg-runtime </artifactId> <version> 2.0 </version> <scope> test </scope> </dependency> <!-- optional, for visualization only --> <dependency> <groupId> com.fasterxml.jackson.core </groupId> <artifactId> jackson-core </artifactId> <version> 2.9.7 </version> <scope> test </scope> </dependency> <dependency> <groupId> com.fasterxml.jackson.core </groupId> <artifactId> jackson-databind </artifactId> <version> 2.9.7 </version> <scope> test </scope> </dependency> <!-- for the unit tests --> <dependency> <groupId> junit </groupId> <artifactId> junit </artifactId> <version> 4.11 </version> <scope> test </scope> </dependency> </dependencies> Now include the RedG Maven Plugin ( redg-maven-plugin ) and configure it. You might also need a JDBC driver if you want the schema analysis to run against a database other than H2. This driver needs to be added as a plugin dependency , not as a project dependency. <plugin> <groupId> com.btc-ag.redg </groupId> <artifactId> redg-maven-plugin </artifactId> <version> 2.0 </version> <executions> <execution> <id> redg-generate </id> <phase> generate-test-sources </phase> <!-- This plugin generates sources for the test code --> <goals> <goal> redg </goal> </goals> <configuration> <!-- Provide database connection information. We'll just use a H2 in-memory database here --> <jdbcDriver> org.h2.Driver </jdbcDriver> <connectionString> jdbc:h2:mem:redg </connectionString> <username> sa </username> <password> sa </password> <!-- Alternative Oracle configuration: <jdbcDriver>oracle.jdbc.OracleDriver</jdbcDriver> <connectionString>jdbc:oracle:thin:@localhost:1521:XE</connectionString> <username>system</username> <password>******</password> --> <enableVisualizationSupport> true </enableVisualizationSupport> <!-- if true, needs jackson dependencies --> <sqlScripts> <!-- the SQL scripts to run before schema analysis --> <param> src/test/resources/create-schema.sql </param> </sqlScripts> <customTypeMappings> src/test/resources/mappings.json </customTypeMappings> <!-- type mappings. Will be explained later --> <schemaRegex> REDG </schemaRegex> </configuration> </execution> </executions> <dependencies> <!-- JDBC driver and SchemaCrawler extension, only if not using H2. Entry depends on DBMS --> <!-- Example for Oracle DB: <dependency> <groupId>com.oracle</groupId> <artifactId>ojdbc6</artifactId> <version>11.2.0.3</version> </dependency> <dependency> <groupId>us.fatehi</groupId> <artifactId>schemacrawler-oracle</artifactId> <version>15.01.06</version> </dependency> --> </dependencies> </plugin> This is a minimal configuration for the Maven plugin. RedG will use an in-memory H2 database named redg . Before schema analysis the create-schema.sql script will be executed. This script will create the complete database schema. The plugin will analyze all tables within the REDG schema and generate code for these. The generated source code will have visualization support, so you can easily debug and visualize your test data. To show how the generated code can be customized, a custom type mapping is provided via a JSON file called mappings.json . For a detailed explanation of all parameters head over to here . Continue with the preparation after you're done here. Gradle \u00b6 Currently there is no Gradle plugin to generate the RedG entity code. See here for other ways to integrate the RedG code generator in your project. The RedG runtime can be included as a dependency. dependencies { testCompile group: 'com.btc-ag.redg' , name: 'redg-runtime' , version '2.0' // optional, only for visualization support testCompile group: 'com.fasterxml.jackson.core' , name: 'jackson-core' , version: '2.9.7' testCompile group: 'com.fasterxml.jackson.core' , name: 'jackson-databind' , version: '2.9.7' // testing framework testCompile group: 'junit' , name: 'junit' , version: '4.11' } Preparation \u00b6 With RedG installed and set up, you can now prepare everything for the first code generation. If you followed the steps above, you'll need two more files before RedG can generate code for your database schema: src/test/resources/create-schema.sql and src/test/resources/mappings.json . SQL Schema Script \u00b6 In order to generate the code for the schema, RedG needs a live database running that schema. As this example uses a H2 in-memory database, all the tables have to be created first. Create the file src/test/resources/create-schema.sql and fill it with your DDL statements. If you don't yet have a database schema or just want to tets RedG, feel free to use this little demo schema: CREATE SCHEMA REDG ; CREATE TABLE REDG . DEMO_BANK_ACCOUNT ( BIC VARCHAR2 ( 11 CHAR ) NOT NULL , IBAN VARCHAR2 ( 22 CHAR ) NOT NULL , CONSTRAINT pk_DEMO_BANK_ACCOUNT PRIMARY KEY ( BIC , IBAN ) ); CREATE TABLE REDG . DEMO_COMPANY ( COUNTRY_CODE VARCHAR2 ( 2 CHAR ) NOT NULL , NAME VARCHAR2 ( 30 CHAR ) NOT NULL , REGISTRATION_DATE TIMESTAMP , ACC_BIC VARCHAR2 ( 11 CHAR ) NOT NULL , ACC_IBAN VARCHAR2 ( 22 CHAR ) NOT NULL , CONSTRAINT PK_DEMO_COMPANY PRIMARY KEY ( COUNTRY_CODE , NAME ), CONSTRAINT FK_DEMO_COMPANY_BANK_ACC FOREIGN KEY ( ACC_BIC , ACC_IBAN ) REFERENCES DEMO_BANK_ACCOUNT ( BIC , IBAN ) ); CREATE TABLE REDG . DEMO_USER ( ID NUMBER ( 19 ) NOT NULL , USERNAME VARCHAR2 ( 30 CHAR ) NOT NULL , FIRST_NAME VARCHAR2 ( 50 CHAR ), LAST_NAME VARCHAR2 ( 50 CHAR ), WORKS_AT_CC VARCHAR2 ( 2 CHAR ), WORKS_AT_NAME VARCHAR2 ( 30 CHAR ), ACC_BIC VARCHAR2 ( 11 CHAR ) NOT NULL , ACC_IBAN VARCHAR2 ( 22 CHAR ) NOT NULL , AGREED_TO_NEWSLETTER NUMBER ( 1 ), CONSTRAINT pk_DEMO_USER PRIMARY KEY ( ID ), CONSTRAINT fk_DEMO_USER_COMPANY FOREIGN KEY ( WORKS_AT_CC , WORKS_AT_NAME ) REFERENCES DEMO_COMPANY ( COUNTRY_CODE , NAME ), CONSTRAINT fk_DEMO_USER_BANK_ACC FOREIGN KEY ( ACC_BIC , ACC_IBAN ) REFERENCES DEMO_BANK_ACCOUNT ( BIC , IBAN ) ); This SQL code will create a schema that looks like this: The demo schema Type Mappings \u00b6 When analysing a database schema, RedG always tries to find an appropriate Java data type for a column. There are three cases, where this might not be enough: You want a different Java data type that still represents the same database data type (eg. long instead of BigDecimal for NUMBER(10) ) RedG cannot understand the semantic meaning of a column data type (eg. NUMBER(1) or CHAR(1) for boolean ) You want to plug in a custom, maybe even far more complex, data type and use it instead of the default types If this happens, you can create a custom type mapping. When using the Maven plugin, you can simply specify that type mapping in a JSON file. For the demo schema from above you can use the following type mapping and save it in the file src/test/resources/mappings.json : { \"REDG.DEMO_USER\" : { \"ID\" : \"Long\" , \"AGREED_TO_NEWSLETTER\" : \"Boolean\" }, \"REDG.DEMO_COMPANY\" : { \"ID\" : \"Long\" , \"REGISTRATION_DATE\" : \"java.time.LocalDateTime\" } } In this example, the DEMO_USER table gets its ID mapped as a Long (always use wrapper classes, not primitive types) and AGREED_TO_NEWSLETTER as a Boolean . The DEMO_COMPANY gets the same mapping for the ID and gets the REGISTRATION_DATE as a LocalDateTime . For each class not in java.lang you have to provide the fully qualified class name. If your JDBC driver is not able to perform the transformations you want ( Boolean to NUMBER(1) or LocalDateTime to TIMESTAMP ), you have to provide a custom PreparedStatementParameterSetter during test runtime. If you want to generate SQL statements, you might need a custom SQLValuesFormatter during test runtime. Code generation \u00b6 By now everything is ready for the first round of code generation. If you are using Maven, either run your whole test-suite with mvn test or just RedG with mvn redg:redg@redg-generate . If you are using Gradle, run your custom solution or wait until the release of the Gradle plugin. If no error occured, you should find the generated sources in target/generated-test-sources/redg . The generated code Test Data Specification \u00b6 Now that RedG has generated the entity classes, you can create a RedG instance. A good approach is to create a factory that will create RedG instances, so you don't have to configure the RedG instance every time you need one. An example for some test data: public class MyRedGFactory { public RedG createRedG () { RedG redG = new RedG (); redG . setDefaultValueStrategy ( createDefaultValueStrategy ()); return redG ; } private DefaultValueStrategy createDefaultValueStrategy () { DefaultValueStrategyBuilder builder = new DefaultValueStrategyBuilder (); builder . whenColumnNameMatches ( \"ID\" ) . thenUseProvider ( new IncrementingNumberProvider ()); builder . whenTableNameMatches ( \".*CARD\" ). andColumnNameMatches ( \"TYPE\" ) . thenUse ( \"MASTERCARD\" ); builder . when ( columnModel -> columnModel . getDbFullTableName (). equals ( \"CCM.CREDITCARD.UUID\" )) . thenCompute (( columnModel , expectedType ) -> UUID . randomUUID (). toString ()); // ... return builder . build (); } } Now you can model your test data. You might end up inlining the test data into your unit tests if it is not too complex. To make RedG insert the modeled data into the database, call AbstractRedG.insertDataIntoDatabase(...) . In most cases this dead simple approach is all you need. Example: import ... ; public class DemoTest { @Test public void testStuff () throws Exception { // instantiate RedG RedG redG = new MyRedGFactory (). createRedG (); // create some test data GDemoBankAccount companyBankAccount = redG . addDemoBankAccount () . iban ( \"DE13109817441665870952\" ); GDemoCompany smallCompany = redG . addDemoCompany ( companyBankAccount ) . countryCode ( \"DE\" ) . name ( \"Spielwarenfachgesch\u00e4ft M\u00fcller\" ); redG . addDemoUser ( redG . dummyDemoBankAccount ) . username ( \"Diana_Dummy\" ) . company ( smallCompany ); // insert the data into the database using a javax.sql.DataSource new DemoTestData (). getDataSet (). insertDataIntoDatabase ( dataSource ); // perform your actual test against the database... ... } } Debugging with the visualizer \u00b6 If your generated RedG entity classes have the visualization support enabled, debugging RedG is extremely simple and comfortable. Add a breakpoint wherever you want to inspect the current RedG dataset and let the code run until there. Once it reached the breakpoint, evaluate the getVisualizationJson() method on your RedG main object. This method will return a big JSON string. Copy it into your clipboard or export it into a file and paste/drag it into the RedG Visualizer .","title":"Getting started"},{"location":"getting_started/#getting-started","text":"This chapter will guide you through your first project with RedG. You'll use RedG via the RedG Maven Plugin and integrate it into a unit test.","title":"Getting started"},{"location":"getting_started/#installation-and-configuration","text":"If your project can process Maven artifacts, the installation is quite straightforward. RedG is available on Maven Central. The newest stable version is 2.0 See here for an overview of all RedG Maven artifacts and the newest versions.","title":"Installation and configuration"},{"location":"getting_started/#maven","text":"Add the dependency for the redg-runtime . If you want to use the visualization feature to debug your application, include jackson-core and jackson-databind . Include junit for the unit tests. <dependencies> <dependency> <groupId> com.btc-ag.redg </groupId> <artifactId> redg-runtime </artifactId> <version> 2.0 </version> <scope> test </scope> </dependency> <!-- optional, for visualization only --> <dependency> <groupId> com.fasterxml.jackson.core </groupId> <artifactId> jackson-core </artifactId> <version> 2.9.7 </version> <scope> test </scope> </dependency> <dependency> <groupId> com.fasterxml.jackson.core </groupId> <artifactId> jackson-databind </artifactId> <version> 2.9.7 </version> <scope> test </scope> </dependency> <!-- for the unit tests --> <dependency> <groupId> junit </groupId> <artifactId> junit </artifactId> <version> 4.11 </version> <scope> test </scope> </dependency> </dependencies> Now include the RedG Maven Plugin ( redg-maven-plugin ) and configure it. You might also need a JDBC driver if you want the schema analysis to run against a database other than H2. This driver needs to be added as a plugin dependency , not as a project dependency. <plugin> <groupId> com.btc-ag.redg </groupId> <artifactId> redg-maven-plugin </artifactId> <version> 2.0 </version> <executions> <execution> <id> redg-generate </id> <phase> generate-test-sources </phase> <!-- This plugin generates sources for the test code --> <goals> <goal> redg </goal> </goals> <configuration> <!-- Provide database connection information. We'll just use a H2 in-memory database here --> <jdbcDriver> org.h2.Driver </jdbcDriver> <connectionString> jdbc:h2:mem:redg </connectionString> <username> sa </username> <password> sa </password> <!-- Alternative Oracle configuration: <jdbcDriver>oracle.jdbc.OracleDriver</jdbcDriver> <connectionString>jdbc:oracle:thin:@localhost:1521:XE</connectionString> <username>system</username> <password>******</password> --> <enableVisualizationSupport> true </enableVisualizationSupport> <!-- if true, needs jackson dependencies --> <sqlScripts> <!-- the SQL scripts to run before schema analysis --> <param> src/test/resources/create-schema.sql </param> </sqlScripts> <customTypeMappings> src/test/resources/mappings.json </customTypeMappings> <!-- type mappings. Will be explained later --> <schemaRegex> REDG </schemaRegex> </configuration> </execution> </executions> <dependencies> <!-- JDBC driver and SchemaCrawler extension, only if not using H2. Entry depends on DBMS --> <!-- Example for Oracle DB: <dependency> <groupId>com.oracle</groupId> <artifactId>ojdbc6</artifactId> <version>11.2.0.3</version> </dependency> <dependency> <groupId>us.fatehi</groupId> <artifactId>schemacrawler-oracle</artifactId> <version>15.01.06</version> </dependency> --> </dependencies> </plugin> This is a minimal configuration for the Maven plugin. RedG will use an in-memory H2 database named redg . Before schema analysis the create-schema.sql script will be executed. This script will create the complete database schema. The plugin will analyze all tables within the REDG schema and generate code for these. The generated source code will have visualization support, so you can easily debug and visualize your test data. To show how the generated code can be customized, a custom type mapping is provided via a JSON file called mappings.json . For a detailed explanation of all parameters head over to here . Continue with the preparation after you're done here.","title":"Maven"},{"location":"getting_started/#gradle","text":"Currently there is no Gradle plugin to generate the RedG entity code. See here for other ways to integrate the RedG code generator in your project. The RedG runtime can be included as a dependency. dependencies { testCompile group: 'com.btc-ag.redg' , name: 'redg-runtime' , version '2.0' // optional, only for visualization support testCompile group: 'com.fasterxml.jackson.core' , name: 'jackson-core' , version: '2.9.7' testCompile group: 'com.fasterxml.jackson.core' , name: 'jackson-databind' , version: '2.9.7' // testing framework testCompile group: 'junit' , name: 'junit' , version: '4.11' }","title":"Gradle"},{"location":"getting_started/#preparation","text":"With RedG installed and set up, you can now prepare everything for the first code generation. If you followed the steps above, you'll need two more files before RedG can generate code for your database schema: src/test/resources/create-schema.sql and src/test/resources/mappings.json .","title":"Preparation"},{"location":"getting_started/#sql-schema-script","text":"In order to generate the code for the schema, RedG needs a live database running that schema. As this example uses a H2 in-memory database, all the tables have to be created first. Create the file src/test/resources/create-schema.sql and fill it with your DDL statements. If you don't yet have a database schema or just want to tets RedG, feel free to use this little demo schema: CREATE SCHEMA REDG ; CREATE TABLE REDG . DEMO_BANK_ACCOUNT ( BIC VARCHAR2 ( 11 CHAR ) NOT NULL , IBAN VARCHAR2 ( 22 CHAR ) NOT NULL , CONSTRAINT pk_DEMO_BANK_ACCOUNT PRIMARY KEY ( BIC , IBAN ) ); CREATE TABLE REDG . DEMO_COMPANY ( COUNTRY_CODE VARCHAR2 ( 2 CHAR ) NOT NULL , NAME VARCHAR2 ( 30 CHAR ) NOT NULL , REGISTRATION_DATE TIMESTAMP , ACC_BIC VARCHAR2 ( 11 CHAR ) NOT NULL , ACC_IBAN VARCHAR2 ( 22 CHAR ) NOT NULL , CONSTRAINT PK_DEMO_COMPANY PRIMARY KEY ( COUNTRY_CODE , NAME ), CONSTRAINT FK_DEMO_COMPANY_BANK_ACC FOREIGN KEY ( ACC_BIC , ACC_IBAN ) REFERENCES DEMO_BANK_ACCOUNT ( BIC , IBAN ) ); CREATE TABLE REDG . DEMO_USER ( ID NUMBER ( 19 ) NOT NULL , USERNAME VARCHAR2 ( 30 CHAR ) NOT NULL , FIRST_NAME VARCHAR2 ( 50 CHAR ), LAST_NAME VARCHAR2 ( 50 CHAR ), WORKS_AT_CC VARCHAR2 ( 2 CHAR ), WORKS_AT_NAME VARCHAR2 ( 30 CHAR ), ACC_BIC VARCHAR2 ( 11 CHAR ) NOT NULL , ACC_IBAN VARCHAR2 ( 22 CHAR ) NOT NULL , AGREED_TO_NEWSLETTER NUMBER ( 1 ), CONSTRAINT pk_DEMO_USER PRIMARY KEY ( ID ), CONSTRAINT fk_DEMO_USER_COMPANY FOREIGN KEY ( WORKS_AT_CC , WORKS_AT_NAME ) REFERENCES DEMO_COMPANY ( COUNTRY_CODE , NAME ), CONSTRAINT fk_DEMO_USER_BANK_ACC FOREIGN KEY ( ACC_BIC , ACC_IBAN ) REFERENCES DEMO_BANK_ACCOUNT ( BIC , IBAN ) ); This SQL code will create a schema that looks like this: The demo schema","title":"SQL Schema Script"},{"location":"getting_started/#type-mappings","text":"When analysing a database schema, RedG always tries to find an appropriate Java data type for a column. There are three cases, where this might not be enough: You want a different Java data type that still represents the same database data type (eg. long instead of BigDecimal for NUMBER(10) ) RedG cannot understand the semantic meaning of a column data type (eg. NUMBER(1) or CHAR(1) for boolean ) You want to plug in a custom, maybe even far more complex, data type and use it instead of the default types If this happens, you can create a custom type mapping. When using the Maven plugin, you can simply specify that type mapping in a JSON file. For the demo schema from above you can use the following type mapping and save it in the file src/test/resources/mappings.json : { \"REDG.DEMO_USER\" : { \"ID\" : \"Long\" , \"AGREED_TO_NEWSLETTER\" : \"Boolean\" }, \"REDG.DEMO_COMPANY\" : { \"ID\" : \"Long\" , \"REGISTRATION_DATE\" : \"java.time.LocalDateTime\" } } In this example, the DEMO_USER table gets its ID mapped as a Long (always use wrapper classes, not primitive types) and AGREED_TO_NEWSLETTER as a Boolean . The DEMO_COMPANY gets the same mapping for the ID and gets the REGISTRATION_DATE as a LocalDateTime . For each class not in java.lang you have to provide the fully qualified class name. If your JDBC driver is not able to perform the transformations you want ( Boolean to NUMBER(1) or LocalDateTime to TIMESTAMP ), you have to provide a custom PreparedStatementParameterSetter during test runtime. If you want to generate SQL statements, you might need a custom SQLValuesFormatter during test runtime.","title":"Type Mappings"},{"location":"getting_started/#code-generation","text":"By now everything is ready for the first round of code generation. If you are using Maven, either run your whole test-suite with mvn test or just RedG with mvn redg:redg@redg-generate . If you are using Gradle, run your custom solution or wait until the release of the Gradle plugin. If no error occured, you should find the generated sources in target/generated-test-sources/redg . The generated code","title":"Code generation"},{"location":"getting_started/#test-data-specification","text":"Now that RedG has generated the entity classes, you can create a RedG instance. A good approach is to create a factory that will create RedG instances, so you don't have to configure the RedG instance every time you need one. An example for some test data: public class MyRedGFactory { public RedG createRedG () { RedG redG = new RedG (); redG . setDefaultValueStrategy ( createDefaultValueStrategy ()); return redG ; } private DefaultValueStrategy createDefaultValueStrategy () { DefaultValueStrategyBuilder builder = new DefaultValueStrategyBuilder (); builder . whenColumnNameMatches ( \"ID\" ) . thenUseProvider ( new IncrementingNumberProvider ()); builder . whenTableNameMatches ( \".*CARD\" ). andColumnNameMatches ( \"TYPE\" ) . thenUse ( \"MASTERCARD\" ); builder . when ( columnModel -> columnModel . getDbFullTableName (). equals ( \"CCM.CREDITCARD.UUID\" )) . thenCompute (( columnModel , expectedType ) -> UUID . randomUUID (). toString ()); // ... return builder . build (); } } Now you can model your test data. You might end up inlining the test data into your unit tests if it is not too complex. To make RedG insert the modeled data into the database, call AbstractRedG.insertDataIntoDatabase(...) . In most cases this dead simple approach is all you need. Example: import ... ; public class DemoTest { @Test public void testStuff () throws Exception { // instantiate RedG RedG redG = new MyRedGFactory (). createRedG (); // create some test data GDemoBankAccount companyBankAccount = redG . addDemoBankAccount () . iban ( \"DE13109817441665870952\" ); GDemoCompany smallCompany = redG . addDemoCompany ( companyBankAccount ) . countryCode ( \"DE\" ) . name ( \"Spielwarenfachgesch\u00e4ft M\u00fcller\" ); redG . addDemoUser ( redG . dummyDemoBankAccount ) . username ( \"Diana_Dummy\" ) . company ( smallCompany ); // insert the data into the database using a javax.sql.DataSource new DemoTestData (). getDataSet (). insertDataIntoDatabase ( dataSource ); // perform your actual test against the database... ... } }","title":"Test Data Specification"},{"location":"getting_started/#debugging-with-the-visualizer","text":"If your generated RedG entity classes have the visualization support enabled, debugging RedG is extremely simple and comfortable. Add a breakpoint wherever you want to inspect the current RedG dataset and let the code run until there. Once it reached the breakpoint, evaluate the getVisualizationJson() method on your RedG main object. This method will return a big JSON string. Copy it into your clipboard or export it into a file and paste/drag it into the RedG Visualizer .","title":"Debugging with the visualizer"},{"location":"specifying_test_data/","text":"Specifying test data \u00b6 With RedG you specify all your test data in pure Java code. And \"all your test data\" means \"only the data you really need\". RedG takes care of all the other stuff (like not specified NOT NULL fields, required foreign key relations etc.). General API design \u00b6 The entity classes RedG generates use a fluent interface with getters and setters in \"JQuery style\" (no get / set prefix, calling without parameter gets the value, with parameter sets it). RedG always generates a \"main class\" (or \"manager class\"). This is not an executable class containing a public static void main(String[] args) , but the class you'll use to create and manage your RedG entities (and thus your test data). This class is usually named RedG . Using the RedG main class you can create entities. An entity is a java object that represents one row of data that will be inserted into a database (or already exists in the database ). Usually you can use methods to change fields (\"columns\" in your database) on these entities. Adding an entity \u00b6 To create a new entity and add it to RedG's internal list of objects to insert call one of the add...() methods on a RedG object. Replace ... with the name of the entity you want to add. If the entity has required fields (either NOT NULL foreign keys or columns / foreign keys marked as explicit ) you'll need to pass them to the method. Passing a null value will result in a NullPointerException . Once you have created your entity you can use it's setters to set the values for the necessary fields. Example: RedG redG = new RedG (); // or when customizing many internal things, consider using the RedGBuilder class // RedG redG = new RedGBuilder<RedG>().build(); // either GTeacher mathTeacher = redG . addTeacher () . name ( \"Leonhard Euler\" ) . age ( 310 ); // or just redG . addTeacher () . name ( \"Isaac Newton\" ); // or even GTeacher chemistryTeacher = redG . addTeacher (); chemistryTeacher . name ( \"Niels Bohr\" ) . hasNobelPrice ( true ) When you do not need an entity for further foreign key relations or data manipulation, there is no need to save it in a variable. As you can see in the example, different fields are set for mathTeacher and chemistryTeacher although they are of the same type and have the same columns. Even if age or hasNobelPrice would both be mandatory ( NOT NULL ) this code would still work, as RedG generates default values for all fields that are not specified by the user. Example for entities with NOT NULL foreign key or explicit attributes: // name of school is an explicit attribute for demonstration purposes redG . addSchool ( \"Time-traveling School with famous teachers\" ) . headmaster ( einstein ); // Every class needs a teacher, so it is specified at creation time and may not be null GClass chemistryClass = redG . addClass ( chemistryTeacher ) . name ( \"Chemistry 101\" ) . maxStudentCount ( 45 ) Generating a dummy entity \u00b6 There are many scenarios where you need to test a specific entity but only need some or none of its dependencies. With most other tools you would have to specify each and every dependency (and their dependencies and so on) and you could wind up with far too much code/XML for just one entity. To solve this problem RedG offers a dummy entity generator, that will generate a valid dummy entity for you. This entity will have meaningless values but is still a valid entity that can be referenced wherever you want. To stay in the educational environment with this example, imagine a test case where you need to test the SCHOOL_SUBJECT table ( SchoolSubject entity name, GSchoolSubject entity class name). Every subjects needs a teacher. A teacher is a human with a pay grade, a qualification and a school he graduated from (All of these have to be provided because of constraints on the database). Every subjects needs one required textbook as well. // Without dummy entities and without the previously defined entities GSchool school = redG . addSchool ( \"Wherever Primary School\" ); GHuman somePerson = redG . addHuman (); GTeacher someTeacher = redG . addTeacher ( somePerson , Paygrade . TEACHER , Qualifications . NONE , school ); GTextBook textBook = redG . addTextBook (); GSchoolSubject aqm = redg . addSchoolSubject ( someTeacher , textBook ) . name ( \"Advanced quantum mechanics\" ) . isCoreClass ( true ) . room ( \"1.42\" ); // with RedGs dummy generator GSchoolSubject aqm = redG . addSchoolSubject ( redG . dummyTeacher (), redG . dummyTextBook () ) . name ( \"Advanced quantum mechanics\" ) . isCoreClass ( true ) . room ( \"1.42\" ); Referencing existing entities \u00b6 Depending on your setup you might already have some data in your database before running RedG and need to reference these data for a foreign key relation within RedG. RedG allows you to specify that a certain entity is already present in the database. When inserting you test data RedG will test that the specified entity is really already in the database. To reference an existing entity, use the existing...() methods of the RedG object. You have to pass the full primary key as the arguments to these methods. If a table does not have primary keys, you cannot reference it. Example: GTeacher euklid = redG . existingTeacher ( 4 ); // 4 is value of primary id column // use euklid just like normal for references, just don't try to modify him or read values other the primary keys // trying to modify fields will throw an UnsupportedOperationException euklid . isDead ( false ); redG . addMemorialDay ( euklid ) // works just like expected Self-references / Circular dependencies \u00b6 RedG supports self-references via the RedG#entitySelfReference() method. If you have a schema like create table TREE_ELEMENT ( ID number ( 19 ) not null primary key , VALUE varchar2 ( 50 char ), PARENT_ID number ( 19 ) not null , constraint FK_TREE_ELEMENT_PARENT foreign key ( PARENT_ID ) REFERENCES TREE_ELEMENT ( ID ) ); you can simply create a root element referencing itself as the parent with redg.addTreeElement(redg.entitySelfReference()).value(\"Root\") . Other circular references and dependencies are currently not supported by RedG. If you really do need this, the best way would be to break open the circle in one place in the specified test data and then \"close\" the circle with a manual INSERT after you inserted the test data.","title":"Specifying test data"},{"location":"specifying_test_data/#specifying-test-data","text":"With RedG you specify all your test data in pure Java code. And \"all your test data\" means \"only the data you really need\". RedG takes care of all the other stuff (like not specified NOT NULL fields, required foreign key relations etc.).","title":"Specifying test data"},{"location":"specifying_test_data/#general-api-design","text":"The entity classes RedG generates use a fluent interface with getters and setters in \"JQuery style\" (no get / set prefix, calling without parameter gets the value, with parameter sets it). RedG always generates a \"main class\" (or \"manager class\"). This is not an executable class containing a public static void main(String[] args) , but the class you'll use to create and manage your RedG entities (and thus your test data). This class is usually named RedG . Using the RedG main class you can create entities. An entity is a java object that represents one row of data that will be inserted into a database (or already exists in the database ). Usually you can use methods to change fields (\"columns\" in your database) on these entities.","title":"General API design"},{"location":"specifying_test_data/#adding-an-entity","text":"To create a new entity and add it to RedG's internal list of objects to insert call one of the add...() methods on a RedG object. Replace ... with the name of the entity you want to add. If the entity has required fields (either NOT NULL foreign keys or columns / foreign keys marked as explicit ) you'll need to pass them to the method. Passing a null value will result in a NullPointerException . Once you have created your entity you can use it's setters to set the values for the necessary fields. Example: RedG redG = new RedG (); // or when customizing many internal things, consider using the RedGBuilder class // RedG redG = new RedGBuilder<RedG>().build(); // either GTeacher mathTeacher = redG . addTeacher () . name ( \"Leonhard Euler\" ) . age ( 310 ); // or just redG . addTeacher () . name ( \"Isaac Newton\" ); // or even GTeacher chemistryTeacher = redG . addTeacher (); chemistryTeacher . name ( \"Niels Bohr\" ) . hasNobelPrice ( true ) When you do not need an entity for further foreign key relations or data manipulation, there is no need to save it in a variable. As you can see in the example, different fields are set for mathTeacher and chemistryTeacher although they are of the same type and have the same columns. Even if age or hasNobelPrice would both be mandatory ( NOT NULL ) this code would still work, as RedG generates default values for all fields that are not specified by the user. Example for entities with NOT NULL foreign key or explicit attributes: // name of school is an explicit attribute for demonstration purposes redG . addSchool ( \"Time-traveling School with famous teachers\" ) . headmaster ( einstein ); // Every class needs a teacher, so it is specified at creation time and may not be null GClass chemistryClass = redG . addClass ( chemistryTeacher ) . name ( \"Chemistry 101\" ) . maxStudentCount ( 45 )","title":"Adding an entity"},{"location":"specifying_test_data/#generating-a-dummy-entity","text":"There are many scenarios where you need to test a specific entity but only need some or none of its dependencies. With most other tools you would have to specify each and every dependency (and their dependencies and so on) and you could wind up with far too much code/XML for just one entity. To solve this problem RedG offers a dummy entity generator, that will generate a valid dummy entity for you. This entity will have meaningless values but is still a valid entity that can be referenced wherever you want. To stay in the educational environment with this example, imagine a test case where you need to test the SCHOOL_SUBJECT table ( SchoolSubject entity name, GSchoolSubject entity class name). Every subjects needs a teacher. A teacher is a human with a pay grade, a qualification and a school he graduated from (All of these have to be provided because of constraints on the database). Every subjects needs one required textbook as well. // Without dummy entities and without the previously defined entities GSchool school = redG . addSchool ( \"Wherever Primary School\" ); GHuman somePerson = redG . addHuman (); GTeacher someTeacher = redG . addTeacher ( somePerson , Paygrade . TEACHER , Qualifications . NONE , school ); GTextBook textBook = redG . addTextBook (); GSchoolSubject aqm = redg . addSchoolSubject ( someTeacher , textBook ) . name ( \"Advanced quantum mechanics\" ) . isCoreClass ( true ) . room ( \"1.42\" ); // with RedGs dummy generator GSchoolSubject aqm = redG . addSchoolSubject ( redG . dummyTeacher (), redG . dummyTextBook () ) . name ( \"Advanced quantum mechanics\" ) . isCoreClass ( true ) . room ( \"1.42\" );","title":"Generating a dummy entity"},{"location":"specifying_test_data/#referencing-existing-entities","text":"Depending on your setup you might already have some data in your database before running RedG and need to reference these data for a foreign key relation within RedG. RedG allows you to specify that a certain entity is already present in the database. When inserting you test data RedG will test that the specified entity is really already in the database. To reference an existing entity, use the existing...() methods of the RedG object. You have to pass the full primary key as the arguments to these methods. If a table does not have primary keys, you cannot reference it. Example: GTeacher euklid = redG . existingTeacher ( 4 ); // 4 is value of primary id column // use euklid just like normal for references, just don't try to modify him or read values other the primary keys // trying to modify fields will throw an UnsupportedOperationException euklid . isDead ( false ); redG . addMemorialDay ( euklid ) // works just like expected","title":"Referencing existing entities"},{"location":"specifying_test_data/#self-references-circular-dependencies","text":"RedG supports self-references via the RedG#entitySelfReference() method. If you have a schema like create table TREE_ELEMENT ( ID number ( 19 ) not null primary key , VALUE varchar2 ( 50 char ), PARENT_ID number ( 19 ) not null , constraint FK_TREE_ELEMENT_PARENT foreign key ( PARENT_ID ) REFERENCES TREE_ELEMENT ( ID ) ); you can simply create a root element referencing itself as the parent with redg.addTreeElement(redg.entitySelfReference()).value(\"Root\") . Other circular references and dependencies are currently not supported by RedG. If you really do need this, the best way would be to break open the circle in one place in the specified test data and then \"close\" the circle with a manual INSERT after you inserted the test data.","title":"Self-references / Circular dependencies"},{"location":"about/imprint/","text":"Imprint / Impressum \u00b6 Responsible for the content of this webpage is / Verantwortlich f\u00fcr den Inhalt dieses Internetauftrittes ist die BTC Business Technology Consulting AG Escherweg 5 26121 Oldenburg Deutschland / Germany Fon: +49 441 3612-0 ( Kein Support, No support ) Fax: +49 441 3612-3999 ( Kein Support, No support ) E-Mail: office@btc-ag.com ( Kein Support, No support ) Web: https://www.btc-ag.com/ Vorstand: Dr. J\u00f6rg Ritter, Dirk Thole Vorsitzender des Aufsichtsrates: Michael Heidkamp Eintragung: Handelsregister Amtsgericht Oldenburg HRB 4717 USt-ID: DE211155632 Privacy Policy / Datenschutzerkl\u00e4rung \u00b6 The BTC AG does not collect, process or store personal information about users on this site. Die BTC AG sammelt, verarbeitet oder speichert keine Daten \u00fcber Nutzerverhalten auf dieser Seite.","title":"Imprint / Impressum"},{"location":"about/imprint/#imprint-impressum","text":"Responsible for the content of this webpage is / Verantwortlich f\u00fcr den Inhalt dieses Internetauftrittes ist die BTC Business Technology Consulting AG Escherweg 5 26121 Oldenburg Deutschland / Germany Fon: +49 441 3612-0 ( Kein Support, No support ) Fax: +49 441 3612-3999 ( Kein Support, No support ) E-Mail: office@btc-ag.com ( Kein Support, No support ) Web: https://www.btc-ag.com/ Vorstand: Dr. J\u00f6rg Ritter, Dirk Thole Vorsitzender des Aufsichtsrates: Michael Heidkamp Eintragung: Handelsregister Amtsgericht Oldenburg HRB 4717 USt-ID: DE211155632","title":"Imprint / Impressum"},{"location":"about/imprint/#privacy-policy-datenschutzerklarung","text":"The BTC AG does not collect, process or store personal information about users on this site. Die BTC AG sammelt, verarbeitet oder speichert keine Daten \u00fcber Nutzerverhalten auf dieser Seite.","title":"Privacy Policy / Datenschutzerkl\u00e4rung"},{"location":"about/license/","text":"License \u00b6 This page provides a quick overview of the different open source licenses used by the RedG projects. Note This is only an overview. For detailed information, check out the LICENSE (or LICENSE.txt ) file in the code repositories. RedG library \u00b6 The main RedG library is available under the Apache 2.0 License . RedG visualizer \u00b6 The RedG visualizer tool is available under the Apache 2.0 License . RedG documentation \u00b6 Unless stated otherwise, this whole documentation is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License","title":"License"},{"location":"about/license/#license","text":"This page provides a quick overview of the different open source licenses used by the RedG projects. Note This is only an overview. For detailed information, check out the LICENSE (or LICENSE.txt ) file in the code repositories.","title":"License"},{"location":"about/license/#redg-library","text":"The main RedG library is available under the Apache 2.0 License .","title":"RedG library"},{"location":"about/license/#redg-visualizer","text":"The RedG visualizer tool is available under the Apache 2.0 License .","title":"RedG visualizer"},{"location":"about/license/#redg-documentation","text":"Unless stated otherwise, this whole documentation is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License","title":"RedG documentation"},{"location":"customization/generator/convenience_setters/","text":"Convenience setter methods \u00b6 This feature of RedG allows you to add convenience setters to the generated entity classes. For example an entity with a java.sql.Timestamp field could get an extra setter for better date types (like java.time.LocalDatetime ). All you have to provide is a conversion method that can convert from the convenient data type to the needed type. This conversion method needs to be a public static method taking exactly two parameters: The value for the attribute (as the convenient type) The class ( Class<?> ) of the required type It needs to return an instance of the class that was passed as a second parameter. Using generics, the method signature for a conversion method that transforms a string into some kind of date could be public static < T > T convertToDate ( String s , Class < T > clazz ) . The RedG runtime provides a converter that can convert a ISO-8601 formatted string into basically every Java date type ( java.util.Date, java.sql.Date, Time, Timestamp, LocalTime, LocalDate, LocalDateTime, ZonedDateTime, OffsetDateTime, OffsetTime ). To use it, specify com.btc.redg.runtime.util.DateConverter.convertDate as the fully qualified converter method name. XML file \u00b6 Use the XmlFileConvenienceSetterProvider class to load your XML file. In the XML you can specify multiple convenience setters for each original data type. The example XML specifies that every attribute of the type java.util.Date gets another setter accepting a java.lang.String and converting this string into a date with the com.btc.redg.runtime.util.DateConverter.convertDate method. If you want to restrict the convenience setters to certain tables / columns, you have to provide a custom implementation . <convenienceSetterConfig> <javaType name= \"java.util.Date\" > <convenienceSetter setterJavaTypeName= \"java.lang.String\" fullyQualifiedConverterMethodName= \"com.btc.redg.runtime.util.DateConverter.convertDate\" /> </javaType> </convenienceSetterConfig> Java API \u00b6 Your custom implementation has to implement the ConvenienceSetterProvider interface. You can then decide for each column on every table what convenience setters should be added. If you do not want any convenience setters, return an empty list or fall back to a DefaultConvenienceSetterProvider . Please always use the javaDataTypeName parameter as the required parameter type and not the type according to the column , as your type mapping might have changed the type that the database analysis framework suggested. public interface ConvenienceSetterProvider { List < ConvenienceSetterModel > getConvenienceSetters ( Column column , String javaDataTypeName ); }","title":"Convenience setter methods"},{"location":"customization/generator/convenience_setters/#convenience-setter-methods","text":"This feature of RedG allows you to add convenience setters to the generated entity classes. For example an entity with a java.sql.Timestamp field could get an extra setter for better date types (like java.time.LocalDatetime ). All you have to provide is a conversion method that can convert from the convenient data type to the needed type. This conversion method needs to be a public static method taking exactly two parameters: The value for the attribute (as the convenient type) The class ( Class<?> ) of the required type It needs to return an instance of the class that was passed as a second parameter. Using generics, the method signature for a conversion method that transforms a string into some kind of date could be public static < T > T convertToDate ( String s , Class < T > clazz ) . The RedG runtime provides a converter that can convert a ISO-8601 formatted string into basically every Java date type ( java.util.Date, java.sql.Date, Time, Timestamp, LocalTime, LocalDate, LocalDateTime, ZonedDateTime, OffsetDateTime, OffsetTime ). To use it, specify com.btc.redg.runtime.util.DateConverter.convertDate as the fully qualified converter method name.","title":"Convenience setter methods"},{"location":"customization/generator/convenience_setters/#xml-file","text":"Use the XmlFileConvenienceSetterProvider class to load your XML file. In the XML you can specify multiple convenience setters for each original data type. The example XML specifies that every attribute of the type java.util.Date gets another setter accepting a java.lang.String and converting this string into a date with the com.btc.redg.runtime.util.DateConverter.convertDate method. If you want to restrict the convenience setters to certain tables / columns, you have to provide a custom implementation . <convenienceSetterConfig> <javaType name= \"java.util.Date\" > <convenienceSetter setterJavaTypeName= \"java.lang.String\" fullyQualifiedConverterMethodName= \"com.btc.redg.runtime.util.DateConverter.convertDate\" /> </javaType> </convenienceSetterConfig>","title":"XML file"},{"location":"customization/generator/convenience_setters/#java-api","text":"Your custom implementation has to implement the ConvenienceSetterProvider interface. You can then decide for each column on every table what convenience setters should be added. If you do not want any convenience setters, return an empty list or fall back to a DefaultConvenienceSetterProvider . Please always use the javaDataTypeName parameter as the required parameter type and not the type according to the column , as your type mapping might have changed the type that the database analysis framework suggested. public interface ConvenienceSetterProvider { List < ConvenienceSetterModel > getConvenienceSetters ( Column column , String javaDataTypeName ); }","title":"Java API"},{"location":"customization/generator/explicit_attributes/","text":"Explicit attributes & foreign keys \u00b6 Explicit attributes and explicit foreign keys can be used to \"mark\" certain attributes / foreign keys as required. If you mark a foreign key as explicit it is treated as a NOT NULL foreign key. This allows you to treat foreign keys that are meant to be NOT NULL but are nullable for some reason (legacy schema, cyclic dependencies, whatever) as NOT NULL within RedG and make them required for entity creation. If you mark an attribute as explicit, it gets treated like a NOT NULL foreign key. This means, that a value has to be set for this attribute at entity creation time and no default value will be used for this attribute. Use this feature sparingly, as using it everywhere defeats the purpose of RedGs default value system. JSON file \u00b6 Load your JSON files with the JsonFileExplicitAttributeDecider . The structure of the JSON input can be found below. Regex support All strings in this JSON file will be evaluated as regualr expressions and matched against the table / column / foreign key names. Remember to escape certain characters with a backslash (\"\\\") if you want the literal character to match. { \"TABLENAME\" : { \"attributes\" : [ \"ATTRIBUTE1\" , \"ATTRIBUTE2\" ], \"relations\" : [ [ \"FOREIGN_KEY_1_COLUMN_1\" , \"COLUMN2\" ], [ \"FOREIGN_KEY_2_PART_1\" , \"OTHER_PART2\" ] ] } } Java API \u00b6 If you want to roll your own implementation, simply implement ExplicitAttributeDecider and decide for each column / attribute and foreign key whether it should be explicitly required or not. public interface ExplicitAttributeDecider { boolean isExplicitAttribute ( Column column ); boolean isExplicitForeignKey ( ForeignKey foreignKey ); }","title":"Explicit attributes & foreign keys"},{"location":"customization/generator/explicit_attributes/#explicit-attributes-foreign-keys","text":"Explicit attributes and explicit foreign keys can be used to \"mark\" certain attributes / foreign keys as required. If you mark a foreign key as explicit it is treated as a NOT NULL foreign key. This allows you to treat foreign keys that are meant to be NOT NULL but are nullable for some reason (legacy schema, cyclic dependencies, whatever) as NOT NULL within RedG and make them required for entity creation. If you mark an attribute as explicit, it gets treated like a NOT NULL foreign key. This means, that a value has to be set for this attribute at entity creation time and no default value will be used for this attribute. Use this feature sparingly, as using it everywhere defeats the purpose of RedGs default value system.","title":"Explicit attributes &amp; foreign keys"},{"location":"customization/generator/explicit_attributes/#json-file","text":"Load your JSON files with the JsonFileExplicitAttributeDecider . The structure of the JSON input can be found below. Regex support All strings in this JSON file will be evaluated as regualr expressions and matched against the table / column / foreign key names. Remember to escape certain characters with a backslash (\"\\\") if you want the literal character to match. { \"TABLENAME\" : { \"attributes\" : [ \"ATTRIBUTE1\" , \"ATTRIBUTE2\" ], \"relations\" : [ [ \"FOREIGN_KEY_1_COLUMN_1\" , \"COLUMN2\" ], [ \"FOREIGN_KEY_2_PART_1\" , \"OTHER_PART2\" ] ] } }","title":"JSON file"},{"location":"customization/generator/explicit_attributes/#java-api","text":"If you want to roll your own implementation, simply implement ExplicitAttributeDecider and decide for each column / attribute and foreign key whether it should be explicitly required or not. public interface ExplicitAttributeDecider { boolean isExplicitAttribute ( Column column ); boolean isExplicitForeignKey ( ForeignKey foreignKey ); }","title":"Java API"},{"location":"customization/generator/name_mapping/","text":"Custom name mapping \u00b6 The custom name mapping allows you to change how RedG names the entity classes and their methods. In many cases and when using pretty default SQL names no intervention is needed here. The default naming behaviour of RedG is described below: Type Behaviour Example Tables Split by underscore into words. Make words lowercase with first letter uppercase and join them together, thus creating a uppercase camel-case name. DEMO_USER \u2192 DemoUser Columns Split by underscore into words. Make words lowercase with first letter uppercase and join them together. First word starts lowercase, thus creating a lowercase camel-case name. FIRST_NAME \u2192 firstName Foreign Key Split by underscore into words. Remove \"FK\" and name of own table. Build lowercase camel-case name of remaining words. FK_USER_WORKS_AT_COMPANY \u2192 worksAtCompany Incoming Foreign Key Name of the referencing table + \"sFor\" + Name for foreign key JSON file \u00b6 Use the JsonFileNameProvider when specifying name mappings in a JSON file. The Maven plugin has built-in support for JSON files. Getting names for incoming foreign keys from JSON files is not supported yet and RedG will fall back to the DefaultNameProvider . See below for the syntax of the JSON file: { \"TABLE_NAME\" : { \"name\" : \"TableClassName\" , \"columns\" : { \"COLUMN_1\" : \"myCustomNameCol1\" , \"COLUMN_2\" : \"otherCustomName\" , \"FK_SPECIAL_FOREIGN_KEY\" : \"customFkName\" } } } Java API \u00b6 Custom implementations have to implement the NameProvider interface. If you only want to override behaviour for one type (table, column, foreign key), consider returning null for all methods you do not want to override and use a MultiProviderNameProvider . public interface NameProvider { String getClassNameForTable ( Table table ); String getMethodNameForColumn ( Column column ); String getMethodNameForForeignKey ( ForeignKey foreignKey ); String getMethodNameForIncomingForeignKey ( ForeignKey foreignKey ); }","title":"Name mapping"},{"location":"customization/generator/name_mapping/#custom-name-mapping","text":"The custom name mapping allows you to change how RedG names the entity classes and their methods. In many cases and when using pretty default SQL names no intervention is needed here. The default naming behaviour of RedG is described below: Type Behaviour Example Tables Split by underscore into words. Make words lowercase with first letter uppercase and join them together, thus creating a uppercase camel-case name. DEMO_USER \u2192 DemoUser Columns Split by underscore into words. Make words lowercase with first letter uppercase and join them together. First word starts lowercase, thus creating a lowercase camel-case name. FIRST_NAME \u2192 firstName Foreign Key Split by underscore into words. Remove \"FK\" and name of own table. Build lowercase camel-case name of remaining words. FK_USER_WORKS_AT_COMPANY \u2192 worksAtCompany Incoming Foreign Key Name of the referencing table + \"sFor\" + Name for foreign key","title":"Custom name mapping"},{"location":"customization/generator/name_mapping/#json-file","text":"Use the JsonFileNameProvider when specifying name mappings in a JSON file. The Maven plugin has built-in support for JSON files. Getting names for incoming foreign keys from JSON files is not supported yet and RedG will fall back to the DefaultNameProvider . See below for the syntax of the JSON file: { \"TABLE_NAME\" : { \"name\" : \"TableClassName\" , \"columns\" : { \"COLUMN_1\" : \"myCustomNameCol1\" , \"COLUMN_2\" : \"otherCustomName\" , \"FK_SPECIAL_FOREIGN_KEY\" : \"customFkName\" } } }","title":"JSON file"},{"location":"customization/generator/name_mapping/#java-api","text":"Custom implementations have to implement the NameProvider interface. If you only want to override behaviour for one type (table, column, foreign key), consider returning null for all methods you do not want to override and use a MultiProviderNameProvider . public interface NameProvider { String getClassNameForTable ( Table table ); String getMethodNameForColumn ( Column column ); String getMethodNameForForeignKey ( ForeignKey foreignKey ); String getMethodNameForIncomingForeignKey ( ForeignKey foreignKey ); }","title":"Java API"},{"location":"customization/generator/type_mapping/","text":"Custom type mapping \u00b6 RedG allows you to customize the SQL to Java type mapping for the generated entity classes. When analysing a database schema, RedG always tries to find an appropriate Java datatype for a column. There are three cases, where this might not be enough: You want a different Java datatype that still represents the same database datatype (eg. long instead of BigDecimal for NUMBER(10) ) RedG cannot understand the semantic meaning of a column datatype (eg. NUMBER(1) or CHAR(1) for boolean ) You want to plug in a custom, maybe even far more complex, data type and use it instead of the default types If this happens, you can create a custom type mapping. The following sections describe how to specify your custom mapping. JSON file \u00b6 If you want to specify your mapping in a JSON file, use the JsonFileDataTypeProvider . The Maven plugin has built-in support for JSON files. The syntax for the JSON file is simple: You can specify tableMappings that specify the type for a column inside a table or you can use the defaultMappings where you can assign a data type to be used for a specific SQL type. The tableMappings have a higher priority and can be used to override the defaultMappings . For the tableMappings : Each table gets an own object. The key for that object is the full table name (including the schema name). This object contains a key for each column you want to map. The key is the column name. The value for each key is the wanted data type. For the defaultMappings : The key is the SQL data type (with or without precision information), the value is the Java type. SQL types with precision information always take precedence over types without precision information. So when a column has the data type NUMBER(1) and the mappings contain both NUMBER -> Long and NUMBER(1) -> Boolean the column will be mapped to a Boolean type. When dealing with VARCHAR s or similar, you can also use \"precision\" (aka length) information, but do not include CHAR inside the brackets (eg. if type is VARCHAR2(100 CHAR) , use VARCHAR2(100) to match this). Example: { \"tableMappings\" : { \"SCHEMA-NAME.TABLE-NAME\" : { \"COLUMN-NAME\" : \"your.java.Datatype\" , \"OTHER-COLUMN\" : \"other.Type\" }, \"SCHEMA-NAME.OTHER-TABLE\" : { \"ID-COLUMN\" : \"long\" } }, \"defaultMappings\" : { \"NUMBER\" : \"java.lang.Long\" , \"NUMBER(1)\" : \"java.lang.Boolean\" } } XML file \u00b6 If you want to specify your type mapping with an XML file, use the XmlFileDataTypeProvider . The Maven plugin has built-in support for XML files. The root element is <typeMappings> . This element has a child <tableTypeMappings> . Each table you want to specify the types for gets a <table> element with a name attribute specifying the table name. Each table element has <column> child elements. These elements have a name attribute and their value is the wanted data type. The other allowed child element is <defaultTypeMappings> . It can have multiple <type> children with a sql attribute specifying the SQL data type (with precision support just like for JSON). The value of this node is the Java type that the SQL type should be mapped to. Example: <typeMappings> <tableTypeMappings> <table name= \"TABLE_NAME\" > <column name= \"COLUMN_NAME\" > java.lang.String </column> </table> </tableTypeMappings> <defaultTypeMappings> <type sql= \"DECIMAL(1)\" > java-lang.Boolean </type> </defaultTypeMappings> </typeMappings> Java API \u00b6 Custom implementations have to implement the DataTypeProvider interface. The method getCanonicalDataTypeName gets called for each column in every table. The method has to return a fully qualified class name that should be used for that column. public interface DataTypeProvider { String getCanonicalDataTypeName ( Column column ); }","title":"Type mapping"},{"location":"customization/generator/type_mapping/#custom-type-mapping","text":"RedG allows you to customize the SQL to Java type mapping for the generated entity classes. When analysing a database schema, RedG always tries to find an appropriate Java datatype for a column. There are three cases, where this might not be enough: You want a different Java datatype that still represents the same database datatype (eg. long instead of BigDecimal for NUMBER(10) ) RedG cannot understand the semantic meaning of a column datatype (eg. NUMBER(1) or CHAR(1) for boolean ) You want to plug in a custom, maybe even far more complex, data type and use it instead of the default types If this happens, you can create a custom type mapping. The following sections describe how to specify your custom mapping.","title":"Custom type mapping"},{"location":"customization/generator/type_mapping/#json-file","text":"If you want to specify your mapping in a JSON file, use the JsonFileDataTypeProvider . The Maven plugin has built-in support for JSON files. The syntax for the JSON file is simple: You can specify tableMappings that specify the type for a column inside a table or you can use the defaultMappings where you can assign a data type to be used for a specific SQL type. The tableMappings have a higher priority and can be used to override the defaultMappings . For the tableMappings : Each table gets an own object. The key for that object is the full table name (including the schema name). This object contains a key for each column you want to map. The key is the column name. The value for each key is the wanted data type. For the defaultMappings : The key is the SQL data type (with or without precision information), the value is the Java type. SQL types with precision information always take precedence over types without precision information. So when a column has the data type NUMBER(1) and the mappings contain both NUMBER -> Long and NUMBER(1) -> Boolean the column will be mapped to a Boolean type. When dealing with VARCHAR s or similar, you can also use \"precision\" (aka length) information, but do not include CHAR inside the brackets (eg. if type is VARCHAR2(100 CHAR) , use VARCHAR2(100) to match this). Example: { \"tableMappings\" : { \"SCHEMA-NAME.TABLE-NAME\" : { \"COLUMN-NAME\" : \"your.java.Datatype\" , \"OTHER-COLUMN\" : \"other.Type\" }, \"SCHEMA-NAME.OTHER-TABLE\" : { \"ID-COLUMN\" : \"long\" } }, \"defaultMappings\" : { \"NUMBER\" : \"java.lang.Long\" , \"NUMBER(1)\" : \"java.lang.Boolean\" } }","title":"JSON file"},{"location":"customization/generator/type_mapping/#xml-file","text":"If you want to specify your type mapping with an XML file, use the XmlFileDataTypeProvider . The Maven plugin has built-in support for XML files. The root element is <typeMappings> . This element has a child <tableTypeMappings> . Each table you want to specify the types for gets a <table> element with a name attribute specifying the table name. Each table element has <column> child elements. These elements have a name attribute and their value is the wanted data type. The other allowed child element is <defaultTypeMappings> . It can have multiple <type> children with a sql attribute specifying the SQL data type (with precision support just like for JSON). The value of this node is the Java type that the SQL type should be mapped to. Example: <typeMappings> <tableTypeMappings> <table name= \"TABLE_NAME\" > <column name= \"COLUMN_NAME\" > java.lang.String </column> </table> </tableTypeMappings> <defaultTypeMappings> <type sql= \"DECIMAL(1)\" > java-lang.Boolean </type> </defaultTypeMappings> </typeMappings>","title":"XML file"},{"location":"customization/generator/type_mapping/#java-api","text":"Custom implementations have to implement the DataTypeProvider interface. The method getCanonicalDataTypeName gets called for each column in every table. The method has to return a fully qualified class name that should be used for that column. public interface DataTypeProvider { String getCanonicalDataTypeName ( Column column ); }","title":"Java API"},{"location":"customization/runtime/default_value_strategy/","text":"DefaultValueStrategy \u00b6 The default value strategy is one of RedGs most important features, and like most of RedG can be customized to fit your requirements. The default implementation is DefaultDefaultValueStrategy . It delivers null for any nullable columns and a fixed non-null value for NOT NULL columns. However, most of the time, the DefaultDefaultValueStrategy will not completely meet your needs. You could easily write your own DefaultValueStrategy from scratch, but we recommend using the DefaultValueStrategyBuilder . It provides a convenient and clear API for creating custom DefaultValueStrategy s. DefaultDefaultValueStrategy \u00b6 RedG's default default value strategy supports the following data types and provides a fixed default value for them. Data type Default value String \"-\" (Oracle does not support empty Strings and treats them as NULL ) char / Character ' ' (whitespace character) boolean / boolean false everything extending Number / primitive number types 0 everything extending java.util.Date 0 (= 01.01.1970 ) Java 8 date types 1970-01-01T00:00:00.000Z If a column is a primary key or has a unique constraint, a value that is unique to that column (but may be the same as in other unique columns) is generated. Data type Unique default value Max number of unique values String \"A\" , \"B\" , ..., \"Z\" , \"AA\" , \"AB\" ... 2^64 char / Character Unicode Character starting with \\u0001 up until \\uffff (2^16)-1 = 65,535 boolean / boolean false , then true 2 everything extending Number / primitive number types 0 , 1 , 2 , ... 2^64 everything extending java.util.Date Counting up milliseconds since unix epoch, starting at 0 until year 8099 Java 8 date types Counting up milliseconds since unix epoch, starting at 0 until year 8099 DefaultValueStrategyBuilder \u00b6 DefaultValueStrategyBuilder is the recommended way of creating DefaultValueStrategy s. It provides a convenient and clear API for creating DefaultValueStrategy s. DefaultValueStrategyBuilder builder = new DefaultValueStrategyBuilder (); builder . whenColumnNameMatches ( \"ID\" ) . thenUseProvider ( new IncrementingNumberProvider ()); builder . whenTableNameMatches ( \".*CARD\" ). andColumnNameMatches ( \"TYPE\" ) . thenUse ( \"MASTERCARD\" ); builder . when ( columnModel -> columnModel . getDbFullTableName (). equals ( \"CCM.CREDITCARD.UUID\" )) . thenCompute (( columnModel , expectedType ) -> UUID . randomUUID (). toString ()); builder . build (); By default DefaultValueStrategyBuilder will add a DefaultDefaultValueStrategy as fallback value provider. However, you can change this using DefaultValueStrategyBuilder.setFallbackStrategy(DefaultValueStrategy) . PluggableDefaultValueStrategy \u00b6 This is the DefaultValueStrategy implementation that the DefaultValueStrategyBuilder uses internally. The PluggableDefaultValueStrategy has a list of PluggableDefaultValueProvider s. When a default value needs to be generated, it checks whether a provider can provide a default value for the required data type / table / column. The values from all eligible providers are then collected and the first not-null value is returned as the default value. If no eligible provider is found or all return null , null gets returned. Even if the column is nullable ( notNull == false ), a not-null value is preferred. The following providers are bundles with RedG: Class name Description ConstantStringProvider Provides a constant String which can be set by the user. ConstantValueProvider Provides a constant value for a certain data type. Returns the value if value.getClass() equals the exact required type. StaticNumberProvider Provides a static number. IncrementingNumberProvider Provides an incrementing number. The start value can be specified. The counter is incremented for each column separately. Ideal for index columns. StaticDateProvider Takes a java.util.Date as a parameter and returns it for every java date type. CurrentDateProvider Returns the current date / time for every java date type. ConditionalProvider Encapsulates another provider and will only return its value if the regular expressions for table & column name match. CustomConditionalProvider A conditional provider that is even more flexible that the ConditionalProvider . Is used by the builder system. DefaultDefaultValueProvider A provider encapsulating the DefaultDefaultValueStrategy . Use for fallback purposes. Custom provider implementation \u00b6 Implementing a custom provider is easy. Simply implement the PluggableDefaultValueProvider interface and implement both the getDefaultValue and willProvide method. The willProvide method should return true if getDefaultValue can and should produce a default value for the current column and data type. Custom implementation \u00b6 Custom default value strategies have to implement the DefaultValueStrategy interface. If notNull is true and null is returned, RedG will fail. RedG does not perform further checks on the value generated by this method. You have full control and responsibility. public interface DefaultValueStrategy { < T > T getDefaultValue ( ColumnModel columnModel , Class < T > type ); }","title":"Default value strategy"},{"location":"customization/runtime/default_value_strategy/#defaultvaluestrategy","text":"The default value strategy is one of RedGs most important features, and like most of RedG can be customized to fit your requirements. The default implementation is DefaultDefaultValueStrategy . It delivers null for any nullable columns and a fixed non-null value for NOT NULL columns. However, most of the time, the DefaultDefaultValueStrategy will not completely meet your needs. You could easily write your own DefaultValueStrategy from scratch, but we recommend using the DefaultValueStrategyBuilder . It provides a convenient and clear API for creating custom DefaultValueStrategy s.","title":"DefaultValueStrategy"},{"location":"customization/runtime/default_value_strategy/#defaultdefaultvaluestrategy","text":"RedG's default default value strategy supports the following data types and provides a fixed default value for them. Data type Default value String \"-\" (Oracle does not support empty Strings and treats them as NULL ) char / Character ' ' (whitespace character) boolean / boolean false everything extending Number / primitive number types 0 everything extending java.util.Date 0 (= 01.01.1970 ) Java 8 date types 1970-01-01T00:00:00.000Z If a column is a primary key or has a unique constraint, a value that is unique to that column (but may be the same as in other unique columns) is generated. Data type Unique default value Max number of unique values String \"A\" , \"B\" , ..., \"Z\" , \"AA\" , \"AB\" ... 2^64 char / Character Unicode Character starting with \\u0001 up until \\uffff (2^16)-1 = 65,535 boolean / boolean false , then true 2 everything extending Number / primitive number types 0 , 1 , 2 , ... 2^64 everything extending java.util.Date Counting up milliseconds since unix epoch, starting at 0 until year 8099 Java 8 date types Counting up milliseconds since unix epoch, starting at 0 until year 8099","title":"DefaultDefaultValueStrategy"},{"location":"customization/runtime/default_value_strategy/#defaultvaluestrategybuilder","text":"DefaultValueStrategyBuilder is the recommended way of creating DefaultValueStrategy s. It provides a convenient and clear API for creating DefaultValueStrategy s. DefaultValueStrategyBuilder builder = new DefaultValueStrategyBuilder (); builder . whenColumnNameMatches ( \"ID\" ) . thenUseProvider ( new IncrementingNumberProvider ()); builder . whenTableNameMatches ( \".*CARD\" ). andColumnNameMatches ( \"TYPE\" ) . thenUse ( \"MASTERCARD\" ); builder . when ( columnModel -> columnModel . getDbFullTableName (). equals ( \"CCM.CREDITCARD.UUID\" )) . thenCompute (( columnModel , expectedType ) -> UUID . randomUUID (). toString ()); builder . build (); By default DefaultValueStrategyBuilder will add a DefaultDefaultValueStrategy as fallback value provider. However, you can change this using DefaultValueStrategyBuilder.setFallbackStrategy(DefaultValueStrategy) .","title":"DefaultValueStrategyBuilder"},{"location":"customization/runtime/default_value_strategy/#pluggabledefaultvaluestrategy","text":"This is the DefaultValueStrategy implementation that the DefaultValueStrategyBuilder uses internally. The PluggableDefaultValueStrategy has a list of PluggableDefaultValueProvider s. When a default value needs to be generated, it checks whether a provider can provide a default value for the required data type / table / column. The values from all eligible providers are then collected and the first not-null value is returned as the default value. If no eligible provider is found or all return null , null gets returned. Even if the column is nullable ( notNull == false ), a not-null value is preferred. The following providers are bundles with RedG: Class name Description ConstantStringProvider Provides a constant String which can be set by the user. ConstantValueProvider Provides a constant value for a certain data type. Returns the value if value.getClass() equals the exact required type. StaticNumberProvider Provides a static number. IncrementingNumberProvider Provides an incrementing number. The start value can be specified. The counter is incremented for each column separately. Ideal for index columns. StaticDateProvider Takes a java.util.Date as a parameter and returns it for every java date type. CurrentDateProvider Returns the current date / time for every java date type. ConditionalProvider Encapsulates another provider and will only return its value if the regular expressions for table & column name match. CustomConditionalProvider A conditional provider that is even more flexible that the ConditionalProvider . Is used by the builder system. DefaultDefaultValueProvider A provider encapsulating the DefaultDefaultValueStrategy . Use for fallback purposes.","title":"PluggableDefaultValueStrategy"},{"location":"customization/runtime/default_value_strategy/#custom-provider-implementation","text":"Implementing a custom provider is easy. Simply implement the PluggableDefaultValueProvider interface and implement both the getDefaultValue and willProvide method. The willProvide method should return true if getDefaultValue can and should produce a default value for the current column and data type.","title":"Custom provider implementation"},{"location":"customization/runtime/default_value_strategy/#custom-implementation","text":"Custom default value strategies have to implement the DefaultValueStrategy interface. If notNull is true and null is returned, RedG will fail. RedG does not perform further checks on the value generated by this method. You have full control and responsibility. public interface DefaultValueStrategy { < T > T getDefaultValue ( ColumnModel columnModel , Class < T > type ); }","title":"Custom implementation"},{"location":"customization/runtime/dummy_factory/","text":"Dummy factory \u00b6 This section describes how to modify the default behaviour of RedG's dummy data generation mechanism. For an explanation and a guide on how to use this mechanism, check this out. There are two main reasons to modify or extend the existing dummy generation system: You want to modify the generated dummy entities RedG cannot generate the dummy entities for some reason If the latter occurs, feel free to open an issue and we might try to implement support for your case. Implement own DummyFactory \u00b6 If you need to, you can always implement your own DummyFactory . Here are a few tips when implementing your custom factory: Remember to take care of all transitive dependencies. Abstain from using user-generated entities already within RedG as dummies. Dummies should be entities your factory generated. Implement isDummy correctly, or features like the visualization will not work properly. public interface DummyFactory { < T extends RedGEntity > T getDummy ( AbstractRedG redG , Class < T > dummyClass ); boolean isDummy ( RedGEntity entity ); }","title":"Dummy factory"},{"location":"customization/runtime/dummy_factory/#dummy-factory","text":"This section describes how to modify the default behaviour of RedG's dummy data generation mechanism. For an explanation and a guide on how to use this mechanism, check this out. There are two main reasons to modify or extend the existing dummy generation system: You want to modify the generated dummy entities RedG cannot generate the dummy entities for some reason If the latter occurs, feel free to open an issue and we might try to implement support for your case.","title":"Dummy factory"},{"location":"customization/runtime/dummy_factory/#implement-own-dummyfactory","text":"If you need to, you can always implement your own DummyFactory . Here are a few tips when implementing your custom factory: Remember to take care of all transitive dependencies. Abstain from using user-generated entities already within RedG as dummies. Dummies should be entities your factory generated. Implement isDummy correctly, or features like the visualization will not work properly. public interface DummyFactory { < T extends RedGEntity > T getDummy ( AbstractRedG redG , Class < T > dummyClass ); boolean isDummy ( RedGEntity entity ); }","title":"Implement own DummyFactory"},{"location":"customization/runtime/prepared_statement_parameter_setter/","text":"PreparedStatement parameter setter \u00b6 The PreparedStatement parameter setter is used by RedG set the column values for the PreparedStatement . It can be used to convert a custom data type into a type the JDBC driver can understand. Note If you are not using PreparedStatements with the insertDataIntoDatabase() method, you can ignore the PreparedStatement parameter setter and take a look at the SQL values formatter Default PreparedStatement parameter setter \u00b6 The DefaultPreparedStatementSetter only calls toString() on the value if the JDBC type is one of Types.CHAR, Types.VARCHAR, Types.LONGNVARCHAR . Every other value is passed to the statement without modification. This works for most standard java types and depending on your JDBC driver it might even work for the new Java time types. Consult the documentation of your JDBC driver for more information on supported types. Java API \u00b6 If you need to implement your own setter, implement the PreparedStatementParameterSetter interface. Inside of this method you should transform the object if needed. The AttributeMetaInfo provide you with metadata about the object you are processing. After transforming the object, set it as the parameter on the passed statement . Caution Only call statement.set...() with the index parameter specified in parameterIndex . RedG performs no further checks whether you actually set the right parameter (or any at all). @FunctionalInterface public interface PreparedStatementParameterSetter { void setParameter ( PreparedStatement statement , int parameterIndex , Object object , AttributeMetaInfo attributeMetaInfo , final Connection connection ) throws SQLException ; }","title":"PreparedStatement parameter setter"},{"location":"customization/runtime/prepared_statement_parameter_setter/#preparedstatement-parameter-setter","text":"The PreparedStatement parameter setter is used by RedG set the column values for the PreparedStatement . It can be used to convert a custom data type into a type the JDBC driver can understand. Note If you are not using PreparedStatements with the insertDataIntoDatabase() method, you can ignore the PreparedStatement parameter setter and take a look at the SQL values formatter","title":"PreparedStatement parameter setter"},{"location":"customization/runtime/prepared_statement_parameter_setter/#default-preparedstatement-parameter-setter","text":"The DefaultPreparedStatementSetter only calls toString() on the value if the JDBC type is one of Types.CHAR, Types.VARCHAR, Types.LONGNVARCHAR . Every other value is passed to the statement without modification. This works for most standard java types and depending on your JDBC driver it might even work for the new Java time types. Consult the documentation of your JDBC driver for more information on supported types.","title":"Default PreparedStatement parameter setter"},{"location":"customization/runtime/prepared_statement_parameter_setter/#java-api","text":"If you need to implement your own setter, implement the PreparedStatementParameterSetter interface. Inside of this method you should transform the object if needed. The AttributeMetaInfo provide you with metadata about the object you are processing. After transforming the object, set it as the parameter on the passed statement . Caution Only call statement.set...() with the index parameter specified in parameterIndex . RedG performs no further checks whether you actually set the right parameter (or any at all). @FunctionalInterface public interface PreparedStatementParameterSetter { void setParameter ( PreparedStatement statement , int parameterIndex , Object object , AttributeMetaInfo attributeMetaInfo , final Connection connection ) throws SQLException ; }","title":"Java API"},{"location":"customization/runtime/sql_values_formatter/","text":"SQL values formatter \u00b6 The SQL values formatter defines how attribute / column values have to be represented in the SQL INSERT string generated by RedG. RedG offers a default formatter DefaultSQLValuesFormatter that can turn the most common data types into valid SQL. If you are using uncommon or custom data types, you have to provide your own implementation. Note If you are not generating SQL INSERT statements with the generateSQLStatements() method, you can ignore the SQL values formatter and take a look at the PreparedStatement parameter setter Default SQL values formatter \u00b6 The default formatter provided by RedG formats the input like described in the following table. (Empty fields in the type columns mean that RedG does not check that type) SQL type Java type Formatting VARCHAR & VARCHAR2 toString() gets called on value and single quotation marks get escaped. Escaped string gets wrapped in single quotation marks. DECIMAL & NUMBER Boolean 1 for true , 0 for false. DECIMAL & NUMBER toString() gets called on value. This works for numbers, as they all implement a correct toString() method. No precision checks are performed. java.util.Date A timestamp gets constructed from the unix timestamp and inserted as a string using the TO_TIMESTAMP(string, format) SQL function. TemporalAccessor The temporal value gets formatted and inserted as a string using the TO_TIMESTAMP(string, format) SQL function. Java API \u00b6 If you need your own formatter, simply implement the SQLValuesFormatter interface. The formatValues method gets called for every value that has to be formatted (so every attribute in every entity). public interface SQLValuesFormatter { < T > String formatValue ( T value , String sqlDataType , String fullTableName , String tableName , String columnName ); }","title":"SQL values formatter"},{"location":"customization/runtime/sql_values_formatter/#sql-values-formatter","text":"The SQL values formatter defines how attribute / column values have to be represented in the SQL INSERT string generated by RedG. RedG offers a default formatter DefaultSQLValuesFormatter that can turn the most common data types into valid SQL. If you are using uncommon or custom data types, you have to provide your own implementation. Note If you are not generating SQL INSERT statements with the generateSQLStatements() method, you can ignore the SQL values formatter and take a look at the PreparedStatement parameter setter","title":"SQL values formatter"},{"location":"customization/runtime/sql_values_formatter/#default-sql-values-formatter","text":"The default formatter provided by RedG formats the input like described in the following table. (Empty fields in the type columns mean that RedG does not check that type) SQL type Java type Formatting VARCHAR & VARCHAR2 toString() gets called on value and single quotation marks get escaped. Escaped string gets wrapped in single quotation marks. DECIMAL & NUMBER Boolean 1 for true , 0 for false. DECIMAL & NUMBER toString() gets called on value. This works for numbers, as they all implement a correct toString() method. No precision checks are performed. java.util.Date A timestamp gets constructed from the unix timestamp and inserted as a string using the TO_TIMESTAMP(string, format) SQL function. TemporalAccessor The temporal value gets formatted and inserted as a string using the TO_TIMESTAMP(string, format) SQL function.","title":"Default SQL values formatter"},{"location":"customization/runtime/sql_values_formatter/#java-api","text":"If you need your own formatter, simply implement the SQLValuesFormatter interface. The formatValues method gets called for every value that has to be formatted (so every attribute in every entity). public interface SQLValuesFormatter { < T > String formatValue ( T value , String sqlDataType , String fullTableName , String tableName , String columnName ); }","title":"Java API"},{"location":"development/debugging_plugin/","text":"Debugging the Maven Plugin \u00b6 If you find problems during the code generation with the Maven plugin, take these steps to debug the redg-generator running inside the plugin: Import the redg project into your IDE (when using IDEA, open in new window) Set your IDE up for remote debugging of the redg project In your other project, add the remote debugging VM options to your Maven profile ( -agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5005 ) Start the Maven build in the other project Set your breakpoints Attach the remote debugger","title":"Debugging Maven plugin"},{"location":"development/debugging_plugin/#debugging-the-maven-plugin","text":"If you find problems during the code generation with the Maven plugin, take these steps to debug the redg-generator running inside the plugin: Import the redg project into your IDE (when using IDEA, open in new window) Set your IDE up for remote debugging of the redg project In your other project, add the remote debugging VM options to your Maven profile ( -agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5005 ) Start the Maven build in the other project Set your breakpoints Attach the remote debugger","title":"Debugging the Maven Plugin"},{"location":"development/quick_start_guide/","text":"Quick Start Guide \u00b6 This is a quick start guide for the development of RedG. If you want to use RedG in your project, see here . Info RedG was developed for internal usage in projects of the BTC Business Technology Consulting AG. Further development will mainly be driven by the needs of the internal projects using RedG. If you require a feature, either open an issue and hope it might get implemented or feel free to fork our repository, implement it yourself and create a pull request. Project setup \u00b6 Clone the Git-Repository ( git@github.com:btc-ag/redg.git or your HTTPS link). RedG uses Maven for development and you can simply import the main pom.xml in your favorite IDE. The main project has 6 sub-projects: Module Content redg-extractor Library for generating RedG entity definition code from existing entities in a database. Can be used for migrating to RedG redg-generator Analyzes the database schema and generates the matching entity classes. Search here if you want to extend or have trouble with the generated code redg-jpa-providers A name and datatype provider for usage with the redg-generator , that uses information from your JPA Metamodel. Not included by default because of Hibernate dependency redg-maven-plugin The plugin that integrates the redg-generator into the Maven build process redg-models Common model files redg-runtime The runtime needed during execution. Search here, if the generated code is fine but execution fails during runtime or you want more features","title":"Quick Start Guide"},{"location":"development/quick_start_guide/#quick-start-guide","text":"This is a quick start guide for the development of RedG. If you want to use RedG in your project, see here . Info RedG was developed for internal usage in projects of the BTC Business Technology Consulting AG. Further development will mainly be driven by the needs of the internal projects using RedG. If you require a feature, either open an issue and hope it might get implemented or feel free to fork our repository, implement it yourself and create a pull request.","title":"Quick Start Guide"},{"location":"development/quick_start_guide/#project-setup","text":"Clone the Git-Repository ( git@github.com:btc-ag/redg.git or your HTTPS link). RedG uses Maven for development and you can simply import the main pom.xml in your favorite IDE. The main project has 6 sub-projects: Module Content redg-extractor Library for generating RedG entity definition code from existing entities in a database. Can be used for migrating to RedG redg-generator Analyzes the database schema and generates the matching entity classes. Search here if you want to extend or have trouble with the generated code redg-jpa-providers A name and datatype provider for usage with the redg-generator , that uses information from your JPA Metamodel. Not included by default because of Hibernate dependency redg-maven-plugin The plugin that integrates the redg-generator into the Maven build process redg-models Common model files redg-runtime The runtime needed during execution. Search here, if the generated code is fine but execution fails during runtime or you want more features","title":"Project setup"},{"location":"features/data_extractor/","text":"Data extractor \u00b6 To help you with migrating from your existing solution to RedG you can use the RedG extractor. It enables you to extract all the data from a database and create a RedG data set that, if inserted, will produce the exact same database content. Note The RedG data set will contain every column from every table. This does not make use of RedG's greatest features (default values, dummy generator). Use the extraction result as a starting point and then reduce your data to the needed minimum. This has to be done by hand, as RedG does not know what data you really need. Java API \u00b6 If you have your current test data only available in-memory during your tests, use the Java API of the extractor to generate the RedG Java code. The generation is a three-step process: Get the RedG TableModel s for all tables you want to extract Extract all the data into EntityModel s Generate the code for the EntityModel s Obtain the TableModels \u00b6 There are multiple ways of obtaining the TableModel s for your database schema. RedG writes a serialized table model into every generated entity class code. These can be accessed at runtime via the static getTableModel() method. If the generated classes are either not yet compiled or compiled but not loaded in your current JVM instance, you can use the TableModelExtractor.extractTableModelsFromSourceCode(directory, codePackage, classPrefix) or TableModelExtractor.extractTableModelFromClasses(directory, codePackage, classPrefix) methods to extract the TableModel s for all RedG entity classes. These two methods take three parameters: Parameter Explanation directory The Path of the source code root, without the package structure folders packageName The name of the Java package that was used during code generation. com.btc.redg.generated if not overwritten classPrefix The class name prefix for the generated RedG classes. G by default Extract all data \u00b6 Obtain a connection to your database and call new DataExtractor().extractAllData( connection, tableModels) . tableModels should be the list of TableModel s from the previous step. Note If the database you are extracting from is not the same you generated the RedG code from, you might have to change the schema name. To do so, use DataExtractor#setSqlSchema(String schema) to specify the schema name. Save the result in a list of EntityModel s for the next step. Note If you manually exclude some TableModel s, keep in mind that the extraction will fail if a TableModel for a dependend table (via foreign key) is not found. Generate the code \u00b6 Using the EntityModel s you can now call new CodeGenerator().generateCode( codePackageName, redGClassName, codeClassName, entityModels) This will return the Java code as a String. The generated code will be in the default package, so you might need to add your own package x.y.z statement at the top. The generateCode method takes four parameters: Parameter Explanation codePackage The code package of the generated RedG entity classes. Needed for imports redgClassName The name of your RedG main class. Normally RedG className The name that will be used for the class containing your entity specification code entityModels The EntityModel s from the previous step Using the generated code \u00b6 When your database only contains strings and numbers, RedG's extractor will most likely produce working Java code. If you are using dates, blobs or other more \"exotic\" types that cannot simply be mapped to a Java type, the toString() result will simply be used as a placeholder and you'll have to fix the code.","title":"Data extraction"},{"location":"features/data_extractor/#data-extractor","text":"To help you with migrating from your existing solution to RedG you can use the RedG extractor. It enables you to extract all the data from a database and create a RedG data set that, if inserted, will produce the exact same database content. Note The RedG data set will contain every column from every table. This does not make use of RedG's greatest features (default values, dummy generator). Use the extraction result as a starting point and then reduce your data to the needed minimum. This has to be done by hand, as RedG does not know what data you really need.","title":"Data extractor"},{"location":"features/data_extractor/#java-api","text":"If you have your current test data only available in-memory during your tests, use the Java API of the extractor to generate the RedG Java code. The generation is a three-step process: Get the RedG TableModel s for all tables you want to extract Extract all the data into EntityModel s Generate the code for the EntityModel s","title":"Java API"},{"location":"features/data_extractor/#obtain-the-tablemodels","text":"There are multiple ways of obtaining the TableModel s for your database schema. RedG writes a serialized table model into every generated entity class code. These can be accessed at runtime via the static getTableModel() method. If the generated classes are either not yet compiled or compiled but not loaded in your current JVM instance, you can use the TableModelExtractor.extractTableModelsFromSourceCode(directory, codePackage, classPrefix) or TableModelExtractor.extractTableModelFromClasses(directory, codePackage, classPrefix) methods to extract the TableModel s for all RedG entity classes. These two methods take three parameters: Parameter Explanation directory The Path of the source code root, without the package structure folders packageName The name of the Java package that was used during code generation. com.btc.redg.generated if not overwritten classPrefix The class name prefix for the generated RedG classes. G by default","title":"Obtain the TableModels"},{"location":"features/data_extractor/#extract-all-data","text":"Obtain a connection to your database and call new DataExtractor().extractAllData( connection, tableModels) . tableModels should be the list of TableModel s from the previous step. Note If the database you are extracting from is not the same you generated the RedG code from, you might have to change the schema name. To do so, use DataExtractor#setSqlSchema(String schema) to specify the schema name. Save the result in a list of EntityModel s for the next step. Note If you manually exclude some TableModel s, keep in mind that the extraction will fail if a TableModel for a dependend table (via foreign key) is not found.","title":"Extract all data"},{"location":"features/data_extractor/#generate-the-code","text":"Using the EntityModel s you can now call new CodeGenerator().generateCode( codePackageName, redGClassName, codeClassName, entityModels) This will return the Java code as a String. The generated code will be in the default package, so you might need to add your own package x.y.z statement at the top. The generateCode method takes four parameters: Parameter Explanation codePackage The code package of the generated RedG entity classes. Needed for imports redgClassName The name of your RedG main class. Normally RedG className The name that will be used for the class containing your entity specification code entityModels The EntityModel s from the previous step","title":"Generate the code"},{"location":"features/data_extractor/#using-the-generated-code","text":"When your database only contains strings and numbers, RedG's extractor will most likely produce working Java code. If you are using dates, blobs or other more \"exotic\" types that cannot simply be mapped to a Java type, the toString() result will simply be used as a placeholder and you'll have to fix the code.","title":"Using the generated code"},{"location":"features/dummy_data/","text":"Dummy data \u00b6 RedG's dummy data feature allows you to focus on the test data you really need. No more specifying dozens of (transitive) dependencies you do not need for your test but your database needs them to satisfy the foreign key constraints. With RedG you can simply say \"I want a dummy entity of that type\" and you get one. With all of its dependencies set to other dummy objects. This works out-of-the-box with zero configuration in 99% of the cases. The RedG main class generated by RedG contains a dummyXX method for each entity type. Example \u00b6 Let's see this in action in a small example. Consider the following database schema: Because the user needs a bank account (it is a NOT NULL foreign key), you have to specify a bank account if you want to create a user with the redG.addDemoUser(GDemoBankAccount bankAcc) method. Simply passing null will not work here. If you now want to add a user and perform some tests that only require its first and last name, you can simply use a dummy as the bank account. redG . addDemoUser ( redG . dummyBankAccount ()) . firstName ( \"Trevor\" ) . lastName ( \"Testcase\" ); As you can see, RedG does all the heavy work for you. No need to specify anything for the dummy. You get a valid dummy that satisfies every database constraint so you can test the first and last name without worrying about the excess baggage. Customization \u00b6 If you need to customize how RedG generates dummy data, see here .","title":"Dummy data"},{"location":"features/dummy_data/#dummy-data","text":"RedG's dummy data feature allows you to focus on the test data you really need. No more specifying dozens of (transitive) dependencies you do not need for your test but your database needs them to satisfy the foreign key constraints. With RedG you can simply say \"I want a dummy entity of that type\" and you get one. With all of its dependencies set to other dummy objects. This works out-of-the-box with zero configuration in 99% of the cases. The RedG main class generated by RedG contains a dummyXX method for each entity type.","title":"Dummy data"},{"location":"features/dummy_data/#example","text":"Let's see this in action in a small example. Consider the following database schema: Because the user needs a bank account (it is a NOT NULL foreign key), you have to specify a bank account if you want to create a user with the redG.addDemoUser(GDemoBankAccount bankAcc) method. Simply passing null will not work here. If you now want to add a user and perform some tests that only require its first and last name, you can simply use a dummy as the bank account. redG . addDemoUser ( redG . dummyBankAccount ()) . firstName ( \"Trevor\" ) . lastName ( \"Testcase\" ); As you can see, RedG does all the heavy work for you. No need to specify anything for the dummy. You get a valid dummy that satisfies every database constraint so you can test the first and last name without worrying about the excess baggage.","title":"Example"},{"location":"features/dummy_data/#customization","text":"If you need to customize how RedG generates dummy data, see here .","title":"Customization"},{"location":"features/jpa_metamodel/","text":"JPA meta-model analysis \u00b6 RedG offers the ability to analyze a JPA meta-model and extract the names and data types from there. So if you are using a JPA persistence layer, configuring the names and data types with your existing JPA meta-model might be considerably easier for you. Maven plugin configuration \u00b6 To use the meta-model analysis with the Maven plugin , add the following XML to the plugin configuration: <jpaProviderConfig> <persistenceUnitName> nameOfPersistenceUnit </persistenceUnitName> <useAsNameProvider> true </useAsNameProvider> <useAsDataTypeProvider> false </useAsDataTypeProvider> </jpaProviderConfig> Java API \u00b6 Create a new JpaMetamodelRedGProvider either with a Metamodel via its constructor or with the static method JpaMetamodelRedGProvider#fromPersistenceUnit(String perstistenceUnitName) . Now use it as the name provider or data type provider as parameter for the RedG code generator method.","title":"JPA meta-model analysis"},{"location":"features/jpa_metamodel/#jpa-meta-model-analysis","text":"RedG offers the ability to analyze a JPA meta-model and extract the names and data types from there. So if you are using a JPA persistence layer, configuring the names and data types with your existing JPA meta-model might be considerably easier for you.","title":"JPA meta-model analysis"},{"location":"features/jpa_metamodel/#maven-plugin-configuration","text":"To use the meta-model analysis with the Maven plugin , add the following XML to the plugin configuration: <jpaProviderConfig> <persistenceUnitName> nameOfPersistenceUnit </persistenceUnitName> <useAsNameProvider> true </useAsNameProvider> <useAsDataTypeProvider> false </useAsDataTypeProvider> </jpaProviderConfig>","title":"Maven plugin configuration"},{"location":"features/jpa_metamodel/#java-api","text":"Create a new JpaMetamodelRedGProvider either with a Metamodel via its constructor or with the static method JpaMetamodelRedGProvider#fromPersistenceUnit(String perstistenceUnitName) . Now use it as the name provider or data type provider as parameter for the RedG code generator method.","title":"Java API"},{"location":"features/visualization/","text":"Visualization \u00b6 The RedG Visualizer allows you to inspect the object graph of a RedG instance. This can be very useful for debugging purposes or to simply have a look at the dependencies of your entities. Preparation \u00b6 Note RedG's visualization support has to be enabled during code generation time. Look at the documentation for your chosen integration method on how to enable support. Enabling visualization support will have a small performance penalty and you'll need Jackson as extra dependencies. After enabling visualization support you have to add jackson-core and jackson-databind as dependencies to your test code. These two are needed to generate the JSON output you'll need for the visualizer. <dependency> <groupId> com.fasterxml.jackson.core </groupId> <artifactId> jackson-core </artifactId> <version> 2.8.5 </version> <scope> test </scope> </dependency> <dependency> <groupId> com.fasterxml.jackson.core </groupId> <artifactId> jackson-databind </artifactId> <version> 2.8.5 </version> <scope> test </scope> </dependency> Now there are two ways to obtain the entity graph as JSON code: In the test, output the result of redG.getVisualizationJson() into a file or to the console. Place a breakpoint somewhere in your test where you have access to the redG object, let the test run until it hits the breakpoint and evaluate redG.getVisualizationJson() with the help of your IDE. Copy the returned string. Visualization \u00b6 With the JSON output either in your clipboard or a file, visit the RedG Visualizer site and paste (or drag & drop) the JSON into the editor. Hit the \"Visualize Me!\" button and let the visualization render. An example visualization Entity view \u00b6 The main panel of the visualizer shows a graphical representation of your RedG object graph. When the graph is rendered for the fist time a layout algorithm is applied. This results in a nice initial layout. When visualizing large object graphs, entities may appear below or right of your initial viewport. Either zoom out or pan to see them. Feature Controls Zoom Use your mouse wheel or double click (Pinch or double tap on touchscreens) Pan / Move viewport Click and drag on background (Cursor is default) Select entity Click an entity. Click again to deselect it Move an entity Click and drag an entity (Cursor is pointer) Detail view \u00b6 When you select an entity in the entity view , the detail view in the lower right corner will show all attributes (explicit & implicit) in full length and will show a list of all outgoing relations. You can click on a relation link to directly select the referenced entity. Options \u00b6 The upper right panel shows the available options and the export buttons. Option Type Explanation Show SQL names Checkbox If checked, the SQL table and column names will be shown instead of the Java identifiers Show relation names Checkbox If checked, the relation arrows will show a text with the relation name Dummy Entity Visibility Combo-Box Full: Show the full dummy entity (explicit & implicit fields) Minimal: Show only the header (class / table name) Invisible: Do not show the entity and their relations Existing Entity Visibility Combo-Box Full: Show the full existing entity (explicit & implicit fields) Minimal: Show only the header (class / table name) Invisible: Do not show the entity and their relations Export view as PNG Button Lets you export the current viewport (exactly what you see on the left) to a PNG file. Will show a popup where you can choose the image resolution Export view as SVG Button Lets you export the current viewport (exactly what you see on the left) to a SVG file. All information (entities & relations) are included so you could manipulate the viewport later. Used fonts might not be available on a different computer","title":"Visualization"},{"location":"features/visualization/#visualization","text":"The RedG Visualizer allows you to inspect the object graph of a RedG instance. This can be very useful for debugging purposes or to simply have a look at the dependencies of your entities.","title":"Visualization"},{"location":"features/visualization/#preparation","text":"Note RedG's visualization support has to be enabled during code generation time. Look at the documentation for your chosen integration method on how to enable support. Enabling visualization support will have a small performance penalty and you'll need Jackson as extra dependencies. After enabling visualization support you have to add jackson-core and jackson-databind as dependencies to your test code. These two are needed to generate the JSON output you'll need for the visualizer. <dependency> <groupId> com.fasterxml.jackson.core </groupId> <artifactId> jackson-core </artifactId> <version> 2.8.5 </version> <scope> test </scope> </dependency> <dependency> <groupId> com.fasterxml.jackson.core </groupId> <artifactId> jackson-databind </artifactId> <version> 2.8.5 </version> <scope> test </scope> </dependency> Now there are two ways to obtain the entity graph as JSON code: In the test, output the result of redG.getVisualizationJson() into a file or to the console. Place a breakpoint somewhere in your test where you have access to the redG object, let the test run until it hits the breakpoint and evaluate redG.getVisualizationJson() with the help of your IDE. Copy the returned string.","title":"Preparation"},{"location":"features/visualization/#visualization_1","text":"With the JSON output either in your clipboard or a file, visit the RedG Visualizer site and paste (or drag & drop) the JSON into the editor. Hit the \"Visualize Me!\" button and let the visualization render. An example visualization","title":"Visualization"},{"location":"features/visualization/#entity-view","text":"The main panel of the visualizer shows a graphical representation of your RedG object graph. When the graph is rendered for the fist time a layout algorithm is applied. This results in a nice initial layout. When visualizing large object graphs, entities may appear below or right of your initial viewport. Either zoom out or pan to see them. Feature Controls Zoom Use your mouse wheel or double click (Pinch or double tap on touchscreens) Pan / Move viewport Click and drag on background (Cursor is default) Select entity Click an entity. Click again to deselect it Move an entity Click and drag an entity (Cursor is pointer)","title":"Entity view"},{"location":"features/visualization/#detail-view","text":"When you select an entity in the entity view , the detail view in the lower right corner will show all attributes (explicit & implicit) in full length and will show a list of all outgoing relations. You can click on a relation link to directly select the referenced entity.","title":"Detail view"},{"location":"features/visualization/#options","text":"The upper right panel shows the available options and the export buttons. Option Type Explanation Show SQL names Checkbox If checked, the SQL table and column names will be shown instead of the Java identifiers Show relation names Checkbox If checked, the relation arrows will show a text with the relation name Dummy Entity Visibility Combo-Box Full: Show the full dummy entity (explicit & implicit fields) Minimal: Show only the header (class / table name) Invisible: Do not show the entity and their relations Existing Entity Visibility Combo-Box Full: Show the full existing entity (explicit & implicit fields) Minimal: Show only the header (class / table name) Invisible: Do not show the entity and their relations Export view as PNG Button Lets you export the current viewport (exactly what you see on the left) to a PNG file. Will show a popup where you can choose the image resolution Export view as SVG Button Lets you export the current viewport (exactly what you see on the left) to a SVG file. All information (entities & relations) are included so you could manipulate the viewport later. Used fonts might not be available on a different computer","title":"Options"},{"location":"integration/","text":"Integration \u00b6 The way you integrate RedG into you project depends on your build system and personal preferences. RedG is very flexible and can easily be adapted to fit your project. RedG code generator \u00b6 The RedG code generator analyzes your database and generates matching entity classes you can then use to specify your test data. Usually the code generation is so fast that it can be run before every test, thus ensuring it is always up-to-date and matches the current database schema. There are multiple ways of integrating the code generator into your project. The RedG Maven plugin Calling the generator API manually RedG runtime \u00b6 The RedG runtime library is available as a Maven dependency in the Maven Central. All of the following integration possibilities require the following dependency: <dependency> <groupId> com.btc-ag.redg </groupId> <artifactId> redg-runtime </artifactId> <version> 2.0 </version> <scope> test </scope> </dependency> After you have specified your test data you can insert them with the runtime API . This approach offers absolute flexibility and can easily be integrated into any Java project.","title":"Overview"},{"location":"integration/#integration","text":"The way you integrate RedG into you project depends on your build system and personal preferences. RedG is very flexible and can easily be adapted to fit your project.","title":"Integration"},{"location":"integration/#redg-code-generator","text":"The RedG code generator analyzes your database and generates matching entity classes you can then use to specify your test data. Usually the code generation is so fast that it can be run before every test, thus ensuring it is always up-to-date and matches the current database schema. There are multiple ways of integrating the code generator into your project. The RedG Maven plugin Calling the generator API manually","title":"RedG code generator"},{"location":"integration/#redg-runtime","text":"The RedG runtime library is available as a Maven dependency in the Maven Central. All of the following integration possibilities require the following dependency: <dependency> <groupId> com.btc-ag.redg </groupId> <artifactId> redg-runtime </artifactId> <version> 2.0 </version> <scope> test </scope> </dependency> After you have specified your test data you can insert them with the runtime API . This approach offers absolute flexibility and can easily be integrated into any Java project.","title":"RedG runtime"},{"location":"integration/generator_api/","text":"Code generator API \u00b6 When you need every last bit of customizability, using the code generator API is your best option. It offers you one big generateCode method that gives you access to every bit of customization that RedG supports out-of-the-box. To use the API, simply include the following Maven dependency: <dependency> <groupId> com.btc-ag.redg </groupId> <artifactId> redg-generator </artifactId> <version> 2.0 </version> </dependency> If you use are not using H2, you need to inlcude the JDBC driver and the SchemaCrawler plugin for your DBMS. See here for a list of all supported DBMS and their SchemaCrawler and plugins. See the Javadoc or source code for a detailed description of every parameter of the generateCode method. If you like an example how to use this method, take a look at the Maven plugin source . If even the standard API is not enough, take a look at the RedGGenerator source code. RedG is pretty modular and every important method is public, so you can just re-use the parts that work for you and re-implement the other parts. If your extension could benefit the community, please consider publishing it and create a pull request.","title":"Code generator API"},{"location":"integration/generator_api/#code-generator-api","text":"When you need every last bit of customizability, using the code generator API is your best option. It offers you one big generateCode method that gives you access to every bit of customization that RedG supports out-of-the-box. To use the API, simply include the following Maven dependency: <dependency> <groupId> com.btc-ag.redg </groupId> <artifactId> redg-generator </artifactId> <version> 2.0 </version> </dependency> If you use are not using H2, you need to inlcude the JDBC driver and the SchemaCrawler plugin for your DBMS. See here for a list of all supported DBMS and their SchemaCrawler and plugins. See the Javadoc or source code for a detailed description of every parameter of the generateCode method. If you like an example how to use this method, take a look at the Maven plugin source . If even the standard API is not enough, take a look at the RedGGenerator source code. RedG is pretty modular and every important method is public, so you can just re-use the parts that work for you and re-implement the other parts. If your extension could benefit the community, please consider publishing it and create a pull request.","title":"Code generator API"},{"location":"integration/maven_plugin/","text":"RedG Maven plugin \u00b6 The RedG Maven plugin offers comfortable and easy integration of the RedG code generation into your Maven project. It is configurable via Maven properties and JSON files. While the Maven plugin is pretty flexible, RedG can be configured even further if you use the code generator API directly. If you need absolute control, check out the docs for the code generator API . Usage \u00b6 Simply add the RedG plugin into your <plugins> section of your pom.xml . You may choose your own <id> , but the <phase> should stay at generate-test-sources in most cases. Now add your configuration in the <configuration> part and, if necessary, specify a dependency to your JDBC driver. If you use a different RDBMS than H2 you need an extra dependency to the SchemaCrawler plugin for your DBMS. The list of the most commonly needed plugins (for full list, see in Maven Central ): DBMS Necessary dependency Oracle us.fatehi:schemacrawler-oracle:15.01.06 IBM DB2 us.fatehi:schemacrawler-db2:15.01.06 MS SQL Server us.fatehi:schemacrawler-sqlserver:15.01.06 MySQL us.fatehi:schemacrawler-mysql:15.01.06 PostgreSQL us.fatehi:schemacrawler-postgresql:15.01.06 <plugin> <groupId> com.btc-ag.redg </groupId> <artifactId> redg-maven-plugin </artifactId> <version> 2.0 </version> <executions> <execution> <id> redg-generate </id> <phase> generate-test-sources </phase> <goals> <goal> redg </goal> </goals> <configuration> <!-- RedG configuration goes here --> </configuration> </execution> </executions> <dependencies> <!-- JDBC driver and SchemaCrawler plugin, only if not using H2. Entry depends on DBMS --> </dependencies> </plugin> Configuration \u00b6 The following table lists all configuration options of the RedG Maven plugin. XML Tag Default value Explanation <connectionString> jdbc:h2:mem:redg;DB_CLOSE_DELAY=-1 The JDBC connection string for the database that will be analyzed. Uses a H2 in-memory database by default, so if you are using SQL-Scripts, you can omit the connection paramters most of the time. <username> The username for the database. Can be left unchanged if used with the default connection string. <password> The password for the database user. Can be left unchanged if used with the default connection string. <jdbcDriver> org.h2.Driver The JDBC driver. A Maven dependency providing this class has to be specified if you are not using H2. <sqlScripts> A file array with SQL scripts that should be executed before the database analysis. These scripts can be used to create the schema when you are using an in-memory H2 database. <schemaRegex> .* A regular expression to select all database schemas that will be included in the database analysis. <tablesRegex> .* A regular expression to select all the tables that will be included in the database analysis. If a table is excluded because it belongs to an exlcuded schema, it will not be included again. <outputDirectory> target/generated-test-sources/redg The output folder for the generated source code. Default value is Maven standard. <targetPackage> com.btc.redg.generated The java package of the to-be-generated entity classes. <classPrefix> G A prefix string that gets prepended to each entity class. <allowPrimitiveTypes> false By default RedG replaces primitive types with their wrapper classes ( int to Integer , etc.). Set to true to disable this behavior. <enableVisualizationSupport> false If true , the generated code will support visualization of the object graph <customTypeMappings> A JSON or XML file with custom type mappings. See here for an explanation and an example code. <customNameMappings> A JSON file that defines custom name mappings. See here for an explanation and an example JSON code. <explicitAttributesConfig> A JSON file that defines explicit attributes and foreign keys. See here for an explanation and an example JSON code. <convenienceSetterConfig> A XML file that defines convenience setter methods. See here for an explanation and an example XML code. <jpaProviderConfig> The configuration for the JPA meta-model analysis. See here for an explanation of this feature and example XML. When running maven from the shell, you can use the follwing command line properties to override some configuration values: XML Tag CMD property <connectionString> redg.connectionString <username> redg.username <password> redg.password <jdbcDriver> redg.jdbcDriver <enableVisualizationSupport> redg.enableVisualization","title":"Maven plugin"},{"location":"integration/maven_plugin/#redg-maven-plugin","text":"The RedG Maven plugin offers comfortable and easy integration of the RedG code generation into your Maven project. It is configurable via Maven properties and JSON files. While the Maven plugin is pretty flexible, RedG can be configured even further if you use the code generator API directly. If you need absolute control, check out the docs for the code generator API .","title":"RedG Maven plugin"},{"location":"integration/maven_plugin/#usage","text":"Simply add the RedG plugin into your <plugins> section of your pom.xml . You may choose your own <id> , but the <phase> should stay at generate-test-sources in most cases. Now add your configuration in the <configuration> part and, if necessary, specify a dependency to your JDBC driver. If you use a different RDBMS than H2 you need an extra dependency to the SchemaCrawler plugin for your DBMS. The list of the most commonly needed plugins (for full list, see in Maven Central ): DBMS Necessary dependency Oracle us.fatehi:schemacrawler-oracle:15.01.06 IBM DB2 us.fatehi:schemacrawler-db2:15.01.06 MS SQL Server us.fatehi:schemacrawler-sqlserver:15.01.06 MySQL us.fatehi:schemacrawler-mysql:15.01.06 PostgreSQL us.fatehi:schemacrawler-postgresql:15.01.06 <plugin> <groupId> com.btc-ag.redg </groupId> <artifactId> redg-maven-plugin </artifactId> <version> 2.0 </version> <executions> <execution> <id> redg-generate </id> <phase> generate-test-sources </phase> <goals> <goal> redg </goal> </goals> <configuration> <!-- RedG configuration goes here --> </configuration> </execution> </executions> <dependencies> <!-- JDBC driver and SchemaCrawler plugin, only if not using H2. Entry depends on DBMS --> </dependencies> </plugin>","title":"Usage"},{"location":"integration/maven_plugin/#configuration","text":"The following table lists all configuration options of the RedG Maven plugin. XML Tag Default value Explanation <connectionString> jdbc:h2:mem:redg;DB_CLOSE_DELAY=-1 The JDBC connection string for the database that will be analyzed. Uses a H2 in-memory database by default, so if you are using SQL-Scripts, you can omit the connection paramters most of the time. <username> The username for the database. Can be left unchanged if used with the default connection string. <password> The password for the database user. Can be left unchanged if used with the default connection string. <jdbcDriver> org.h2.Driver The JDBC driver. A Maven dependency providing this class has to be specified if you are not using H2. <sqlScripts> A file array with SQL scripts that should be executed before the database analysis. These scripts can be used to create the schema when you are using an in-memory H2 database. <schemaRegex> .* A regular expression to select all database schemas that will be included in the database analysis. <tablesRegex> .* A regular expression to select all the tables that will be included in the database analysis. If a table is excluded because it belongs to an exlcuded schema, it will not be included again. <outputDirectory> target/generated-test-sources/redg The output folder for the generated source code. Default value is Maven standard. <targetPackage> com.btc.redg.generated The java package of the to-be-generated entity classes. <classPrefix> G A prefix string that gets prepended to each entity class. <allowPrimitiveTypes> false By default RedG replaces primitive types with their wrapper classes ( int to Integer , etc.). Set to true to disable this behavior. <enableVisualizationSupport> false If true , the generated code will support visualization of the object graph <customTypeMappings> A JSON or XML file with custom type mappings. See here for an explanation and an example code. <customNameMappings> A JSON file that defines custom name mappings. See here for an explanation and an example JSON code. <explicitAttributesConfig> A JSON file that defines explicit attributes and foreign keys. See here for an explanation and an example JSON code. <convenienceSetterConfig> A XML file that defines convenience setter methods. See here for an explanation and an example XML code. <jpaProviderConfig> The configuration for the JPA meta-model analysis. See here for an explanation of this feature and example XML. When running maven from the shell, you can use the follwing command line properties to override some configuration values: XML Tag CMD property <connectionString> redg.connectionString <username> redg.username <password> redg.password <jdbcDriver> redg.jdbcDriver <enableVisualizationSupport> redg.enableVisualization","title":"Configuration"},{"location":"integration/runtime_api/","text":"RedG runtime API \u00b6 The most bare-bone approach to inserting data with RedG ist the runtime API. Using it directly is the most flexible way and does not require any extra dependencies. The runtime API can be used to either insert the data set via PreparedStatements into a database using a JDBc Connection . generate SQL INSERT statements that can be used with some other tool (Oracle SqlDeveloper, JetBrains DataGrip, MySQL Workbench, etc.). Using PreparedStatements \u00b6 To insert the of a RedG instance into a database, call the insertDataIntoDatabase() method and provide a JDBC connection. Note You might need to use a custom PreparedStatement parameter setter for special data types. Generating SQL statements \u00b6 To generate SQL INSERT statements for your test data, call the generateSQLStatements method on your RedG object. It will return a List<String> with each String being a complete SQL INSERT statement. The list is ordered so that no foreign key constraints are violated, so preserve this order. When exporting the statements into an SQL file you have to append a semicolon to each statement. Note You might need to use a custom SQL values formatter for special data types. Example code for export: List < String > list = redG . generateSQLStatements (); String sqlScript = sql . stream (). collect ( Collectors . joining ( \";\\n\" )); // do whatever you want with sqlScript","title":"Runtime API"},{"location":"integration/runtime_api/#redg-runtime-api","text":"The most bare-bone approach to inserting data with RedG ist the runtime API. Using it directly is the most flexible way and does not require any extra dependencies. The runtime API can be used to either insert the data set via PreparedStatements into a database using a JDBc Connection . generate SQL INSERT statements that can be used with some other tool (Oracle SqlDeveloper, JetBrains DataGrip, MySQL Workbench, etc.).","title":"RedG runtime API"},{"location":"integration/runtime_api/#using-preparedstatements","text":"To insert the of a RedG instance into a database, call the insertDataIntoDatabase() method and provide a JDBC connection. Note You might need to use a custom PreparedStatement parameter setter for special data types.","title":"Using PreparedStatements"},{"location":"integration/runtime_api/#generating-sql-statements","text":"To generate SQL INSERT statements for your test data, call the generateSQLStatements method on your RedG object. It will return a List<String> with each String being a complete SQL INSERT statement. The list is ordered so that no foreign key constraints are violated, so preserve this order. When exporting the statements into an SQL file you have to append a semicolon to each statement. Note You might need to use a custom SQL values formatter for special data types. Example code for export: List < String > list = redG . generateSQLStatements (); String sqlScript = sql . stream (). collect ( Collectors . joining ( \";\\n\" )); // do whatever you want with sqlScript","title":"Generating SQL statements"}]}