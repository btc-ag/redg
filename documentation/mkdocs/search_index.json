{
    "docs": [
        {
            "location": "/",
            "text": "RedG User Documentation\n\u00b6\n\n\nThis is the user documentation for \"RedG\" (Ridiculously easy data Generation), a framework that\nsimplifies and revolutionizes test data generation.\nIf you are looking for the Javadoc, see \nhere\n.\n\n\nOverview\n\u00b6\n\n\nTake a look at our \nlanding page\n for a quick overview. \n\n\nQuick start\n\u00b6\n\n\nSee \nhere\n for a quick guide on how to setup RedG and integrate it into a Maven project.\n\n\nSee \nhere\n for other ways of integration RedG into your workflow.\n\n\nRead up on \nhow to specify your test data\n with RedG.",
            "title": "Home"
        },
        {
            "location": "/#redg-user-documentation",
            "text": "This is the user documentation for \"RedG\" (Ridiculously easy data Generation), a framework that\nsimplifies and revolutionizes test data generation.\nIf you are looking for the Javadoc, see  here .",
            "title": "RedG User Documentation"
        },
        {
            "location": "/#overview",
            "text": "Take a look at our  landing page  for a quick overview.",
            "title": "Overview"
        },
        {
            "location": "/#quick-start",
            "text": "See  here  for a quick guide on how to setup RedG and integrate it into a Maven project.  See  here  for other ways of integration RedG into your workflow.  Read up on  how to specify your test data  with RedG.",
            "title": "Quick start"
        },
        {
            "location": "/getting_started/",
            "text": "Getting started\n\u00b6\n\n\nThis chapter will guide you through your first project with RedG. You'll use RedG via the \nRedG Maven Plugin\n and integrate it into a JUnit unit test.\nIf you don't use Maven or JUnit, take a look at the chapter \nIntegration\n and choose the appropriate integration for your project.\n\n\nInstallation and configuration\n\u00b6\n\n\nIf your project can process Maven artifacts, the installation is quite straightforward. \nRedG will soon be available in Maven Central. For now you have to build it yourself\n.\n\n\nMaven\n\u00b6\n\n\nAdd the dependency for the \nredg-runtime\n. If you want to use the visualization feature to debug your application, include \njackson-core\n and \njackson-databind\n.\nInclude \njunit\n for the unit tests.\n\n\n<dependencies>\n\n    \n<dependency>\n\n        \n<groupId>\ncom.btc-ag.redg\n</groupId>\n\n        \n<artifactId>\nredg-runtime\n</artifactId>\n\n        \n<version>\n1.0.15\n</version>\n\n        \n<scope>\ntest\n</scope>\n\n    \n</dependency>\n\n    \n<!-- optional, for visualization only -->\n\n    \n<dependency>\n\n        \n<groupId>\ncom.fasterxml.jackson.core\n</groupId>\n\n        \n<artifactId>\njackson-core\n</artifactId>\n\n        \n<version>\n2.8.5\n</version>\n\n        \n<scope>\ntest\n</scope>\n\n    \n</dependency>\n\n    \n<dependency>\n\n        \n<groupId>\ncom.fasterxml.jackson.core\n</groupId>\n\n        \n<artifactId>\njackson-databind\n</artifactId>\n\n        \n<version>\n2.8.5\n</version>\n\n        \n<scope>\ntest\n</scope>\n\n    \n</dependency>\n\n    \n<!-- for the unit tests -->\n\n    \n<dependency>\n\n        \n<groupId>\njunit\n</groupId>\n\n        \n<artifactId>\njunit\n</artifactId>\n\n        \n<version>\n4.11\n</version>\n\n        \n<scope>\ntest\n</scope>\n\n    \n</dependency>\n\n\n</dependencies>\n\n\n\n\n\n\nNow include the RedG Maven Plugin (\nredg-maven-plugin\n) and configure it. You might also need a JDBC driver if you want the schema analysis to run against a database other than H2. This driver needs to be added as a \nplugin dependency\n, not as a project dependency.\n\n\n<plugin>\n\n    \n<groupId>\ncom.btc-ag.redg\n</groupId>\n\n    \n<artifactId>\nredg-maven-plugin\n</artifactId>\n\n    \n<version>\n1.0.15\n</version>\n\n    \n<executions>\n\n        \n<execution>\n\n            \n<id>\nredg-generate\n</id>\n\n            \n<phase>\ngenerate-test-sources\n</phase>\n \n<!-- This plugin generates sources for the test code -->\n\n            \n<goals>\n\n                \n<goal>\nredg\n</goal>\n\n            \n</goals>\n\n            \n<configuration>\n\n                \n<!-- Provide database connection information. We'll just use a H2 in-memory database here -->\n\n                \n<jdbcDriver>\norg.h2.Driver\n</jdbcDriver>\n\n                \n<connectionString>\njdbc:h2:mem:redg\n</connectionString>\n\n                \n<username>\nsa\n</username>\n\n                \n<password>\nsa\n</password>\n\n                \n<!-- Alternative Oracle configuration:\n\n\n                <jdbcDriver>oracle.jdbc.OracleDriver</jdbcDriver>\n\n\n                <connectionString>jdbc:oracle:thin:@localhost:1521:XE</connectionString>\n\n\n                <username>system</username>\n\n\n                <password>******</password>\n\n\n                -->\n\n                \n<enableVisualizationSupport>\ntrue\n</enableVisualizationSupport>\n \n<!-- if true, needs jackson dependencies -->\n\n                \n<sqlScripts>\n \n<!-- the SQL scripts to run before schema analysis -->\n\n                    \n<param>\nsrc/test/resources/create-schema.sql\n</param>\n\n                \n</sqlScripts>\n\n                \n<customTypeMappings>\nsrc/test/resources/mappings.json\n</customTypeMappings>\n \n<!-- type mappings. Will be explained later -->\n\n                \n<schemaRegex>\nREDG\n</schemaRegex>\n\n            \n</configuration>\n\n        \n</execution>\n\n    \n</executions>\n\n    \n<dependencies>\n\n        \n<!-- JDBC driver and SchemaCrawler extension, only if not using H2. Entry depends on DBMS -->\n\n        \n<!-- Example for Oracle DB:\n\n\n        <dependency>\n\n\n            <groupId>com.oracle</groupId>\n\n\n            <artifactId>ojdbc6</artifactId>\n\n\n            <version>11.2.0.3</version>\n\n\n        </dependency>\n\n\n        <dependency>\n\n\n            <groupId>us.fatehi</groupId>\n\n\n            <artifactId>schemacrawler-oracle</artifactId>\n\n\n            <version>14.16.01</version>\n\n\n        </dependency>\n\n\n        -->\n\n    \n</dependencies>\n\n\n</plugin>\n\n\n\n\n\n\nThis is a minimal configuration for the Maven plugin. RedG will use an in-memory H2 database named \nredg\n. Before schema analysis the \ncreate-schema.sql\n script will be executed. This script will create the complete database schema. The plugin will analyze all tables within the \nREDG\n schema and generate code for these. \n\n\nThe generated source code will have visualization support, so you can easily debug and visualize your test data.\n\n\nTo show how the generated code can be customized, a custom type mapping is provided via a JSON file called \nmappings.json\n.\n\n\nFor a detailed explanation of all parameters head over to \nhere\n.\n\n\nContinue \nwith the preparation\n after you're done here.\n\n\nGradle\n\u00b6\n\n\nCurrently there is no Gradle plugin to generate the RedG entity code. See \nhere\n for other ways to integrate the RedG code generator in your project.\n\n\nThe RedG runtime can be included as a dependency.\n\n\ndependencies\n \n{\n\n    \ntestCompile\n \ngroup:\n \n'com.btc-ag.redg'\n,\n \nname:\n \n'redg-runtime'\n,\n \nversion\n \n'1.0.15'\n\n\n    \n// optional, only for visualization support\n\n    \ntestCompile\n \ngroup:\n \n'com.fasterxml.jackson.core'\n,\n \nname:\n \n'jackson-core'\n,\n \nversion:\n \n'2.8.5'\n\n    \ntestCompile\n \ngroup:\n \n'com.fasterxml.jackson.core'\n,\n \nname:\n \n'jackson-databind'\n,\n \nversion:\n \n'2.8.5'\n\n\n    \n// testing framework\n\n    \ntestCompile\n \ngroup:\n \n'junit'\n,\n \nname:\n \n'junit'\n,\n \nversion:\n \n'4.11'\n\n\n\n}\n\n\n\n\n\n\nPreparation\n\u00b6\n\n\nWith RedG installed and set up, you can now prepare everything for the first code generation. If you followed the steps above, you'll need two more files before RedG can generate code for your database schema: \nsrc/test/resources/create-schema.sql\n and \nsrc/test/resources/mappings.json\n.\n\n\nSQL preparation script\n\u00b6\n\n\nIn order to generate the code for the schema, RedG needs a live database running that schema. As this example uses a H2 in-memory database, all the tables have to be created first. Create the file \nsrc/test/resources/create-schema.sql\n and fill it with your DDL statements.\n\n\nIf you don't yet have a database schema or just want to tets RedG, feel free to use this little demo schema:\n\n\nCREATE\n \nSCHEMA\n \nREDG\n;\n\n\n\nCREATE\n \nTABLE\n \nREDG\n.\nDEMO_BANK_ACCOUNT\n \n(\n\n  \nBIC\n  \nVARCHAR2\n(\n11\n \nCHAR\n)\n \nNOT\n \nNULL\n,\n\n  \nIBAN\n \nVARCHAR2\n(\n22\n \nCHAR\n)\n \nNOT\n \nNULL\n,\n\n\n  \nCONSTRAINT\n \npk_DEMO_BANK_ACCOUNT\n \nPRIMARY\n \nKEY\n \n(\nBIC\n,\n \nIBAN\n)\n\n\n);\n\n\n\nCREATE\n \nTABLE\n \nREDG\n.\nDEMO_COMPANY\n \n(\n\n  \nCOUNTRY_CODE\n      \nVARCHAR2\n(\n2\n \nCHAR\n)\n  \nNOT\n \nNULL\n,\n\n  \nNAME\n              \nVARCHAR2\n(\n30\n \nCHAR\n)\n \nNOT\n \nNULL\n,\n\n  \nREGISTRATION_DATE\n \nTIMESTAMP\n,\n\n  \nACC_BIC\n           \nVARCHAR2\n(\n11\n \nCHAR\n)\n \nNOT\n \nNULL\n,\n\n  \nACC_IBAN\n          \nVARCHAR2\n(\n22\n \nCHAR\n)\n \nNOT\n \nNULL\n,\n\n\n  \nCONSTRAINT\n \nPK_DEMO_COMPANY\n \nPRIMARY\n \nKEY\n \n(\nCOUNTRY_CODE\n,\n \nNAME\n),\n\n  \nCONSTRAINT\n \nFK_DEMO_COMPANY_BANK_ACC\n \nFOREIGN\n \nKEY\n \n(\nACC_BIC\n,\n \nACC_IBAN\n)\n \nREFERENCES\n \nDEMO_BANK_ACCOUNT\n \n(\nBIC\n,\n \nIBAN\n)\n\n\n);\n\n\n\nCREATE\n \nTABLE\n \nREDG\n.\nDEMO_USER\n \n(\n\n  \nID\n            \nNUMBER\n(\n19\n)\n        \nNOT\n \nNULL\n,\n\n  \nUSERNAME\n      \nVARCHAR2\n(\n30\n \nCHAR\n)\n \nNOT\n \nNULL\n,\n\n  \nFIRST_NAME\n    \nVARCHAR2\n(\n50\n \nCHAR\n),\n\n  \nLAST_NAME\n     \nVARCHAR2\n(\n50\n \nCHAR\n),\n\n  \nWORKS_AT_CC\n   \nVARCHAR2\n(\n2\n \nCHAR\n),\n\n  \nWORKS_AT_NAME\n \nVARCHAR2\n(\n30\n \nCHAR\n),\n\n  \nACC_BIC\n       \nVARCHAR2\n(\n11\n \nCHAR\n)\n \nNOT\n \nNULL\n,\n\n  \nACC_IBAN\n      \nVARCHAR2\n(\n22\n \nCHAR\n)\n \nNOT\n \nNULL\n,\n\n  \nAGREED_TO_NEWSLETTER\n \nNUMBER\n(\n1\n),\n\n\n  \nCONSTRAINT\n \npk_DEMO_USER\n \nPRIMARY\n \nKEY\n \n(\nID\n),\n\n  \nCONSTRAINT\n \nfk_DEMO_USER_COMPANY\n \nFOREIGN\n \nKEY\n \n(\nWORKS_AT_CC\n,\n \nWORKS_AT_NAME\n)\n \nREFERENCES\n \nDEMO_COMPANY\n \n(\nCOUNTRY_CODE\n,\n \nNAME\n),\n\n  \nCONSTRAINT\n \nfk_DEMO_USER_BANK_ACC\n \nFOREIGN\n \nKEY\n \n(\nACC_BIC\n,\n \nACC_IBAN\n)\n \nREFERENCES\n \nDEMO_BANK_ACCOUNT\n \n(\nBIC\n,\n \nIBAN\n)\n\n\n);\n\n\n\n\n\n\nThis SQL code will create a schema that looks like this:\n\n\n\nThe demo schema\n\n\nType mappings\n\u00b6\n\n\nWhen analysing a database schema, RedG always tries to find an appropriate Java data type for a column. There are three cases, where this might not be enough:\n\n\n\n\nYou want a different Java data type that still represents the same database data type (eg. \nlong\n instead of \nBigDecimal\n for \nNUMBER(10)\n)\n\n\nRedG cannot understand the semantic meaning of a column data type (eg. \nNUMBER(1)\n or \nCHAR(1)\n for \nboolean\n)\n\n\nYou want to plug in a custom, maybe even far more complex, data type and use it instead of the default types\n\n\n\n\nIf this happens, you can create a custom type mapping. When using the Maven plugin, you can simply specify that type mapping in a JSON file. For the demo schema from above you can use the following type mapping and save it in the file \nsrc/test/resources/mappings.json\n:\n\n\n{\n\n  \n\"REDG.DEMO_USER\"\n:\n \n{\n\n    \n\"ID\"\n:\n \n\"Long\"\n,\n\n    \n\"AGREED_TO_NEWSLETTER\"\n:\n \n\"Boolean\"\n\n  \n},\n\n  \n\"REDG.DEMO_COMPANY\"\n:\n \n{\n\n    \n\"ID\"\n:\n \n\"Long\"\n,\n\n    \n\"REGISTRATION_DATE\"\n:\n \n\"java.time.LocalDateTime\"\n\n  \n}\n\n\n}\n\n\n\n\n\n\nIn this example, the \nDEMO_USER\n table gets its \nID\n mapped as a \nLong\n (always use wrapper classes, not primitive types) and \nAGREED_TO_NEWSLETTER\n as a \nBoolean\n. \nThe \nDEMO_COMPANY\n gets the same mapping for the \nID\n and gets the \nREGISTRATION_DATE\n as a \nLocalDateTime\n. For each class not in \njava.lang\n you have to provide the fully qualified class name.\n\n\nIf your JDBC driver is not able to perform the transformations you want (\nBoolean\n to \nNUMBER(1)\n or \nLocalDateTime\n to \nTIMESTAMP\n), you have to provide a custom \nPreparedStatementParameterSetter\n during test runtime. If you want to generate SQL statements, you might need a custom \nSQLValuesFormatter\n during test runtime.\n\n\nCode generation\n\u00b6\n\n\nBy now everything is ready for the first round of code generation. If you are using Maven, either run your whole test-suite with \nmvn test\n or just RedG with \nmvn redg:redg@redg-generate\n. If you are using Gradle, run your custom solution or wait until the release of the Gradle plugin. If no error occured, you should find the generated sources in \ntarget/generated-test-sources/redg\n.\n\n\n\n\nThe generated code\n\n\nTest data specification\n\u00b6\n\n\nNow that RedG has generated the entity classes, you can start to specify your test data. A good approach to specifying your test data in smaller projects is to create public methods in classes with a default constructor that return an \nAbstractRedG\n. Inside these methods you instantiate a \nRedG\n object, setup the default value providers, specify your data and return the filled \nRedG\n object.\n\n\nAn example for some test data:\n\n\nimport\n \ncom.btc.redg.generated.*\n;\n\n\nimport\n \ncom.btc.redg.runtime.defaultvalues.pluggable.*\n;\n\n\nimport\n \ncom.btc.redg.runtime.AbstractRedG\n;\n\n\n\npublic\n \nclass\n \nDemoTestData\n \n{\n\n\n    \npublic\n \nAbstractRedG\n \ngetDataSet\n()\n \n{\n\n\n        \nPluggableDefaultValueStrategy\n \nstrategy\n \n=\n \nnew\n \nPluggableDefaultValueStrategy\n.\nBuilder\n()\n\n            \n.\nuse\n(\nnew\n \nIncrementingNumberProvider\n())\n\n            \n.\nuse\n(\nnew\n \nCurrentDateProvider\n())\n\n            \n.\nuse\n(\nnew\n \nCostantStringProvider\n(\n\"Example\"\n));\n\n\n        \nRedG\n \nredG\n \n=\n \nnew\n \nRedGBuilder\n<\nRedG\n>()\n\n            \n.\nwithDefaultValueStrategy\n(\nstrategy\n)\n\n            \n.\nbuild\n();\n\n\n        \nGDemoBankAccount\n \ncompanyBankAccount\n \n=\n \nredG\n.\naddDemoBankAccount\n()\n\n                \n.\nbic\n(\n\"ONEPIZZAPLZ\"\n)\n\n                \n.\niban\n(\n\"DE13109817441665870952\"\n);\n\n        \nGDemoBankAccount\n \nuserBankAccount\n \n=\n \nredG\n.\naddDemoBankAccount\n()\n\n                \n.\nbic\n(\n\"THEREYOUGO1\"\n)\n\n                \n.\niban\n(\n\"DE55617403662248482423\"\n);\n\n        \nGDemoCompany\n \nsmallCompany\n \n=\n \nredG\n.\naddDemoCompany\n(\ncompanyBankAccount\n)\n\n                \n.\ncountryCode\n(\n\"DE\"\n)\n\n                \n.\nname\n(\n\"Spielwarenfachgesch\u00e4ft M\u00fcller\"\n);\n\n        \nIntStream\n.\nrangeClosed\n(\n1\n,\n \n5\n).\nforEach\n(\ni\n \n->\n \n{\n\n            \nredG\n.\naddDemoUser\n(\nuserBankAccount\n)\n\n                    \n.\nusername\n(\n\"user\"\n \n+\n \ni\n)\n\n                    \n.\ncompany\n(\nsmallCompany\n);\n\n        \n});\n\n        \nGDemoCompany\n \ndummy\n \n=\n \nredG\n.\ndummyDemoCompany\n();\n\n        \nredG\n.\naddDemoUser\n(\ndummy\n.\nbankAcc\n()).\nusername\n(\n\"Diana_Dummy\"\n).\ncompany\n(\ndummy\n);\n\n\n        \nreturn\n \nredG\n;\n\n    \n}\n\n\n}\n\n\n\n\n\n\nJUnit integration\n\u00b6\n\n\nThere are multiple ways to integrate your test data specification into your JUnit tests, but for this guide the most simple approach is\nrecommended. It is very simple and does not need further dependencies. Just call your test data specification method, open a JDBC connection and \ncall \nAbstractRedG.insertDataIntoDatabase(Connection)\n. In most cases this dead simple approach is all you need. \nIf you want to use RedG in a bigger project, consider some of the other \nintegration possibilities\n.\n\n\nExample:\n\n\nimport\n \n...\n;\n\n\n\npublic\n \nclass\n \nDemoTest\n \n{\n\n\n    \n@Test\n\n    \npublic\n \nvoid\n \ntestStuff\n()\n \nthrows\n \nException\n \n{\n\n        \nConnection\n \nconnection\n \n=\n \n...;\n\n        \nnew\n \nDemoTestData\n().\ngetDataSet\n().\ninsertDataIntoDatabase\n(\nconnection\n);\n\n\n        \n// perform your test\n\n    \n}\n\n\n\n}\n\n\n\n\n\n\nDebugging with the visualizer\n\u00b6\n\n\nIf your generated RedG entity classes have the visualization support enabled, debugging RedG is extremely\nsimple and comfortable. Add a breakpoint wherever you want to inspect the current RedG dataset and let the\ncode run until there. Once it reached the breakpoint, evaluate the \ngetVisualizationJson()\n method on your RedG\nmain object. This method will return a big JSON string. Copy it into your clipboard or export it into a file\nand paste/drag it into the \nRedG Visualizer\n.",
            "title": "Getting started"
        },
        {
            "location": "/getting_started/#getting-started",
            "text": "This chapter will guide you through your first project with RedG. You'll use RedG via the  RedG Maven Plugin  and integrate it into a JUnit unit test.\nIf you don't use Maven or JUnit, take a look at the chapter  Integration  and choose the appropriate integration for your project.",
            "title": "Getting started"
        },
        {
            "location": "/getting_started/#installation-and-configuration",
            "text": "If your project can process Maven artifacts, the installation is quite straightforward.  RedG will soon be available in Maven Central. For now you have to build it yourself .",
            "title": "Installation and configuration"
        },
        {
            "location": "/getting_started/#maven",
            "text": "Add the dependency for the  redg-runtime . If you want to use the visualization feature to debug your application, include  jackson-core  and  jackson-databind .\nInclude  junit  for the unit tests.  <dependencies> \n     <dependency> \n         <groupId> com.btc-ag.redg </groupId> \n         <artifactId> redg-runtime </artifactId> \n         <version> 1.0.15 </version> \n         <scope> test </scope> \n     </dependency> \n     <!-- optional, for visualization only --> \n     <dependency> \n         <groupId> com.fasterxml.jackson.core </groupId> \n         <artifactId> jackson-core </artifactId> \n         <version> 2.8.5 </version> \n         <scope> test </scope> \n     </dependency> \n     <dependency> \n         <groupId> com.fasterxml.jackson.core </groupId> \n         <artifactId> jackson-databind </artifactId> \n         <version> 2.8.5 </version> \n         <scope> test </scope> \n     </dependency> \n     <!-- for the unit tests --> \n     <dependency> \n         <groupId> junit </groupId> \n         <artifactId> junit </artifactId> \n         <version> 4.11 </version> \n         <scope> test </scope> \n     </dependency>  </dependencies>   Now include the RedG Maven Plugin ( redg-maven-plugin ) and configure it. You might also need a JDBC driver if you want the schema analysis to run against a database other than H2. This driver needs to be added as a  plugin dependency , not as a project dependency.  <plugin> \n     <groupId> com.btc-ag.redg </groupId> \n     <artifactId> redg-maven-plugin </artifactId> \n     <version> 1.0.15 </version> \n     <executions> \n         <execution> \n             <id> redg-generate </id> \n             <phase> generate-test-sources </phase>   <!-- This plugin generates sources for the test code --> \n             <goals> \n                 <goal> redg </goal> \n             </goals> \n             <configuration> \n                 <!-- Provide database connection information. We'll just use a H2 in-memory database here --> \n                 <jdbcDriver> org.h2.Driver </jdbcDriver> \n                 <connectionString> jdbc:h2:mem:redg </connectionString> \n                 <username> sa </username> \n                 <password> sa </password> \n                 <!-- Alternative Oracle configuration:                  <jdbcDriver>oracle.jdbc.OracleDriver</jdbcDriver>                  <connectionString>jdbc:oracle:thin:@localhost:1521:XE</connectionString>                  <username>system</username>                  <password>******</password>                  --> \n                 <enableVisualizationSupport> true </enableVisualizationSupport>   <!-- if true, needs jackson dependencies --> \n                 <sqlScripts>   <!-- the SQL scripts to run before schema analysis --> \n                     <param> src/test/resources/create-schema.sql </param> \n                 </sqlScripts> \n                 <customTypeMappings> src/test/resources/mappings.json </customTypeMappings>   <!-- type mappings. Will be explained later --> \n                 <schemaRegex> REDG </schemaRegex> \n             </configuration> \n         </execution> \n     </executions> \n     <dependencies> \n         <!-- JDBC driver and SchemaCrawler extension, only if not using H2. Entry depends on DBMS --> \n         <!-- Example for Oracle DB:          <dependency>              <groupId>com.oracle</groupId>              <artifactId>ojdbc6</artifactId>              <version>11.2.0.3</version>          </dependency>          <dependency>              <groupId>us.fatehi</groupId>              <artifactId>schemacrawler-oracle</artifactId>              <version>14.16.01</version>          </dependency>          --> \n     </dependencies>  </plugin>   This is a minimal configuration for the Maven plugin. RedG will use an in-memory H2 database named  redg . Before schema analysis the  create-schema.sql  script will be executed. This script will create the complete database schema. The plugin will analyze all tables within the  REDG  schema and generate code for these.   The generated source code will have visualization support, so you can easily debug and visualize your test data.  To show how the generated code can be customized, a custom type mapping is provided via a JSON file called  mappings.json .  For a detailed explanation of all parameters head over to  here .  Continue  with the preparation  after you're done here.",
            "title": "Maven"
        },
        {
            "location": "/getting_started/#gradle",
            "text": "Currently there is no Gradle plugin to generate the RedG entity code. See  here  for other ways to integrate the RedG code generator in your project.  The RedG runtime can be included as a dependency.  dependencies   { \n     testCompile   group:   'com.btc-ag.redg' ,   name:   'redg-runtime' ,   version   '1.0.15' \n\n     // optional, only for visualization support \n     testCompile   group:   'com.fasterxml.jackson.core' ,   name:   'jackson-core' ,   version:   '2.8.5' \n     testCompile   group:   'com.fasterxml.jackson.core' ,   name:   'jackson-databind' ,   version:   '2.8.5' \n\n     // testing framework \n     testCompile   group:   'junit' ,   name:   'junit' ,   version:   '4.11'  }",
            "title": "Gradle"
        },
        {
            "location": "/getting_started/#preparation",
            "text": "With RedG installed and set up, you can now prepare everything for the first code generation. If you followed the steps above, you'll need two more files before RedG can generate code for your database schema:  src/test/resources/create-schema.sql  and  src/test/resources/mappings.json .",
            "title": "Preparation"
        },
        {
            "location": "/getting_started/#sql-preparation-script",
            "text": "In order to generate the code for the schema, RedG needs a live database running that schema. As this example uses a H2 in-memory database, all the tables have to be created first. Create the file  src/test/resources/create-schema.sql  and fill it with your DDL statements.  If you don't yet have a database schema or just want to tets RedG, feel free to use this little demo schema:  CREATE   SCHEMA   REDG ;  CREATE   TABLE   REDG . DEMO_BANK_ACCOUNT   ( \n   BIC    VARCHAR2 ( 11   CHAR )   NOT   NULL , \n   IBAN   VARCHAR2 ( 22   CHAR )   NOT   NULL , \n\n   CONSTRAINT   pk_DEMO_BANK_ACCOUNT   PRIMARY   KEY   ( BIC ,   IBAN )  );  CREATE   TABLE   REDG . DEMO_COMPANY   ( \n   COUNTRY_CODE        VARCHAR2 ( 2   CHAR )    NOT   NULL , \n   NAME                VARCHAR2 ( 30   CHAR )   NOT   NULL , \n   REGISTRATION_DATE   TIMESTAMP , \n   ACC_BIC             VARCHAR2 ( 11   CHAR )   NOT   NULL , \n   ACC_IBAN            VARCHAR2 ( 22   CHAR )   NOT   NULL , \n\n   CONSTRAINT   PK_DEMO_COMPANY   PRIMARY   KEY   ( COUNTRY_CODE ,   NAME ), \n   CONSTRAINT   FK_DEMO_COMPANY_BANK_ACC   FOREIGN   KEY   ( ACC_BIC ,   ACC_IBAN )   REFERENCES   DEMO_BANK_ACCOUNT   ( BIC ,   IBAN )  );  CREATE   TABLE   REDG . DEMO_USER   ( \n   ID              NUMBER ( 19 )          NOT   NULL , \n   USERNAME        VARCHAR2 ( 30   CHAR )   NOT   NULL , \n   FIRST_NAME      VARCHAR2 ( 50   CHAR ), \n   LAST_NAME       VARCHAR2 ( 50   CHAR ), \n   WORKS_AT_CC     VARCHAR2 ( 2   CHAR ), \n   WORKS_AT_NAME   VARCHAR2 ( 30   CHAR ), \n   ACC_BIC         VARCHAR2 ( 11   CHAR )   NOT   NULL , \n   ACC_IBAN        VARCHAR2 ( 22   CHAR )   NOT   NULL , \n   AGREED_TO_NEWSLETTER   NUMBER ( 1 ), \n\n   CONSTRAINT   pk_DEMO_USER   PRIMARY   KEY   ( ID ), \n   CONSTRAINT   fk_DEMO_USER_COMPANY   FOREIGN   KEY   ( WORKS_AT_CC ,   WORKS_AT_NAME )   REFERENCES   DEMO_COMPANY   ( COUNTRY_CODE ,   NAME ), \n   CONSTRAINT   fk_DEMO_USER_BANK_ACC   FOREIGN   KEY   ( ACC_BIC ,   ACC_IBAN )   REFERENCES   DEMO_BANK_ACCOUNT   ( BIC ,   IBAN )  );   This SQL code will create a schema that looks like this:  The demo schema",
            "title": "SQL preparation script"
        },
        {
            "location": "/getting_started/#type-mappings",
            "text": "When analysing a database schema, RedG always tries to find an appropriate Java data type for a column. There are three cases, where this might not be enough:   You want a different Java data type that still represents the same database data type (eg.  long  instead of  BigDecimal  for  NUMBER(10) )  RedG cannot understand the semantic meaning of a column data type (eg.  NUMBER(1)  or  CHAR(1)  for  boolean )  You want to plug in a custom, maybe even far more complex, data type and use it instead of the default types   If this happens, you can create a custom type mapping. When using the Maven plugin, you can simply specify that type mapping in a JSON file. For the demo schema from above you can use the following type mapping and save it in the file  src/test/resources/mappings.json :  { \n   \"REDG.DEMO_USER\" :   { \n     \"ID\" :   \"Long\" , \n     \"AGREED_TO_NEWSLETTER\" :   \"Boolean\" \n   }, \n   \"REDG.DEMO_COMPANY\" :   { \n     \"ID\" :   \"Long\" , \n     \"REGISTRATION_DATE\" :   \"java.time.LocalDateTime\" \n   }  }   In this example, the  DEMO_USER  table gets its  ID  mapped as a  Long  (always use wrapper classes, not primitive types) and  AGREED_TO_NEWSLETTER  as a  Boolean . \nThe  DEMO_COMPANY  gets the same mapping for the  ID  and gets the  REGISTRATION_DATE  as a  LocalDateTime . For each class not in  java.lang  you have to provide the fully qualified class name.  If your JDBC driver is not able to perform the transformations you want ( Boolean  to  NUMBER(1)  or  LocalDateTime  to  TIMESTAMP ), you have to provide a custom  PreparedStatementParameterSetter  during test runtime. If you want to generate SQL statements, you might need a custom  SQLValuesFormatter  during test runtime.",
            "title": "Type mappings"
        },
        {
            "location": "/getting_started/#code-generation",
            "text": "By now everything is ready for the first round of code generation. If you are using Maven, either run your whole test-suite with  mvn test  or just RedG with  mvn redg:redg@redg-generate . If you are using Gradle, run your custom solution or wait until the release of the Gradle plugin. If no error occured, you should find the generated sources in  target/generated-test-sources/redg .   The generated code",
            "title": "Code generation"
        },
        {
            "location": "/getting_started/#test-data-specification",
            "text": "Now that RedG has generated the entity classes, you can start to specify your test data. A good approach to specifying your test data in smaller projects is to create public methods in classes with a default constructor that return an  AbstractRedG . Inside these methods you instantiate a  RedG  object, setup the default value providers, specify your data and return the filled  RedG  object.  An example for some test data:  import   com.btc.redg.generated.* ;  import   com.btc.redg.runtime.defaultvalues.pluggable.* ;  import   com.btc.redg.runtime.AbstractRedG ;  public   class   DemoTestData   { \n\n     public   AbstractRedG   getDataSet ()   { \n\n         PluggableDefaultValueStrategy   strategy   =   new   PluggableDefaultValueStrategy . Builder () \n             . use ( new   IncrementingNumberProvider ()) \n             . use ( new   CurrentDateProvider ()) \n             . use ( new   CostantStringProvider ( \"Example\" )); \n\n         RedG   redG   =   new   RedGBuilder < RedG >() \n             . withDefaultValueStrategy ( strategy ) \n             . build (); \n\n         GDemoBankAccount   companyBankAccount   =   redG . addDemoBankAccount () \n                 . bic ( \"ONEPIZZAPLZ\" ) \n                 . iban ( \"DE13109817441665870952\" ); \n         GDemoBankAccount   userBankAccount   =   redG . addDemoBankAccount () \n                 . bic ( \"THEREYOUGO1\" ) \n                 . iban ( \"DE55617403662248482423\" ); \n         GDemoCompany   smallCompany   =   redG . addDemoCompany ( companyBankAccount ) \n                 . countryCode ( \"DE\" ) \n                 . name ( \"Spielwarenfachgesch\u00e4ft M\u00fcller\" ); \n         IntStream . rangeClosed ( 1 ,   5 ). forEach ( i   ->   { \n             redG . addDemoUser ( userBankAccount ) \n                     . username ( \"user\"   +   i ) \n                     . company ( smallCompany ); \n         }); \n         GDemoCompany   dummy   =   redG . dummyDemoCompany (); \n         redG . addDemoUser ( dummy . bankAcc ()). username ( \"Diana_Dummy\" ). company ( dummy ); \n\n         return   redG ; \n     }  }",
            "title": "Test data specification"
        },
        {
            "location": "/getting_started/#junit-integration",
            "text": "There are multiple ways to integrate your test data specification into your JUnit tests, but for this guide the most simple approach is\nrecommended. It is very simple and does not need further dependencies. Just call your test data specification method, open a JDBC connection and \ncall  AbstractRedG.insertDataIntoDatabase(Connection) . In most cases this dead simple approach is all you need. \nIf you want to use RedG in a bigger project, consider some of the other  integration possibilities .  Example:  import   ... ;  public   class   DemoTest   { \n\n     @Test \n     public   void   testStuff ()   throws   Exception   { \n         Connection   connection   =   ...; \n         new   DemoTestData (). getDataSet (). insertDataIntoDatabase ( connection ); \n\n         // perform your test \n     }  }",
            "title": "JUnit integration"
        },
        {
            "location": "/getting_started/#debugging-with-the-visualizer",
            "text": "If your generated RedG entity classes have the visualization support enabled, debugging RedG is extremely\nsimple and comfortable. Add a breakpoint wherever you want to inspect the current RedG dataset and let the\ncode run until there. Once it reached the breakpoint, evaluate the  getVisualizationJson()  method on your RedG\nmain object. This method will return a big JSON string. Copy it into your clipboard or export it into a file\nand paste/drag it into the  RedG Visualizer .",
            "title": "Debugging with the visualizer"
        },
        {
            "location": "/specifying_test_data/",
            "text": "Specifying test data\n\u00b6\n\n\nWith RedG you specify all your test data in pure Java code. And \"all your test data\" means \n\"only the data you \nreally\n need\". RedG takes care of all the other stuff (like not specified \nNOT NULL\n fields, required\nforeign key relations etc.).\n\n\nGeneral API design\n\u00b6\n\n\nThe entity classes RedG generates use a \nfluent interface\n with getters and\nsetters in \"JQuery style\" (no \nget\n/\nset\n prefix, calling without parameter gets the value, with parameter sets it).\n\n\nRedG  always generates a \"main class\" (or \"manager class\"). This is not an executable class containing a \n\npublic static void main(String[] args)\n, but the class you'll use to create and manage your RedG entities (and thus your\ntest data). This class is usually named \nRedG\n.\n\n\nUsing the RedG main class you can create entities. An entity is a java object that represents one row of data that will be\ninserted into a database (or already \nexists in the database\n). Usually you can use methods\nto change fields (\"columns\" in your database) on these entities.\n\n\nAdding an entity\n\u00b6\n\n\nTo create a new entity and add it to RedG's internal list of objects to insert call one of the \nadd...()\n methods\non a RedG object. Replace \n...\n with the name of the entity you want to add. If the entity has required fields (either\n\nNOT NULL\n foreign keys or columns / foreign keys marked as \nexplicit\n) \nyou'll need to pass them to the method. Passing a \nnull\n value will result in a \nNullPointerException\n.\n\n\nOnce you have created your entity you can use it's setters to set the values for the necessary fields.\n\n\nExample:\n\n\nRedG\n \nredG\n \n=\n \nnew\n \nRedG\n();\n\n\n// or when customizing many things, consider using the RedGBuilder class\n\n\n// RedG redG = new RedGBuilder<RedG>().build();\n\n\n\n// either \n\n\nGTeacher\n \nmathTeacher\n \n=\n \nredG\n.\naddTeacher\n()\n\n    \n.\nname\n(\n\"Leonhard Euler\"\n)\n\n    \n.\nage\n(\n310\n);\n\n\n\n// or just\n\n\nredG\n.\naddTeacher\n()\n\n    \n.\nname\n(\n\"Isaac Newton\"\n);\n\n\n\n// or even\n\n\nGTeacher\n \nchemistryTeacher\n \n=\n \nredG\n.\naddTeacher\n();\n\n\nchemistryTeacher\n\n    \n.\nname\n(\n\"Niels Bohr\"\n)\n\n    \n.\nhasNobelPrice\n(\ntrue\n)\n\n\n\n\n\n\nWhen you do not need an entity for further foreign key relations or data manipulation, there is no need to save it \nin a variable.\n\n\nAs you can see in the example, different fields are set for \nmathTeacher\n and \nchemistryTeacher\n although they are of the same \ntype and have the same columns. Even if \nage\n or \nhasNobelPrice\n would both be mandatory (\nNOT NULL\n) this code would\nstill work, as RedG generates default values for all fields that are not specified by the user.\n\n\nExample for entities with \nNOT NULL\n foreign key or explicit attributes:\n\n\n// name of school is an explicit attribute for demonstration purposes\n\n\nredG\n.\naddSchool\n(\n\"Time-traveling School with famous teachers\"\n)\n\n    \n.\nheadmaster\n(\neinstein\n);\n\n\n\n// Every class needs a teacher, so it is specified at creation time and may not be null\n\n\nGClass\n \nchemistryClass\n \n=\n \nredG\n.\naddClass\n(\nchemistryTeacher\n)\n\n    \n.\nname\n(\n\"Chemistry 101\"\n)\n\n    \n.\nmaxStudentCount\n(\n45\n)\n\n\n\n\n\n\nGenerating a dummy entity\n\u00b6\n\n\nThere are many scenarios where you need to test a specific entity but only need some or none of its dependencies.\nWith most other tools you would have to specify each and every dependency (and their dependencies and so on) and \nyou could wind up with far too much code/XML for just one entity.\n\n\nTo solve this problem RedG offers a dummy entity generator, that will generate a valid dummy entity for you. This entity\nwill have meaningless values but is still a valid entity that can be referenced wherever you want.\n\n\nTo stay in the educational environment with this example, imagine a test case where you need to test the \nSCHOOL_SUBJECT\n table\n(\nSchoolSubject\n entity name, \nGSchoolSubject\n entity class name). Every subjects needs a teacher. A teacher is a human\nwith a pay grade, a qualification and a school he graduated from (All of these have to be provided because of constraints \non the database). Every subjects needs one required textbook as well.\n\n\n// Without dummy entities and without the previously defined entities\n\n\n\nGSchool\n \nschool\n \n=\n \nredG\n.\naddSchool\n(\n\"Wherever Primary School\"\n);\n\n\nGHuman\n \nsomePerson\n \n=\n \nredG\n.\naddHuman\n();\n\n\nGTeacher\n \nsomeTeacher\n \n=\n \nredG\n.\naddTeacher\n(\nsomePerson\n,\n \nPaygrade\n.\nTEACHER\n,\n \n    \nQualifications\n.\nNONE\n,\n \nschool\n);\n\n\nGTextBook\n \ntextBook\n \n=\n \nredG\n.\naddTextBook\n();\n\n\n\nGSchoolSubject\n \naqm\n \n=\n \nredg\n.\naddSchoolSubject\n(\nsomeTeacher\n,\n \ntextBook\n)\n\n    \n.\nname\n(\n\"Advanced quantum mechanics\"\n)\n\n    \n.\nisCoreClass\n(\ntrue\n)\n\n    \n.\nroom\n(\n\"1.42\"\n);\n\n\n\n// with RedGs dummy generator\n\n\n\nGSchoolSubject\n \naqm\n \n=\n \nredG\n.\naddSchoolSubject\n(\n\n        \nredG\n.\ndummyTeacher\n(),\n\n        \nredG\n.\ndummyTextBook\n()\n\n\n)\n\n    \n.\nname\n(\n\"Advanced quantum mechanics\"\n)\n\n    \n.\nisCoreClass\n(\ntrue\n)\n\n    \n.\nroom\n(\n\"1.42\"\n);\n\n\n\n\n\n\nReferencing existing entities\n\u00b6\n\n\nDepending on your setup you might already have some data in your database before running RedG and need to reference\nthese data for a foreign key relation within RedG.\n\n\nRedG allows you to specify that a certain entity is already present in the database. When inserting you test data\nRedG will test that the specified entity is really already in the database.\n\n\nTo reference an existing entity, use the \nexisting...()\n methods of the RedG object. You have to pass\nthe full primary key as the arguments to these methods. If a table does not have primary keys, you cannot reference\nit.\n\n\nExample:\n\n\nGTeacher\n \neuklid\n \n=\n \nredG\n.\nexistingWizard\n(\n4\n);\n \n// 4 is value of primary id column\n\n\n\n// use euklid just like normal for references, just don't try to modify him or read values other the primary keys\n\n\n\n// trying to modify fields will throw an UnsupportedOperationException\n\n\neuklid\n.\nisDead\n(\nfalse\n);\n \n\n\nredG\n.\naddMemorialDay\n(\neuklid\n)\n \n// works just like expected",
            "title": "Specifying test data"
        },
        {
            "location": "/specifying_test_data/#specifying-test-data",
            "text": "With RedG you specify all your test data in pure Java code. And \"all your test data\" means \n\"only the data you  really  need\". RedG takes care of all the other stuff (like not specified  NOT NULL  fields, required\nforeign key relations etc.).",
            "title": "Specifying test data"
        },
        {
            "location": "/specifying_test_data/#general-api-design",
            "text": "The entity classes RedG generates use a  fluent interface  with getters and\nsetters in \"JQuery style\" (no  get / set  prefix, calling without parameter gets the value, with parameter sets it).  RedG  always generates a \"main class\" (or \"manager class\"). This is not an executable class containing a  public static void main(String[] args) , but the class you'll use to create and manage your RedG entities (and thus your\ntest data). This class is usually named  RedG .  Using the RedG main class you can create entities. An entity is a java object that represents one row of data that will be\ninserted into a database (or already  exists in the database ). Usually you can use methods\nto change fields (\"columns\" in your database) on these entities.",
            "title": "General API design"
        },
        {
            "location": "/specifying_test_data/#adding-an-entity",
            "text": "To create a new entity and add it to RedG's internal list of objects to insert call one of the  add...()  methods\non a RedG object. Replace  ...  with the name of the entity you want to add. If the entity has required fields (either NOT NULL  foreign keys or columns / foreign keys marked as  explicit ) \nyou'll need to pass them to the method. Passing a  null  value will result in a  NullPointerException .  Once you have created your entity you can use it's setters to set the values for the necessary fields.  Example:  RedG   redG   =   new   RedG ();  // or when customizing many things, consider using the RedGBuilder class  // RedG redG = new RedGBuilder<RedG>().build();  // either   GTeacher   mathTeacher   =   redG . addTeacher () \n     . name ( \"Leonhard Euler\" ) \n     . age ( 310 );  // or just  redG . addTeacher () \n     . name ( \"Isaac Newton\" );  // or even  GTeacher   chemistryTeacher   =   redG . addTeacher ();  chemistryTeacher \n     . name ( \"Niels Bohr\" ) \n     . hasNobelPrice ( true )   When you do not need an entity for further foreign key relations or data manipulation, there is no need to save it \nin a variable.  As you can see in the example, different fields are set for  mathTeacher  and  chemistryTeacher  although they are of the same \ntype and have the same columns. Even if  age  or  hasNobelPrice  would both be mandatory ( NOT NULL ) this code would\nstill work, as RedG generates default values for all fields that are not specified by the user.  Example for entities with  NOT NULL  foreign key or explicit attributes:  // name of school is an explicit attribute for demonstration purposes  redG . addSchool ( \"Time-traveling School with famous teachers\" ) \n     . headmaster ( einstein );  // Every class needs a teacher, so it is specified at creation time and may not be null  GClass   chemistryClass   =   redG . addClass ( chemistryTeacher ) \n     . name ( \"Chemistry 101\" ) \n     . maxStudentCount ( 45 )",
            "title": "Adding an entity"
        },
        {
            "location": "/specifying_test_data/#generating-a-dummy-entity",
            "text": "There are many scenarios where you need to test a specific entity but only need some or none of its dependencies.\nWith most other tools you would have to specify each and every dependency (and their dependencies and so on) and \nyou could wind up with far too much code/XML for just one entity.  To solve this problem RedG offers a dummy entity generator, that will generate a valid dummy entity for you. This entity\nwill have meaningless values but is still a valid entity that can be referenced wherever you want.  To stay in the educational environment with this example, imagine a test case where you need to test the  SCHOOL_SUBJECT  table\n( SchoolSubject  entity name,  GSchoolSubject  entity class name). Every subjects needs a teacher. A teacher is a human\nwith a pay grade, a qualification and a school he graduated from (All of these have to be provided because of constraints \non the database). Every subjects needs one required textbook as well.  // Without dummy entities and without the previously defined entities  GSchool   school   =   redG . addSchool ( \"Wherever Primary School\" );  GHuman   somePerson   =   redG . addHuman ();  GTeacher   someTeacher   =   redG . addTeacher ( somePerson ,   Paygrade . TEACHER ,  \n     Qualifications . NONE ,   school );  GTextBook   textBook   =   redG . addTextBook ();  GSchoolSubject   aqm   =   redg . addSchoolSubject ( someTeacher ,   textBook ) \n     . name ( \"Advanced quantum mechanics\" ) \n     . isCoreClass ( true ) \n     . room ( \"1.42\" );  // with RedGs dummy generator  GSchoolSubject   aqm   =   redG . addSchoolSubject ( \n         redG . dummyTeacher (), \n         redG . dummyTextBook ()  ) \n     . name ( \"Advanced quantum mechanics\" ) \n     . isCoreClass ( true ) \n     . room ( \"1.42\" );",
            "title": "Generating a dummy entity"
        },
        {
            "location": "/specifying_test_data/#referencing-existing-entities",
            "text": "Depending on your setup you might already have some data in your database before running RedG and need to reference\nthese data for a foreign key relation within RedG.  RedG allows you to specify that a certain entity is already present in the database. When inserting you test data\nRedG will test that the specified entity is really already in the database.  To reference an existing entity, use the  existing...()  methods of the RedG object. You have to pass\nthe full primary key as the arguments to these methods. If a table does not have primary keys, you cannot reference\nit.  Example:  GTeacher   euklid   =   redG . existingWizard ( 4 );   // 4 is value of primary id column  // use euklid just like normal for references, just don't try to modify him or read values other the primary keys  // trying to modify fields will throw an UnsupportedOperationException  euklid . isDead ( false );   redG . addMemorialDay ( euklid )   // works just like expected",
            "title": "Referencing existing entities"
        },
        {
            "location": "/features/dummy_data/",
            "text": "Dummy data\n\u00b6\n\n\nRedG's dummy data feature allows you to focus on the test data you really need. No more specifying dozens of (transitive)\ndependencies you do not need for your test but your database needs them to satisfy the foreign key constraints.\n\n\nWith RedG you can simply say \"I want a dummy entity of that type\" and you get one. With all of its dependencies\nset to other dummy objects. This works out-of-the-box with zero configuration in 99% of the cases.\n\n\nThe RedG main class generated by RedG contains a \ndummyXX\n method for each entity type.\n\n\nExample\n\u00b6\n\n\nLet's see this in action in a small example. Consider the following database schema:\n\n\n\n\nBecause the user needs a bank account (it is a \nNOT NULL\n foreign key), you have to specify a bank account if you\nwant to create a user with the \nredG.addDemoUser(GDemoBankAccount bankAcc)\n method. Simply passing \nnull\n will not\nwork here.\n\n\nIf you now want to add a user and perform some tests that only require its first and last name, you can simply use a dummy\nas the bank account.\n\n\nredG\n.\naddDemoUser\n(\nredG\n.\ndummyBankAccount\n())\n\n    \n.\nfirstName\n(\n\"Trevor\"\n)\n\n    \n.\nlastName\n(\n\"Testcase\"\n);\n\n\n\n\n\n\nAs you can see, RedG does all the heavy work for you. No need to specify anything for the dummy. You get a valid dummy that \nsatisfies every database constraint so you can test the first and last name without worrying about the excess baggage.\n\n\nCustomization\n\u00b6\n\n\nIf you need to customize how RedG generates dummy data, see \nhere\n.",
            "title": "Dummy data"
        },
        {
            "location": "/features/dummy_data/#dummy-data",
            "text": "RedG's dummy data feature allows you to focus on the test data you really need. No more specifying dozens of (transitive)\ndependencies you do not need for your test but your database needs them to satisfy the foreign key constraints.  With RedG you can simply say \"I want a dummy entity of that type\" and you get one. With all of its dependencies\nset to other dummy objects. This works out-of-the-box with zero configuration in 99% of the cases.  The RedG main class generated by RedG contains a  dummyXX  method for each entity type.",
            "title": "Dummy data"
        },
        {
            "location": "/features/dummy_data/#example",
            "text": "Let's see this in action in a small example. Consider the following database schema:   Because the user needs a bank account (it is a  NOT NULL  foreign key), you have to specify a bank account if you\nwant to create a user with the  redG.addDemoUser(GDemoBankAccount bankAcc)  method. Simply passing  null  will not\nwork here.  If you now want to add a user and perform some tests that only require its first and last name, you can simply use a dummy\nas the bank account.  redG . addDemoUser ( redG . dummyBankAccount ()) \n     . firstName ( \"Trevor\" ) \n     . lastName ( \"Testcase\" );   As you can see, RedG does all the heavy work for you. No need to specify anything for the dummy. You get a valid dummy that \nsatisfies every database constraint so you can test the first and last name without worrying about the excess baggage.",
            "title": "Example"
        },
        {
            "location": "/features/dummy_data/#customization",
            "text": "If you need to customize how RedG generates dummy data, see  here .",
            "title": "Customization"
        },
        {
            "location": "/features/visualization/",
            "text": "Visualization\n\u00b6\n\n\nThe \nRedG Visualizer\n allows you to inspect the object graph of a RedG instance.\nThis can be very useful for debugging purposes or to simply have a look at the dependencies of your entities.\n\n\nPreparation\n\u00b6\n\n\n\n\nNote\n\n\nRedG's visualization support has to be enabled during code generation time. Look at the documentation for your chosen\n\nintegration\n method on how to enable support.\n\n\nEnabling visualization support will have a small performance penalty and you'll need Jackson as extra dependencies.\n\n\n\n\nAfter enabling visualization support you have to add \njackson-core\n and \njackson-databind\n as dependencies to your test code.\nThese two are needed to generate the JSON output you'll need for the visualizer.\n\n\n<dependency>\n\n    \n<groupId>\ncom.fasterxml.jackson.core\n</groupId>\n\n    \n<artifactId>\njackson-core\n</artifactId>\n\n    \n<version>\n2.8.5\n</version>\n\n    \n<scope>\ntest\n</scope>\n\n\n</dependency>\n\n\n<dependency>\n\n    \n<groupId>\ncom.fasterxml.jackson.core\n</groupId>\n\n    \n<artifactId>\njackson-databind\n</artifactId>\n\n    \n<version>\n2.8.5\n</version>\n\n    \n<scope>\ntest\n</scope>\n\n\n</dependency>\n\n\n\n\n\n\nNow there are two ways to obtain the entity graph as JSON code:\n\n\n\n\nIn the test, output the result of \nredG.getVisualizationJson()\n into a file or to the console.\n\n\nPlace a breakpoint somewhere in your test where you have access to the \nredG\n object, let the test run until \n it hits the breakpoint and evaluate \nredG.getVisualizationJson()\n with the help of your IDE. Copy the returned string.\n\n\n\n\nVisualization\n\u00b6\n\n\nWith the JSON output either in your clipboard or a file, visit \n\nthe RedG Visualizer site\n and paste (or drag & drop) the JSON into the editor.\nHit the \"Visualize Me!\" button and let the visualization render.\n\n\n\n\nAn example visualization\n\n\nEntity view\n\u00b6\n\n\nThe main panel of the visualizer shows a graphical representation of your RedG object graph. When the graph is rendered for \nthe fist time a layout algorithm is applied. This results in a nice initial layout. When visualizing large object\ngraphs, entities may appear below or right of your initial viewport. Either zoom out or pan to see them.\n\n\n\n\n\n\n\n\nFeature\n\n\nControls\n\n\n\n\n\n\n\n\n\n\nZoom\n\n\nUse your mouse wheel or double click (Pinch or double tap on touchscreens)\n\n\n\n\n\n\nPan / Move viewport\n\n\nClick and drag on background (Cursor is default)\n\n\n\n\n\n\nSelect entity\n\n\nClick an entity. Click again to deselect it\n\n\n\n\n\n\nMove an entity\n\n\nClick and drag an entity (Cursor is pointer)\n\n\n\n\n\n\n\n\nDetail view\n\u00b6\n\n\nWhen you select an entity in the \nentity view\n, the detail view in the lower right corner will\nshow all attributes (explicit & implicit) in full length and will show a list of all outgoing relations. You can\nclick on a relation link to directly select the referenced entity.\n\n\nOptions\n\u00b6\n\n\nThe upper right panel shows the available options and the export buttons.\n\n\n\n\n\n\n\n\nOption\n\n\nType\n\n\nExplanation\n\n\n\n\n\n\n\n\n\n\nShow SQL names\n\n\nCheckbox\n\n\nIf checked, the SQL table and column names will be shown instead of the Java identifiers\n\n\n\n\n\n\nShow relation names\n\n\nCheckbox\n\n\nIf checked, the relation arrows will show a text with the relation name\n\n\n\n\n\n\nDummy Entity Visibility\n\n\nCombo-Box\n\n\nFull: Show the full dummy entity (explicit & implicit fields)\nMinimal: Show only the header (class / table name)\nInvisible: Do not show the entity and their relations\n\n\n\n\n\n\nExisting Entity Visibility\n\n\nCombo-Box\n\n\nFull: Show the full existing entity (explicit & implicit fields)\nMinimal: Show only the header (class / table name)\nInvisible: Do not show the entity and their relations\n\n\n\n\n\n\nExport view as PNG\n\n\nButton\n\n\nLets you export the current viewport (exactly what you see on the left) to a PNG file. Will show a popup where you can choose the image resolution\n\n\n\n\n\n\nExport view as SVG\n\n\nButton\n\n\nLets you export the current viewport (exactly what you see on the left) to a SVG file. All information (entities & relations) are included so you could manipulate the viewport later. Used fonts might not be available on a different computer",
            "title": "Visualization"
        },
        {
            "location": "/features/visualization/#visualization",
            "text": "The  RedG Visualizer  allows you to inspect the object graph of a RedG instance.\nThis can be very useful for debugging purposes or to simply have a look at the dependencies of your entities.",
            "title": "Visualization"
        },
        {
            "location": "/features/visualization/#preparation",
            "text": "Note  RedG's visualization support has to be enabled during code generation time. Look at the documentation for your chosen integration  method on how to enable support.  Enabling visualization support will have a small performance penalty and you'll need Jackson as extra dependencies.   After enabling visualization support you have to add  jackson-core  and  jackson-databind  as dependencies to your test code.\nThese two are needed to generate the JSON output you'll need for the visualizer.  <dependency> \n     <groupId> com.fasterxml.jackson.core </groupId> \n     <artifactId> jackson-core </artifactId> \n     <version> 2.8.5 </version> \n     <scope> test </scope>  </dependency>  <dependency> \n     <groupId> com.fasterxml.jackson.core </groupId> \n     <artifactId> jackson-databind </artifactId> \n     <version> 2.8.5 </version> \n     <scope> test </scope>  </dependency>   Now there are two ways to obtain the entity graph as JSON code:   In the test, output the result of  redG.getVisualizationJson()  into a file or to the console.  Place a breakpoint somewhere in your test where you have access to the  redG  object, let the test run until \n it hits the breakpoint and evaluate  redG.getVisualizationJson()  with the help of your IDE. Copy the returned string.",
            "title": "Preparation"
        },
        {
            "location": "/features/visualization/#visualization_1",
            "text": "With the JSON output either in your clipboard or a file, visit  the RedG Visualizer site  and paste (or drag & drop) the JSON into the editor.\nHit the \"Visualize Me!\" button and let the visualization render.   An example visualization",
            "title": "Visualization"
        },
        {
            "location": "/features/visualization/#entity-view",
            "text": "The main panel of the visualizer shows a graphical representation of your RedG object graph. When the graph is rendered for \nthe fist time a layout algorithm is applied. This results in a nice initial layout. When visualizing large object\ngraphs, entities may appear below or right of your initial viewport. Either zoom out or pan to see them.     Feature  Controls      Zoom  Use your mouse wheel or double click (Pinch or double tap on touchscreens)    Pan / Move viewport  Click and drag on background (Cursor is default)    Select entity  Click an entity. Click again to deselect it    Move an entity  Click and drag an entity (Cursor is pointer)",
            "title": "Entity view"
        },
        {
            "location": "/features/visualization/#detail-view",
            "text": "When you select an entity in the  entity view , the detail view in the lower right corner will\nshow all attributes (explicit & implicit) in full length and will show a list of all outgoing relations. You can\nclick on a relation link to directly select the referenced entity.",
            "title": "Detail view"
        },
        {
            "location": "/features/visualization/#options",
            "text": "The upper right panel shows the available options and the export buttons.     Option  Type  Explanation      Show SQL names  Checkbox  If checked, the SQL table and column names will be shown instead of the Java identifiers    Show relation names  Checkbox  If checked, the relation arrows will show a text with the relation name    Dummy Entity Visibility  Combo-Box  Full: Show the full dummy entity (explicit & implicit fields) Minimal: Show only the header (class / table name) Invisible: Do not show the entity and their relations    Existing Entity Visibility  Combo-Box  Full: Show the full existing entity (explicit & implicit fields) Minimal: Show only the header (class / table name) Invisible: Do not show the entity and their relations    Export view as PNG  Button  Lets you export the current viewport (exactly what you see on the left) to a PNG file. Will show a popup where you can choose the image resolution    Export view as SVG  Button  Lets you export the current viewport (exactly what you see on the left) to a SVG file. All information (entities & relations) are included so you could manipulate the viewport later. Used fonts might not be available on a different computer",
            "title": "Options"
        },
        {
            "location": "/features/data_extractor/",
            "text": "Data extractor\n\u00b6\n\n\nTo help you with migrating from your existing solution to RedG you can use\nthe RedG extractor. It enables you to extract all the data from a database and\ncreate a RedG data set that, if inserted, will produce the exact same database\ncontent.\n\n\n\n\nNote\n\n\nThe RedG data set will contain every column from every table. This does not\nmake use of RedG's greatest features (default values, dummy generator).\nUse the extraction result as a starting point and then reduce your data to the\nneeded minimum. This has to be done by hand, as RedG does not know what data you\nreally need.\n\n\n\n\nJava API\n\u00b6\n\n\nIf you have your current test data only available in-memory during your tests,\nuse the Java API of the extractor to generate the RedG Java code.\n\n\nThe generation is a three-step process:\n\n\n\n\nGet the RedG \nTableModel\ns for all tables you want to extract\n\n\nExtract all the data into \nEntityModel\ns\n\n\nGenerate the code for the \nEntityModel\ns\n\n\n\n\nObtain the TableModels\n\u00b6\n\n\nThere are multiple ways of obtaining the \nTableModel\ns for your database schema.\nRedG writes a serializes table model into every generated entity class code.\n\n\nThese can be accessed at runtime via the static \ngetTableModel()\n method.\nIf the generated classes are either not yet compiled or compiled but not loaded\nin your current JVM instance, you can use the \nTableModelExtractor.extractTableModelsFromSourceCode(directory, codePackage, classPrefix)\n\nor \nTableModelExtractor.extractTableModelFromClasses(directory, codePackage, classPrefix)\n methods to\nextract the \nTableModel\ns for all RedG entity classes.\n\n\nThese two methods take three parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nExplanation\n\n\n\n\n\n\n\n\n\n\ndirectory\n\n\nThe \nPath\n of the source code root, \nwithout\n the package structure folders\n\n\n\n\n\n\npackageName\n\n\nThe name of the Java package that was used during code generation. \ncom.btc.redg.generated\n if not overwritten\n\n\n\n\n\n\nclassPrefix\n\n\nThe class name prefix for the generated RedG classes. \nG\n by default\n\n\n\n\n\n\n\n\nExtract all data\n\u00b6\n\n\nObtain a connection to your database and call \nnew DataExtractor().extractAllData( connection, tableModels)\n.\n\ntableModels\n should be the list of \nTableModel\ns from the previous step.\n\n\nSave the result in a list of \nEntityModel\ns for the next step.\n\n\n\n\nNote\n\n\nIf you manually exclude some \nTableModel\ns, keep in mind that the extraction will fail if a \nTableModel\n\nfor a dependend table (via foreign key) is not found.\n\n\n\n\nGenerate the code\n\u00b6\n\n\nUsing the \nEntityModel\ns you can now call \nnew CodeGenerator().generateCode( codePackageName, redGClassName, codeClassName, entityModels)\n\n\nThis will return the Java code as a String.\n\n\nThe \ngenerateCode\n method takes four parameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nExplanation\n\n\n\n\n\n\n\n\n\n\ncodePackage\n\n\nThe code package of the generated RedG entity classes. Needed for imports\n\n\n\n\n\n\nredgClassName\n\n\nThe name of your RedG main class. Normally \nRedG\n\n\n\n\n\n\nclassName\n\n\nThe name that will be used for the class containing your entity specification code\n\n\n\n\n\n\nentityModels\n\n\nThe \nEntityModel\ns from the previous step\n\n\n\n\n\n\n\n\nUsing the generated code\n\u00b6\n\n\nWhen your database only contains strings and numbers, RedG's extractor will most likely produce working Java code.\nIf you are using dates, blobs or other more \"exotic\" types that cannot simply be mapped to a Java type, the \ntoString()\n result\nwill simply be used as a placeholder and you'll have to fix the code.",
            "title": "Data extraction"
        },
        {
            "location": "/features/data_extractor/#data-extractor",
            "text": "To help you with migrating from your existing solution to RedG you can use\nthe RedG extractor. It enables you to extract all the data from a database and\ncreate a RedG data set that, if inserted, will produce the exact same database\ncontent.   Note  The RedG data set will contain every column from every table. This does not\nmake use of RedG's greatest features (default values, dummy generator).\nUse the extraction result as a starting point and then reduce your data to the\nneeded minimum. This has to be done by hand, as RedG does not know what data you\nreally need.",
            "title": "Data extractor"
        },
        {
            "location": "/features/data_extractor/#java-api",
            "text": "If you have your current test data only available in-memory during your tests,\nuse the Java API of the extractor to generate the RedG Java code.  The generation is a three-step process:   Get the RedG  TableModel s for all tables you want to extract  Extract all the data into  EntityModel s  Generate the code for the  EntityModel s",
            "title": "Java API"
        },
        {
            "location": "/features/data_extractor/#obtain-the-tablemodels",
            "text": "There are multiple ways of obtaining the  TableModel s for your database schema.\nRedG writes a serializes table model into every generated entity class code.  These can be accessed at runtime via the static  getTableModel()  method.\nIf the generated classes are either not yet compiled or compiled but not loaded\nin your current JVM instance, you can use the  TableModelExtractor.extractTableModelsFromSourceCode(directory, codePackage, classPrefix) \nor  TableModelExtractor.extractTableModelFromClasses(directory, codePackage, classPrefix)  methods to\nextract the  TableModel s for all RedG entity classes.  These two methods take three parameters:     Parameter  Explanation      directory  The  Path  of the source code root,  without  the package structure folders    packageName  The name of the Java package that was used during code generation.  com.btc.redg.generated  if not overwritten    classPrefix  The class name prefix for the generated RedG classes.  G  by default",
            "title": "Obtain the TableModels"
        },
        {
            "location": "/features/data_extractor/#extract-all-data",
            "text": "Obtain a connection to your database and call  new DataExtractor().extractAllData( connection, tableModels) . tableModels  should be the list of  TableModel s from the previous step.  Save the result in a list of  EntityModel s for the next step.   Note  If you manually exclude some  TableModel s, keep in mind that the extraction will fail if a  TableModel \nfor a dependend table (via foreign key) is not found.",
            "title": "Extract all data"
        },
        {
            "location": "/features/data_extractor/#generate-the-code",
            "text": "Using the  EntityModel s you can now call  new CodeGenerator().generateCode( codePackageName, redGClassName, codeClassName, entityModels)  This will return the Java code as a String.  The  generateCode  method takes four parameters:     Parameter  Explanation      codePackage  The code package of the generated RedG entity classes. Needed for imports    redgClassName  The name of your RedG main class. Normally  RedG    className  The name that will be used for the class containing your entity specification code    entityModels  The  EntityModel s from the previous step",
            "title": "Generate the code"
        },
        {
            "location": "/features/data_extractor/#using-the-generated-code",
            "text": "When your database only contains strings and numbers, RedG's extractor will most likely produce working Java code.\nIf you are using dates, blobs or other more \"exotic\" types that cannot simply be mapped to a Java type, the  toString()  result\nwill simply be used as a placeholder and you'll have to fix the code.",
            "title": "Using the generated code"
        },
        {
            "location": "/features/jpa_metamodel/",
            "text": "JPA meta-model analysis\n\u00b6\n\n\nRedG offers the ability to analyze a JPA meta-model and extract the names and data types from there. So if you are using a\nJPA persistence layer, configuring the names and data types with your existing JPA meta-model might be considerably easier\nfor you.\n\n\nMaven plugin configuration\n\u00b6\n\n\nTo use the meta-model analysis with the \nMaven plugin\n, add the following XML to the \nplugin configuration:\n\n\n<jpaProviderConfig>\n\n    \n<persistenceUnitName>\nnameOfPersistenceUnit\n</persistenceUnitName>\n\n    \n<useAsNameProvider>\ntrue\n</useAsNameProvider>\n\n    \n<useAsDataTypeProvider>\nfalse\n</useAsDataTypeProvider>\n\n\n</jpaProviderConfig>\n\n\n\n\n\n\nJava API\n\u00b6\n\n\nCreate a new \nJpaMetamodelRedGProvider\n either with a \nMetamodel\n via its constructor or with the static method\n\nJpaMetamodelRedGProvider#fromPersistenceUnit(String perstistenceUnitName)\n. Now use it as the name provider or data type\nprovider as parameter for the RedG code generator method.",
            "title": "JPA meta-model analysis"
        },
        {
            "location": "/features/jpa_metamodel/#jpa-meta-model-analysis",
            "text": "RedG offers the ability to analyze a JPA meta-model and extract the names and data types from there. So if you are using a\nJPA persistence layer, configuring the names and data types with your existing JPA meta-model might be considerably easier\nfor you.",
            "title": "JPA meta-model analysis"
        },
        {
            "location": "/features/jpa_metamodel/#maven-plugin-configuration",
            "text": "To use the meta-model analysis with the  Maven plugin , add the following XML to the \nplugin configuration:  <jpaProviderConfig> \n     <persistenceUnitName> nameOfPersistenceUnit </persistenceUnitName> \n     <useAsNameProvider> true </useAsNameProvider> \n     <useAsDataTypeProvider> false </useAsDataTypeProvider>  </jpaProviderConfig>",
            "title": "Maven plugin configuration"
        },
        {
            "location": "/features/jpa_metamodel/#java-api",
            "text": "Create a new  JpaMetamodelRedGProvider  either with a  Metamodel  via its constructor or with the static method JpaMetamodelRedGProvider#fromPersistenceUnit(String perstistenceUnitName) . Now use it as the name provider or data type\nprovider as parameter for the RedG code generator method.",
            "title": "Java API"
        },
        {
            "location": "/integration/",
            "text": "Integration\n\u00b6\n\n\nHow you integrate RedG into you project depends on your build system and personal preferences. RedG is very flexible and\ncan easily be adapted to fit your project.\n\n\nRedG code generator\n\u00b6\n\n\nThe RedG code generator analyzes your database and generates matching entity classes you can then use to specify your test\ndata. Usually the code generation is so fast that it can be run before every test, thus ensuring it is always up-to-date and\nmatches the current database schema. \n\n\nThere are multiple ways of integrating the code generator into your project.\n\n\n\n\nThe \nRedG Maven plugin\n\n\nCalling the \ngenerator API\n manually\n\n\n\n\nRedG runtime\n\u00b6\n\n\nThe RedG runtime library is available as a Maven dependency in the Maven Central. \n\n\nAll of the following integration possibilities require the following dependency:\n\n\n<dependency>\n\n    \n<groupId>\ncom.btc-ag.redg\n</groupId>\n\n    \n<artifactId>\nredg-runtime\n</artifactId>\n\n    \n<version>\n1.0.15\n</version>\n\n    \n<scope>\ntest\n</scope>\n\n\n</dependency>\n\n\n\n\n\n\nAfter you have specified your test data you can insert them with the \nruntime API\n. This approach\noffers absolute flexibility abnd can easily be integrated into JUnit, Spring or whatever awesome frameworks your project\nis using.",
            "title": "Overview"
        },
        {
            "location": "/integration/#integration",
            "text": "How you integrate RedG into you project depends on your build system and personal preferences. RedG is very flexible and\ncan easily be adapted to fit your project.",
            "title": "Integration"
        },
        {
            "location": "/integration/#redg-code-generator",
            "text": "The RedG code generator analyzes your database and generates matching entity classes you can then use to specify your test\ndata. Usually the code generation is so fast that it can be run before every test, thus ensuring it is always up-to-date and\nmatches the current database schema.   There are multiple ways of integrating the code generator into your project.   The  RedG Maven plugin  Calling the  generator API  manually",
            "title": "RedG code generator"
        },
        {
            "location": "/integration/#redg-runtime",
            "text": "The RedG runtime library is available as a Maven dependency in the Maven Central.   All of the following integration possibilities require the following dependency:  <dependency> \n     <groupId> com.btc-ag.redg </groupId> \n     <artifactId> redg-runtime </artifactId> \n     <version> 1.0.15 </version> \n     <scope> test </scope>  </dependency>   After you have specified your test data you can insert them with the  runtime API . This approach\noffers absolute flexibility abnd can easily be integrated into JUnit, Spring or whatever awesome frameworks your project\nis using.",
            "title": "RedG runtime"
        },
        {
            "location": "/integration/maven_plugin/",
            "text": "RedG Maven plugin\n\u00b6\n\n\nThe RedG Maven plugin offers comfortable and easy integration of the RedG code generation into your \nMaven project. It is configurable via Maven properties and JSON files.\n\n\n\n\nWhile the Maven plugin is pretty flexible, RedG can be configured even further if you use the \ncode generator API directly. If you need absolute control, check out the \n\ndocs for the code generator API\n.\n\n\n\n\nUsage\n\u00b6\n\n\nSimply add the RedG plugin into your \n<plugins>\n section of your \npom.xml\n. You may choose your own\n\n<id>\n, but the \n<phase>\n should stay at \ngenerate-test-sources\n in most cases. Now add your \nconfiguration in the \n<configuration>\n part and, if necessary, specify a dependency to your JDBC\ndriver. If you use a different RDBMS than H2 you need an extra dependency to the SchemaCrawler plugin for your DBMS.\n\n\nThe list of the most commonly needed plugins (for full list, see in \nMaven Central\n):\n\n\n\n\n\n\n\n\nDBMS\n\n\nNecessary dependency\n\n\n\n\n\n\n\n\n\n\nOracle\n\n\nus.fatehi:schemacrawler-oracle:14.16.01\n\n\n\n\n\n\nIBM DB2\n\n\nus.fatehi:schemacrawler-db2:14.16.01\n\n\n\n\n\n\nMS SQL Server\n\n\nus.fatehi:schemacrawler-sqlserver:14.16.01\n\n\n\n\n\n\nMySQL\n\n\nus.fatehi:schemacrawler-mysql:14.16.01\n\n\n\n\n\n\nPostgreSQL\n\n\nus.fatehi:schemacrawler-postgresql:14.16.01\n\n\n\n\n\n\n\n\n<plugin>\n\n    \n<groupId>\ncom.btc-ag.redg\n</groupId>\n\n    \n<artifactId>\nredg-maven-plugin\n</artifactId>\n\n    \n<version>\n1.0.15\n</version>\n\n    \n<executions>\n\n        \n<execution>\n\n            \n<id>\nredg-generate\n</id>\n\n            \n<phase>\ngenerate-test-sources\n</phase>\n\n            \n<goals>\n\n                \n<goal>\nredg\n</goal>\n\n            \n</goals>\n\n            \n<configuration>\n\n                \n<!-- RedG configuration goes here -->\n\n            \n</configuration>\n\n        \n</execution>\n\n    \n</executions>\n\n    \n<dependencies>\n\n        \n<!-- JDBC driver and SchemaCrawler plugin, only if not using H2. Entry depends on DBMS -->\n\n    \n</dependencies>\n\n\n</plugin>\n\n\n\n\n\n\nConfiguration\n\u00b6\n\n\nThe following table lists all configuration options of the RedG Maven plugin.\n\n\n\n\n\n\n\n\nXML Tag\n\n\nCMD property\n\n\nDefault value\n\n\nExplanation\n\n\n\n\n\n\n\n\n\n\n<connectionString>\n\n\nredg.connectionString\n\n\njdbc:h2:mem:redg;DB_CLOSE_DELAY=-1\n\n\nThe JDBC connection string for the database that will be analyzed. Uses a H2 in-memory database by default, so if you are using SQL-Scripts, you can omit the connection paramters most of the time.\n\n\n\n\n\n\n<username>\n\n\nredg.username\n\n\n\n\nThe username for the database.  Can be left unchanged if used with the default connection string.\n\n\n\n\n\n\n<password>\n\n\nredg.password\n\n\n\n\nThe password for the database user. Can be left unchanged if used with the default connection string.\n\n\n\n\n\n\n<jdbcDriver>\n\n\nredg.jdbcDriver\n\n\norg.h2.Driver\n\n\nThe JDBC driver. A Maven dependency providing this class has to be specified if you are not using H2.\n\n\n\n\n\n\n<sqlScripts>\n\n\nnot available\n\n\n\n\nA file array with SQL scripts that should be executed before the database analysis. These scripts can be used to create the schema when you are using an in-memory H2 database.\n\n\n\n\n\n\n<schemaRegex>\n\n\nnot available\n\n\n.*\n\n\nA regular expression to select all database schemas that will be included in the database analysis.\n\n\n\n\n\n\n<tablesRegex>\n\n\nnot available\n\n\n.*\n\n\nA regular expression to select all the tables that will be included in the database analysis. If a table is excluded because it belongs to an exlcuded schema, it will \nnot\n be included again.\n\n\n\n\n\n\n<outputDirectory>\n\n\nnot available\n\n\ntarget/generated-test-sources/redg\n\n\nThe output folder for the generated source code. Default value is Maven standard.\n\n\n\n\n\n\n<targetPackage>\n\n\nnot available\n\n\ncom.btc.redg.generated\n\n\nThe java package of the to-be-generated entity classes.\n\n\n\n\n\n\n<classPrefix>\n\n\nnot available\n\n\nG\n\n\nA prefix string that gets prepended to each entity class.\n\n\n\n\n\n\n<allowPrimitiveTypes>\n\n\nnot available\n\n\nfalse\n\n\nBy default RedG replaces primitive types with their wrapper classes (\nint\n to \nInteger\n, etc.). Set to \ntrue\n to disable this behavior.\n\n\n\n\n\n\n<enableVisualizationSupport>\n\n\nredg.enableVisualization\n\n\nfalse\n\n\nIf \ntrue\n, the generated code will support \nvisualization\n of the object graph\n\n\n\n\n\n\n<customTypeMappings>\n\n\nnot available\n\n\n\n\nA JSON or XML file with custom type mappings. See \nhere\n for an explanation and an example code.\n\n\n\n\n\n\n<customNameMappings>\n\n\nnot available\n\n\n\n\nA JSON file that defines custom name mappings. See \nhere\n for an explanation and an example JSON code.\n\n\n\n\n\n\n<explicitAttributesConfig>\n\n\nnot available\n\n\n\n\nA JSON file that defines explicit attributes and foreign keys. See \nhere\n for an explanation and an example JSON code.\n\n\n\n\n\n\n<convenienceSetterConfig>\n\n\nnot available\n\n\n\n\nA XML file that defines convenience setter methods. See \nhere\n for an explanation and an example XML code.\n\n\n\n\n\n\n<jpaProviderConfig>\n\n\nnot available\n\n\n\n\nThe configuration for the JPA meta-model analysis. See \nhere\n for an explanation of this feature and example XML.",
            "title": "Maven plugin"
        },
        {
            "location": "/integration/maven_plugin/#redg-maven-plugin",
            "text": "The RedG Maven plugin offers comfortable and easy integration of the RedG code generation into your \nMaven project. It is configurable via Maven properties and JSON files.   While the Maven plugin is pretty flexible, RedG can be configured even further if you use the \ncode generator API directly. If you need absolute control, check out the  docs for the code generator API .",
            "title": "RedG Maven plugin"
        },
        {
            "location": "/integration/maven_plugin/#usage",
            "text": "Simply add the RedG plugin into your  <plugins>  section of your  pom.xml . You may choose your own <id> , but the  <phase>  should stay at  generate-test-sources  in most cases. Now add your \nconfiguration in the  <configuration>  part and, if necessary, specify a dependency to your JDBC\ndriver. If you use a different RDBMS than H2 you need an extra dependency to the SchemaCrawler plugin for your DBMS.  The list of the most commonly needed plugins (for full list, see in  Maven Central ):     DBMS  Necessary dependency      Oracle  us.fatehi:schemacrawler-oracle:14.16.01    IBM DB2  us.fatehi:schemacrawler-db2:14.16.01    MS SQL Server  us.fatehi:schemacrawler-sqlserver:14.16.01    MySQL  us.fatehi:schemacrawler-mysql:14.16.01    PostgreSQL  us.fatehi:schemacrawler-postgresql:14.16.01     <plugin> \n     <groupId> com.btc-ag.redg </groupId> \n     <artifactId> redg-maven-plugin </artifactId> \n     <version> 1.0.15 </version> \n     <executions> \n         <execution> \n             <id> redg-generate </id> \n             <phase> generate-test-sources </phase> \n             <goals> \n                 <goal> redg </goal> \n             </goals> \n             <configuration> \n                 <!-- RedG configuration goes here --> \n             </configuration> \n         </execution> \n     </executions> \n     <dependencies> \n         <!-- JDBC driver and SchemaCrawler plugin, only if not using H2. Entry depends on DBMS --> \n     </dependencies>  </plugin>",
            "title": "Usage"
        },
        {
            "location": "/integration/maven_plugin/#configuration",
            "text": "The following table lists all configuration options of the RedG Maven plugin.     XML Tag  CMD property  Default value  Explanation      <connectionString>  redg.connectionString  jdbc:h2:mem:redg;DB_CLOSE_DELAY=-1  The JDBC connection string for the database that will be analyzed. Uses a H2 in-memory database by default, so if you are using SQL-Scripts, you can omit the connection paramters most of the time.    <username>  redg.username   The username for the database.  Can be left unchanged if used with the default connection string.    <password>  redg.password   The password for the database user. Can be left unchanged if used with the default connection string.    <jdbcDriver>  redg.jdbcDriver  org.h2.Driver  The JDBC driver. A Maven dependency providing this class has to be specified if you are not using H2.    <sqlScripts>  not available   A file array with SQL scripts that should be executed before the database analysis. These scripts can be used to create the schema when you are using an in-memory H2 database.    <schemaRegex>  not available  .*  A regular expression to select all database schemas that will be included in the database analysis.    <tablesRegex>  not available  .*  A regular expression to select all the tables that will be included in the database analysis. If a table is excluded because it belongs to an exlcuded schema, it will  not  be included again.    <outputDirectory>  not available  target/generated-test-sources/redg  The output folder for the generated source code. Default value is Maven standard.    <targetPackage>  not available  com.btc.redg.generated  The java package of the to-be-generated entity classes.    <classPrefix>  not available  G  A prefix string that gets prepended to each entity class.    <allowPrimitiveTypes>  not available  false  By default RedG replaces primitive types with their wrapper classes ( int  to  Integer , etc.). Set to  true  to disable this behavior.    <enableVisualizationSupport>  redg.enableVisualization  false  If  true , the generated code will support  visualization  of the object graph    <customTypeMappings>  not available   A JSON or XML file with custom type mappings. See  here  for an explanation and an example code.    <customNameMappings>  not available   A JSON file that defines custom name mappings. See  here  for an explanation and an example JSON code.    <explicitAttributesConfig>  not available   A JSON file that defines explicit attributes and foreign keys. See  here  for an explanation and an example JSON code.    <convenienceSetterConfig>  not available   A XML file that defines convenience setter methods. See  here  for an explanation and an example XML code.    <jpaProviderConfig>  not available   The configuration for the JPA meta-model analysis. See  here  for an explanation of this feature and example XML.",
            "title": "Configuration"
        },
        {
            "location": "/integration/generator_api/",
            "text": "Code generator API\n\u00b6\n\n\nWhen you need every last bit of customizability, using the code generator API is your best option. It offers you\none big \ngenerateCode\n method that gives you access to every bit of customization that RedG supports out-of-the-box.\n\n\nTo use the API, simply include the following Maven dependency:\n\n\n<dependency>\n\n    \n<groupId>\ncom.btc-ag.redg\n</groupId>\n\n    \n<artifactId>\nredg-generator\n</artifactId>\n\n    \n<version>\n1.0.15\n</version>\n\n\n</dependency>\n\n\n\n\n\n\nIf you use are not using H2, you need to inlcude the JDBC driver and the SchemaCrawler plugin for your DBMS. See \nhere\n for a\nlist of all supported DBMS and their SchemaCrawler and plugins.\n\n\nSee the \nJavadoc\n or source code for a detailed description of every parameter of the \ngenerateCode\n method.\nIf you like an example how to use this method, take a look at the \n\nMaven plugin source\n.\n\n\n\n\nIf even the standard API is not enough, take a look at the \nRedGGenerator\n source code. RedG is pretty modular\nand every important method is public, so you can just re-use the parts that work for you and re-implement the other parts.\n\n\nIf your extension could benefit the community, please consider publishing it and create a pull request.",
            "title": "Code generator API"
        },
        {
            "location": "/integration/generator_api/#code-generator-api",
            "text": "When you need every last bit of customizability, using the code generator API is your best option. It offers you\none big  generateCode  method that gives you access to every bit of customization that RedG supports out-of-the-box.  To use the API, simply include the following Maven dependency:  <dependency> \n     <groupId> com.btc-ag.redg </groupId> \n     <artifactId> redg-generator </artifactId> \n     <version> 1.0.15 </version>  </dependency>   If you use are not using H2, you need to inlcude the JDBC driver and the SchemaCrawler plugin for your DBMS. See  here  for a\nlist of all supported DBMS and their SchemaCrawler and plugins.  See the  Javadoc  or source code for a detailed description of every parameter of the  generateCode  method.\nIf you like an example how to use this method, take a look at the  Maven plugin source .   If even the standard API is not enough, take a look at the  RedGGenerator  source code. RedG is pretty modular\nand every important method is public, so you can just re-use the parts that work for you and re-implement the other parts.  If your extension could benefit the community, please consider publishing it and create a pull request.",
            "title": "Code generator API"
        },
        {
            "location": "/integration/runtime_api/",
            "text": "RedG runtime API\n\u00b6\n\n\nThe most bare-bone approach to inserting data with RedG ist the runtime API. Using it directly is the most flexible way and does not\nrequire any extra dependencies.\n\n\nThe runtime API can be used to either \n\n\n\n\ninsert the data set via \nPreparedStatements\n into a database using a JDBc \nConnection\n.\n\n\ngenerate SQL \nINSERT\n statements that can be used with some other tool (Oracle SqlDeveloper, JetBrains DataGrip, MySQL Workbench, etc.).\n\n\n\n\nUsing PreparedStatements\n\u00b6\n\n\nTo insert the of a RedG instance into a database, call the \ninsertDataIntoDatabase\n method and provide a JDBC connection.\n\n\n\n\nNote\n\n\nYou might need to use a custom \n\nPreparedStatement parameter setter\n for special data types.\n\n\n\n\nGenerating SQL statements\n\u00b6\n\n\nTo generate SQL \nINSERT\n statements for your test data, call the \ngenerateSQLStatements\n method on your RedG object. It will return a\n\nList<String>\n with each String being a complete SQL INSERT statement. The list is ordered so that no foreign key constraints are\nviolated, so preserve this order. When exporting the statements into an SQL file you have to append a semicolon to each statement.\n\n\n\n\nNote\n\n\nYou might need to use a custom \n\nSQL values formatter\n for special data types.\n\n\n\n\nExample code for export:\n\n\nList\n<\nString\n>\n \nlist\n \n=\n \nredG\n.\ngenerateSQLStatements\n();\n\n\nString\n \nsqlScript\n \n=\n \nsql\n.\nstream\n().\ncollect\n(\nCollectors\n.\njoining\n(\n\";\\n\"\n));\n\n\n// do whatever you want with sqlScript",
            "title": "Runtime API"
        },
        {
            "location": "/integration/runtime_api/#redg-runtime-api",
            "text": "The most bare-bone approach to inserting data with RedG ist the runtime API. Using it directly is the most flexible way and does not\nrequire any extra dependencies.  The runtime API can be used to either    insert the data set via  PreparedStatements  into a database using a JDBc  Connection .  generate SQL  INSERT  statements that can be used with some other tool (Oracle SqlDeveloper, JetBrains DataGrip, MySQL Workbench, etc.).",
            "title": "RedG runtime API"
        },
        {
            "location": "/integration/runtime_api/#using-preparedstatements",
            "text": "To insert the of a RedG instance into a database, call the  insertDataIntoDatabase  method and provide a JDBC connection.   Note  You might need to use a custom  PreparedStatement parameter setter  for special data types.",
            "title": "Using PreparedStatements"
        },
        {
            "location": "/integration/runtime_api/#generating-sql-statements",
            "text": "To generate SQL  INSERT  statements for your test data, call the  generateSQLStatements  method on your RedG object. It will return a List<String>  with each String being a complete SQL INSERT statement. The list is ordered so that no foreign key constraints are\nviolated, so preserve this order. When exporting the statements into an SQL file you have to append a semicolon to each statement.   Note  You might need to use a custom  SQL values formatter  for special data types.   Example code for export:  List < String >   list   =   redG . generateSQLStatements ();  String   sqlScript   =   sql . stream (). collect ( Collectors . joining ( \";\\n\" ));  // do whatever you want with sqlScript",
            "title": "Generating SQL statements"
        },
        {
            "location": "/customization/generator/type_mapping/",
            "text": "Custom type mapping\n\u00b6\n\n\nRedG allows you to customize the SQL to Java type mapping for the generated entity classes.\nWhen analysing a database schema, RedG always tries to find an appropriate Java datatype for a column. \nThere are three cases, where this might not be enough:\n\n\n\n\nYou want a different Java datatype that still represents the same database datatype (eg. \nlong\n instead of \nBigDecimal\n for \nNUMBER(10)\n)\n\n\nRedG cannot understand the semantic meaning of a column datatype (eg. \nNUMBER(1)\n or \nCHAR(1)\n for \nboolean\n)\n\n\nYou want to plug in a custom, maybe even far more complex, data type and use it instead of the default types\n\n\n\n\nIf this happens, you can create a custom type mapping. The following sections describe how to specify your custom mapping.\n\n\nJSON file\n\u00b6\n\n\nIf you want to specify your mapping in a JSON file, use the \nJsonFileDataTypeProvider\n. The \n\nMaven plugin\n has built-in support for JSON files.\n\n\nThe syntax for the JSON file is simple: You can specify \ntableMappings\n that specify the type for a column inside a table\nor you can use the \ndefaultMappings\n where you can assign a data type to be used for a specific SQL type. The \ntableMappings\n have a higher priority and can be \nused to override the \ndefaultMappings\n.\n\n\nFor the \ntableMappings\n: Each table gets an own object. The key for that object is the full table name \n(including the schema name). This object contains a key for each column you want to map. The key is the column name. \nThe value for each key is the wanted data type.\n\n\nFor the \ndefaultMappings\n: The key is the SQL data type (with or without precision information), the value is the Java type. SQL types with precision information\nalways take precedence over types without precision information. So when a column has the data type \nNUMBER(1)\n and the mappings contain both \nNUMBER -> Long\n and\n\nNUMBER(1) -> Boolean\n the column will be mapped to a \nBoolean\n type. When dealing with \nVARCHAR\ns or similar, you can also use \"precision\" (aka length) information,\nbut do not include \nCHAR\n inside the brackets (eg. if type is \nVARCHAR2(100 CHAR)\n, use \nVARCHAR2(100)\n to match this).\n\n\nExample:\n\n\n{\n\n  \n\"tableMappings\"\n:\n \n{\n\n    \n\"SCHEMA-NAME.TABLE-NAME\"\n:\n \n{\n\n      \n\"COLUMN-NAME\"\n:\n \n\"your.java.Datatype\"\n,\n\n      \n\"OTHER-COLUMN\"\n:\n \n\"other.Type\"\n\n    \n},\n\n    \n\"SCHEMA-NAME.OTHER-TABLE\"\n:\n \n{\n\n      \n\"ID-COLUMN\"\n:\n \n\"long\"\n\n    \n}\n\n  \n},\n\n  \n\"defaultMappings\"\n:\n \n{\n\n    \n\"NUMBER\"\n:\n \n\"java.lang.Long\"\n,\n\n    \n\"NUMBER(1)\"\n:\n \n\"java.lang.Boolean\"\n\n  \n}\n\n\n}\n\n\n\n\n\n\nXML file\n\u00b6\n\n\nIf you want to specify your type mapping with an XML file, use the \nXmlFileDataTypeProvider\n. The \n\nMaven plugin\n has built-in support for XML files. \n\n\nThe root element is \n<typeMappings>\n. This element has a child \n<tableTypeMappings>\n. Each table you want to\nspecify the types for gets a \n<table>\n element with a \nname\n attribute specifying the table name. \nEach table element has \n<column>\n child elements. These elements have a \nname\n attribute and their value is\nthe wanted data type.\n\n\nThe other allowed child element is \n<defaultTypeMappings>\n. It can have multiple \n<type>\n children with a \nsql\n attribute specifying the SQL data \ntype (with precision support just like for JSON). The value of this node is the Java type that the SQL type should be mapped to.\n\n\nExample:\n\n\n<typeMappings>\n\n   \n<tableTypeMappings>\n\n       \n<table\n \nname=\n\"TABLE_NAME\"\n>\n\n            \n<column\n \nname=\n\"COLUMN_NAME\"\n>\njava.lang.String\n</column>\n\n       \n</table>\n\n   \n</tableTypeMappings>\n\n   \n<defaultTypeMappings>\n\n       \n<type\n \nsql=\n\"DECIMAL(1)\"\n>\njava-lang.Boolean\n</type>\n\n   \n</defaultTypeMappings>\n\n\n</typeMappings>\n\n\n\n\n\n\nJava API\n\u00b6\n\n\nCustom implementations have to implement the \nDataTypeProvider\n interface. The method \ngetCanonicalDataTypeName\n gets\ncalled for each column in every table. The method has to return a fully qualified class name that should be used for\nthat column.\n\n\npublic\n \ninterface\n \nDataTypeProvider\n \n{\n\n    \nString\n \ngetCanonicalDataTypeName\n(\nColumn\n \ncolumn\n);\n\n\n}",
            "title": "Type mapping"
        },
        {
            "location": "/customization/generator/type_mapping/#custom-type-mapping",
            "text": "RedG allows you to customize the SQL to Java type mapping for the generated entity classes.\nWhen analysing a database schema, RedG always tries to find an appropriate Java datatype for a column. \nThere are three cases, where this might not be enough:   You want a different Java datatype that still represents the same database datatype (eg.  long  instead of  BigDecimal  for  NUMBER(10) )  RedG cannot understand the semantic meaning of a column datatype (eg.  NUMBER(1)  or  CHAR(1)  for  boolean )  You want to plug in a custom, maybe even far more complex, data type and use it instead of the default types   If this happens, you can create a custom type mapping. The following sections describe how to specify your custom mapping.",
            "title": "Custom type mapping"
        },
        {
            "location": "/customization/generator/type_mapping/#json-file",
            "text": "If you want to specify your mapping in a JSON file, use the  JsonFileDataTypeProvider . The  Maven plugin  has built-in support for JSON files.  The syntax for the JSON file is simple: You can specify  tableMappings  that specify the type for a column inside a table\nor you can use the  defaultMappings  where you can assign a data type to be used for a specific SQL type. The  tableMappings  have a higher priority and can be \nused to override the  defaultMappings .  For the  tableMappings : Each table gets an own object. The key for that object is the full table name \n(including the schema name). This object contains a key for each column you want to map. The key is the column name. \nThe value for each key is the wanted data type.  For the  defaultMappings : The key is the SQL data type (with or without precision information), the value is the Java type. SQL types with precision information\nalways take precedence over types without precision information. So when a column has the data type  NUMBER(1)  and the mappings contain both  NUMBER -> Long  and NUMBER(1) -> Boolean  the column will be mapped to a  Boolean  type. When dealing with  VARCHAR s or similar, you can also use \"precision\" (aka length) information,\nbut do not include  CHAR  inside the brackets (eg. if type is  VARCHAR2(100 CHAR) , use  VARCHAR2(100)  to match this).  Example:  { \n   \"tableMappings\" :   { \n     \"SCHEMA-NAME.TABLE-NAME\" :   { \n       \"COLUMN-NAME\" :   \"your.java.Datatype\" , \n       \"OTHER-COLUMN\" :   \"other.Type\" \n     }, \n     \"SCHEMA-NAME.OTHER-TABLE\" :   { \n       \"ID-COLUMN\" :   \"long\" \n     } \n   }, \n   \"defaultMappings\" :   { \n     \"NUMBER\" :   \"java.lang.Long\" , \n     \"NUMBER(1)\" :   \"java.lang.Boolean\" \n   }  }",
            "title": "JSON file"
        },
        {
            "location": "/customization/generator/type_mapping/#xml-file",
            "text": "If you want to specify your type mapping with an XML file, use the  XmlFileDataTypeProvider . The  Maven plugin  has built-in support for XML files.   The root element is  <typeMappings> . This element has a child  <tableTypeMappings> . Each table you want to\nspecify the types for gets a  <table>  element with a  name  attribute specifying the table name. \nEach table element has  <column>  child elements. These elements have a  name  attribute and their value is\nthe wanted data type.  The other allowed child element is  <defaultTypeMappings> . It can have multiple  <type>  children with a  sql  attribute specifying the SQL data \ntype (with precision support just like for JSON). The value of this node is the Java type that the SQL type should be mapped to.  Example:  <typeMappings> \n    <tableTypeMappings> \n        <table   name= \"TABLE_NAME\" > \n             <column   name= \"COLUMN_NAME\" > java.lang.String </column> \n        </table> \n    </tableTypeMappings> \n    <defaultTypeMappings> \n        <type   sql= \"DECIMAL(1)\" > java-lang.Boolean </type> \n    </defaultTypeMappings>  </typeMappings>",
            "title": "XML file"
        },
        {
            "location": "/customization/generator/type_mapping/#java-api",
            "text": "Custom implementations have to implement the  DataTypeProvider  interface. The method  getCanonicalDataTypeName  gets\ncalled for each column in every table. The method has to return a fully qualified class name that should be used for\nthat column.  public   interface   DataTypeProvider   { \n     String   getCanonicalDataTypeName ( Column   column );  }",
            "title": "Java API"
        },
        {
            "location": "/customization/generator/name_mapping/",
            "text": "Custom name mapping\n\u00b6\n\n\nThe custom name mapping allows you to change how RedG names the entity classes and their methods. In many cases and when using pretty default SQL names no\nintervention is needed here.\n\n\nThe default naming behaviour of RedG is described below:\n\n\n\n\n\n\n\n\nType\n\n\nBehaviour\n\n\nExample\n\n\n\n\n\n\n\n\n\n\nTables\n\n\nSplit by underscore into words. Make words lowercase with first letter uppercase and join them together, thus creating a uppercase camel-case name.\n\n\nDEMO_USER \u2192 DemoUser\n\n\n\n\n\n\nColumns\n\n\nSplit by underscore into words. Make words lowercase with first letter uppercase and join them together. First word starts lowercase, thus creating a lowercase camel-case name.\n\n\nFIRST_NAME \u2192 firstName\n\n\n\n\n\n\nForeign Key\n\n\nSplit by underscore into words. Remove \"FK\" and name of own table. Build lowercase camel-case name of remaining words.\n\n\nFK_USER_WORKS_AT_COMPANY \u2192 worksAtCompany\n\n\n\n\n\n\nIncoming Foreign Key\n\n\nName of the referencing table + \"sFor\" + Name for foreign key\n\n\n\n\n\n\n\n\n\n\nJSON file\n\u00b6\n\n\nUse the \nJsonFileNameProvider\n when specifying name mappings in a JSON file. The \nMaven plugin\n has built-in support for JSON\nfiles. Getting names for incoming foreign keys from JSON files is not supported yet and RedG will fall back to the \nDefaultNameProvider\n.\n\n\nSee below for the syntax of the JSON file:\n\n\n{\n\n  \n\"TABLE_NAME\"\n:\n \n{\n\n    \n\"name\"\n:\n \n\"TableClassName\"\n,\n\n    \n\"columns\"\n:\n \n{\n\n      \n\"COLUMN_1\"\n:\n \n\"myCustomNameCol1\"\n,\n\n      \n\"COLUMN_2\"\n:\n \n\"otherCustomName\"\n,\n\n      \n\"FK_SPECIAL_FOREIGN_KEY\"\n:\n \n\"customFkName\"\n\n    \n}\n\n  \n}\n\n\n}\n\n\n\n\n\n\nJava API\n\u00b6\n\n\nCustom implementations have to implement the \nNameProvider\n interface. If you only want to override behaviour for one type (table, column, foreign key), consider\nreturning \nnull\n for all methods you do not want to override and use a \nMultiProviderNameProvider\n.\n\n\npublic\n \ninterface\n \nNameProvider\n \n{\n\n\n    \nString\n \ngetClassNameForTable\n(\nTable\n \ntable\n);\n\n\n    \nString\n \ngetMethodNameForColumn\n(\nColumn\n \ncolumn\n);\n\n\n    \nString\n \ngetMethodNameForForeignKey\n(\nForeignKey\n \nforeignKey\n);\n\n\n    \nString\n \ngetMethodNameForIncomingForeignKey\n(\nForeignKey\n \nforeignKey\n);\n\n\n}",
            "title": "Name mapping"
        },
        {
            "location": "/customization/generator/name_mapping/#custom-name-mapping",
            "text": "The custom name mapping allows you to change how RedG names the entity classes and their methods. In many cases and when using pretty default SQL names no\nintervention is needed here.  The default naming behaviour of RedG is described below:     Type  Behaviour  Example      Tables  Split by underscore into words. Make words lowercase with first letter uppercase and join them together, thus creating a uppercase camel-case name.  DEMO_USER \u2192 DemoUser    Columns  Split by underscore into words. Make words lowercase with first letter uppercase and join them together. First word starts lowercase, thus creating a lowercase camel-case name.  FIRST_NAME \u2192 firstName    Foreign Key  Split by underscore into words. Remove \"FK\" and name of own table. Build lowercase camel-case name of remaining words.  FK_USER_WORKS_AT_COMPANY \u2192 worksAtCompany    Incoming Foreign Key  Name of the referencing table + \"sFor\" + Name for foreign key",
            "title": "Custom name mapping"
        },
        {
            "location": "/customization/generator/name_mapping/#json-file",
            "text": "Use the  JsonFileNameProvider  when specifying name mappings in a JSON file. The  Maven plugin  has built-in support for JSON\nfiles. Getting names for incoming foreign keys from JSON files is not supported yet and RedG will fall back to the  DefaultNameProvider .  See below for the syntax of the JSON file:  { \n   \"TABLE_NAME\" :   { \n     \"name\" :   \"TableClassName\" , \n     \"columns\" :   { \n       \"COLUMN_1\" :   \"myCustomNameCol1\" , \n       \"COLUMN_2\" :   \"otherCustomName\" , \n       \"FK_SPECIAL_FOREIGN_KEY\" :   \"customFkName\" \n     } \n   }  }",
            "title": "JSON file"
        },
        {
            "location": "/customization/generator/name_mapping/#java-api",
            "text": "Custom implementations have to implement the  NameProvider  interface. If you only want to override behaviour for one type (table, column, foreign key), consider\nreturning  null  for all methods you do not want to override and use a  MultiProviderNameProvider .  public   interface   NameProvider   { \n\n     String   getClassNameForTable ( Table   table ); \n\n     String   getMethodNameForColumn ( Column   column ); \n\n     String   getMethodNameForForeignKey ( ForeignKey   foreignKey ); \n\n     String   getMethodNameForIncomingForeignKey ( ForeignKey   foreignKey );  }",
            "title": "Java API"
        },
        {
            "location": "/customization/generator/explicit_attributes/",
            "text": "Explicit attributes & foreign keys\n\u00b6\n\n\nExplicit attributes and explicit foreign keys can be used to \"mark\" certain attributes / foreign keys as required. \n\n\nIf you mark a foreign key as explicit it is treated as a \nNOT\n \nNULL\n foreign key. This allows you to treat foreign keys that are meant to be \nNOT\n \nNULL\n \nbut are nullable for some reason (legacy schema, cyclic dependencies, whatever) as \nNOT\n \nNULL\n within RedG and make them required for entity creation.\n\n\nIf you mark an attribute as explicit, it gets treated like a \nNOT\n \nNULL\n foreign key. This means, that a value has to be set for this attribute at\nentity creation time and no default value will be used for this attribute. Use this feature sparingly, as using it everywhere defeats the purpose of\nRedGs default value system.\n\n\nJSON file\n\u00b6\n\n\nLoad your JSON files with the \nJsonFileExplicitAttributeDecider\n. \n\n\nThe structure of the JSON input can be found below. \n\n\n\n\nRegex support\n\n\nAll strings in this JSON file will be evaluated as regualr expressions and matched against the table / column / foreign key names. Remember to escape\ncertain characters with a backslash (\"\\\") if you want the literal character to match.\n\n\n\n\n{\n\n  \n\"TABLENAME\"\n:\n \n{\n\n    \n\"attributes\"\n:\n \n[\n\"ATTRIBUTE1\"\n,\n \n\"ATTRIBUTE2\"\n],\n\n    \n\"relations\"\n:\n \n[\n\n      \n[\n\"FOREIGN_KEY_1_COLUMN_1\"\n,\n \n\"COLUMN2\"\n],\n\n      \n[\n\"FOREIGN_KEY_2_PART_1\"\n,\n \n\"OTHER_PART2\"\n]\n\n    \n]\n\n  \n}\n\n\n}\n\n\n\n\n\n\nJava API\n\u00b6\n\n\nIf you want to roll your own implementation, simply implement \nExplicitAttributeDecider\n and decide for each column / attribute and foreign key whether it\n should be explicitly required or not.\n\n\npublic\n \ninterface\n \nExplicitAttributeDecider\n \n{\n\n\n    \nboolean\n \nisExplicitAttribute\n(\nColumn\n \ncolumn\n);\n\n\n    \nboolean\n \nisExplicitForeignKey\n(\nForeignKey\n \nforeignKey\n);\n\n\n\n}",
            "title": "Explicit attributes & foreign keys"
        },
        {
            "location": "/customization/generator/explicit_attributes/#explicit-attributes-foreign-keys",
            "text": "Explicit attributes and explicit foreign keys can be used to \"mark\" certain attributes / foreign keys as required.   If you mark a foreign key as explicit it is treated as a  NOT   NULL  foreign key. This allows you to treat foreign keys that are meant to be  NOT   NULL  \nbut are nullable for some reason (legacy schema, cyclic dependencies, whatever) as  NOT   NULL  within RedG and make them required for entity creation.  If you mark an attribute as explicit, it gets treated like a  NOT   NULL  foreign key. This means, that a value has to be set for this attribute at\nentity creation time and no default value will be used for this attribute. Use this feature sparingly, as using it everywhere defeats the purpose of\nRedGs default value system.",
            "title": "Explicit attributes &amp; foreign keys"
        },
        {
            "location": "/customization/generator/explicit_attributes/#json-file",
            "text": "Load your JSON files with the  JsonFileExplicitAttributeDecider .   The structure of the JSON input can be found below.    Regex support  All strings in this JSON file will be evaluated as regualr expressions and matched against the table / column / foreign key names. Remember to escape\ncertain characters with a backslash (\"\\\") if you want the literal character to match.   { \n   \"TABLENAME\" :   { \n     \"attributes\" :   [ \"ATTRIBUTE1\" ,   \"ATTRIBUTE2\" ], \n     \"relations\" :   [ \n       [ \"FOREIGN_KEY_1_COLUMN_1\" ,   \"COLUMN2\" ], \n       [ \"FOREIGN_KEY_2_PART_1\" ,   \"OTHER_PART2\" ] \n     ] \n   }  }",
            "title": "JSON file"
        },
        {
            "location": "/customization/generator/explicit_attributes/#java-api",
            "text": "If you want to roll your own implementation, simply implement  ExplicitAttributeDecider  and decide for each column / attribute and foreign key whether it\n should be explicitly required or not.  public   interface   ExplicitAttributeDecider   { \n\n     boolean   isExplicitAttribute ( Column   column ); \n\n     boolean   isExplicitForeignKey ( ForeignKey   foreignKey );  }",
            "title": "Java API"
        },
        {
            "location": "/customization/generator/convenience_setters/",
            "text": "Convenience setter methods\n\u00b6\n\n\nThis feature of RedG allows you to add convenience setters to the generated entity classes.\nFor example an entity with a \njava.sql.Timestamp\n field could get an extra setter for better date types \n(like \njava.time.LocalDatetime\n). All you have to provide is a conversion method that can convert from the convenient \ndata type to the needed type. This conversion method needs to be a public static method taking exactly two parameters:\n\n\n\n\nThe value for the attribute (as the convenient type)\n\n\nThe class (\nClass<?>\n) of the required type\n\n\n\n\nIt needs to return an instance of the class that was passed as a second parameter. Using generics, the method \nsignature for a conversion method that transforms a string into some kind of date could be \n\npublic\n \nstatic\n \n<\nT\n>\n \nT\n \nconvertToDate\n(\nString\n \ns\n,\n \nClass\n<\nT\n>\n \nclazz\n)\n.\n\n\nThe RedG runtime provides a converter that can convert a ISO-8601 formatted string into basically every Java date type\n(\njava.util.Date, java.sql.Date, Time, Timestamp, LocalTime, LocalDate, LocalDateTime, ZonedDateTime, OffsetDateTime, OffsetTime\n).\nTo use it, specify \ncom.btc.redg.runtime.util.DateConverter.convertDate\n as the fully qualified converter method name.\n\n\nXML file\n\u00b6\n\n\nUse the \nXmlFileConvenienceSetterProvider\n class to load your XML file.\n\n\nIn the XML you can specify multiple convenience setters for each original data type. The example XML specifies that every\nattribute of the type \njava.util.Date\n gets another setter accepting a \njava.lang.String\n and converting this string into a\ndate with the \ncom.btc.redg.runtime.util.DateConverter.convertDate\n method.\n\n\nIf you want to restrict the convenience setters to certain tables / columns, you have to provide a \n\ncustom implementation\n.\n\n\n<convenienceSetterConfig>\n\n   \n<javaType\n \nname=\n\"java.util.Date\"\n>\n\n       \n<convenienceSetter\n \nsetterJavaTypeName=\n\"java.lang.String\"\n \nfullyQualifiedConverterMethodName=\n\"com.btc.redg.runtime.util.DateConverter.convertDate\"\n/>\n\n   \n</javaType>\n\n\n</convenienceSetterConfig>\n\n\n\n\n\n\nJava API\n\u00b6\n\n\nYour custom implementation has to implement the \nConvenienceSetterProvider\n interface. You can then decide for each \ncolumn on every table what convenience setters should be added. If you do not want any convenience setters, return an \nempty list or fall back to a \nDefaultConvenienceSetterProvider\n. Please always use the \njavaDataTypeName\n parameter as\nthe required parameter type and not the type according to the \ncolumn\n, as your \ntype mapping\n might\nhave changed the type that the database analysis framework suggested.\n\n\npublic\n \ninterface\n \nConvenienceSetterProvider\n \n{\n\n\n    \nList\n<\nConvenienceSetterModel\n>\n \ngetConvenienceSetters\n(\nColumn\n \ncolumn\n,\n \nString\n \njavaDataTypeName\n);\n\n\n\n}",
            "title": "Convenience setter methods"
        },
        {
            "location": "/customization/generator/convenience_setters/#convenience-setter-methods",
            "text": "This feature of RedG allows you to add convenience setters to the generated entity classes.\nFor example an entity with a  java.sql.Timestamp  field could get an extra setter for better date types \n(like  java.time.LocalDatetime ). All you have to provide is a conversion method that can convert from the convenient \ndata type to the needed type. This conversion method needs to be a public static method taking exactly two parameters:   The value for the attribute (as the convenient type)  The class ( Class<?> ) of the required type   It needs to return an instance of the class that was passed as a second parameter. Using generics, the method \nsignature for a conversion method that transforms a string into some kind of date could be  public   static   < T >   T   convertToDate ( String   s ,   Class < T >   clazz ) .  The RedG runtime provides a converter that can convert a ISO-8601 formatted string into basically every Java date type\n( java.util.Date, java.sql.Date, Time, Timestamp, LocalTime, LocalDate, LocalDateTime, ZonedDateTime, OffsetDateTime, OffsetTime ).\nTo use it, specify  com.btc.redg.runtime.util.DateConverter.convertDate  as the fully qualified converter method name.",
            "title": "Convenience setter methods"
        },
        {
            "location": "/customization/generator/convenience_setters/#xml-file",
            "text": "Use the  XmlFileConvenienceSetterProvider  class to load your XML file.  In the XML you can specify multiple convenience setters for each original data type. The example XML specifies that every\nattribute of the type  java.util.Date  gets another setter accepting a  java.lang.String  and converting this string into a\ndate with the  com.btc.redg.runtime.util.DateConverter.convertDate  method.  If you want to restrict the convenience setters to certain tables / columns, you have to provide a  custom implementation .  <convenienceSetterConfig> \n    <javaType   name= \"java.util.Date\" > \n        <convenienceSetter   setterJavaTypeName= \"java.lang.String\"   fullyQualifiedConverterMethodName= \"com.btc.redg.runtime.util.DateConverter.convertDate\" /> \n    </javaType>  </convenienceSetterConfig>",
            "title": "XML file"
        },
        {
            "location": "/customization/generator/convenience_setters/#java-api",
            "text": "Your custom implementation has to implement the  ConvenienceSetterProvider  interface. You can then decide for each \ncolumn on every table what convenience setters should be added. If you do not want any convenience setters, return an \nempty list or fall back to a  DefaultConvenienceSetterProvider . Please always use the  javaDataTypeName  parameter as\nthe required parameter type and not the type according to the  column , as your  type mapping  might\nhave changed the type that the database analysis framework suggested.  public   interface   ConvenienceSetterProvider   { \n\n     List < ConvenienceSetterModel >   getConvenienceSetters ( Column   column ,   String   javaDataTypeName );  }",
            "title": "Java API"
        },
        {
            "location": "/customization/runtime/default_value_strategy/",
            "text": "Default value strategy\n\u00b6\n\n\nThe default value strategy is one of RedGs best features, and like most of RedG can be customized to fit your \nrequirements. Out-of-the-box RedG provides two default value strategies: The \nDefaultDefaultValueStrategy\n, a \nminimalistic strategy, and the \nPluggableDefaultValueStrategy\n, a plug-in system that can be extended by \neither provided or custom plug-ins.\n\n\nDefault default value strategy\n\u00b6\n\n\nRedG's default default value strategy supports the following data types and provides a fixed default value for them.\n\n\n\n\n\n\n\n\nData type\n\n\nDefault value\n\n\n\n\n\n\n\n\n\n\nString\n\n\n\"-\"\n (Oracle does not support empty Strings and treats them as \nNULL\n)\n\n\n\n\n\n\nchar\n / \nCharacter\n\n\n' '\n (whitespace character)\n\n\n\n\n\n\nboolean\n / \nboolean\n\n\nfalse\n\n\n\n\n\n\neverything extending \nNumber\n / primitive number types\n\n\n0\n\n\n\n\n\n\neverything extending \njava.util.Date\n\n\n0\n (= \n01.01.1970\n)\n\n\n\n\n\n\nJava 8 date types\n\n\n1970-01-01T00:00:00.000Z\n\n\n\n\n\n\n\n\nIf a column is a primary key or has a unique constraint, a value that is unique to that column \n(but may be the same as in other unique columns) is generated.\n\n\n\n\n\n\n\n\nData type\n\n\nUnique default value\n\n\nMax number of unique values\n\n\n\n\n\n\n\n\n\n\nString\n\n\n\"A\"\n, \n\"B\"\n, ..., \n\"Z\"\n, \n\"AA\"\n, \n\"AB\"\n ...\n\n\n2^64\n\n\n\n\n\n\nchar\n / \nCharacter\n\n\nUnicode Character starting with \n\\u0001\n up until \n\\uffff\n\n\n(2^16)-1 = 65,535\n\n\n\n\n\n\nboolean\n / \nboolean\n\n\nfalse\n, then \ntrue\n\n\n2\n\n\n\n\n\n\neverything extending \nNumber\n / primitive number types\n\n\n0\n, \n1\n, \n2\n, ...\n\n\n2^64\n\n\n\n\n\n\neverything extending \njava.util.Date\n\n\nCounting up milliseconds since unix epoch, starting at \n0\n\n\nuntil year 8099\n\n\n\n\n\n\nJava 8 date types\n\n\nCounting up milliseconds since unix epoch, starting at \n0\n\n\nuntil year 8099\n\n\n\n\n\n\n\n\nPluggable default value strategy\n\u00b6\n\n\nThe \nPluggableDefaultValueStrategy\n has a list of \nPluggableDefaultValueProvider\ns. When a default value needs to be\ngenerated, it checks whether a provider can provide a default value for the required data type / table / column. \nThe values from all eligible providers are then collected and the first not-null value is returned as the default value.\nIf no eligible provider is found or all return \nnull\n, \nnull\n gets returned. Even if the column is nullable \n(\nnotNull == false\n), a not-null value is preferred.\n\n\nThe following providers are bundles with RedG:\n\n\n\n\n\n\n\n\nClass name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nConstantStringProvider\n\n\nProvides a constant String which can be set by the user.\n\n\n\n\n\n\nConstantValueProvider\n\n\nProvides a constant value for a certain data type. Returns the value if \nvalue.getClass()\n equals the exact required type.\n\n\n\n\n\n\nStaticNumberProvider\n\n\nProvides a static number.\n\n\n\n\n\n\nIncrementingNumberProvider\n\n\nProvides an incrementing number. The start value can be specified. The counter is incremented for each column separately. Ideal for index columns.\n\n\n\n\n\n\nStaticDateProvider\n\n\nTakes a \njava.util.Date\n as a parameter and returns it for \nevery\n java date type.\n\n\n\n\n\n\nCurrentDateProvider\n\n\nReturns the current date / time for \nevery\n java date type.\n\n\n\n\n\n\nConditionalProvider\n\n\nEncapsulates another provider and will only return its value if the regular expressions for table & column name match.\n\n\n\n\n\n\nCustomConditionalProvider\n\n\nA conditional provider that is even more flexible that the \nConditionalProvider\n. Is used by the builder system.\n\n\n\n\n\n\nDefaultDefaultValueProvider\n\n\nA provider encapsulating the \nDefaultDefaultValueStrategy\n. Use for fallback purposes.\n\n\n\n\n\n\n\n\nYou can use the \nPluggableDefaultValueStrategy.Builder()\n class to easily build a highly customized system:\n\n\nPluggableDefaultValueStrategy\n \nstrategy\n \n=\n \nnew\n \nPluggableDefaultValueStrategy\n.\nBuilder\n()\n\n    \n.\nuse\n(\nnew\n \nIncrementingNumberProvider\n()).\nwhen\n(\ncolumnName\n(\ncontains\n(\n\"_ID\"\n)))\n\n    \n.\nuse\n(\nnew\n \nStaticNumberProvider\n(\n42\n))\n\n    \n.\nuseDefault\n()\n \n// shortcut for a DefaultDefaultValueProvider, perfect as fallback\n\n    \n.\nbuild\n();\n\n\n\n\n\n\nTake a look at the Javadoc for \ncom.btc.redg.runtime.defaultvalues.pluggable.buildermatchers.Matchers\n and \n\ncom.btc.redg.runtime.defaultvalues.pluggable.buildermatchers.Conditions\n for all available conditions to use in the \n.when()\n part. As the \n.when()\n method \nexpects a \nPredicate<ColumnModel>\n, you can easily implement a custom system.\n\n\nCustom provider implementation\n\u00b6\n\n\nImplementing a custom provider is easy. Simply implement the \nPluggableDefaultValueProvider\n interface and implement\nboth the \ngetDefaultValue\n and \nwillProvide\n method. The \nwillProvide\n method should return \ntrue\n if \ngetDefaultValue\n\ncan and should produce a default value for the current column and data type.\n\n\nCustom implementation\n\u00b6\n\n\nCustom default value strategies have to implement the \nDefaultValueStrategy\n interface.\n\n\nIf \nnotNull\n is \ntrue\n and \nnull\n is returned, RedG will fail. RedG does not perform further checks on the value\ngenerated by this method. You have full control and responsibility.\n\n\npublic\n \ninterface\n \nDefaultValueStrategy\n \n{\n\n    \n<\nT\n>\n \nT\n \ngetDefaultValue\n(\nColumnModel\n \ncolumnModel\n,\n \nClass\n<\nT\n>\n \ntype\n);\n\n\n}",
            "title": "Default value strategy"
        },
        {
            "location": "/customization/runtime/default_value_strategy/#default-value-strategy",
            "text": "The default value strategy is one of RedGs best features, and like most of RedG can be customized to fit your \nrequirements. Out-of-the-box RedG provides two default value strategies: The  DefaultDefaultValueStrategy , a \nminimalistic strategy, and the  PluggableDefaultValueStrategy , a plug-in system that can be extended by \neither provided or custom plug-ins.",
            "title": "Default value strategy"
        },
        {
            "location": "/customization/runtime/default_value_strategy/#default-default-value-strategy",
            "text": "RedG's default default value strategy supports the following data types and provides a fixed default value for them.     Data type  Default value      String  \"-\"  (Oracle does not support empty Strings and treats them as  NULL )    char  /  Character  ' '  (whitespace character)    boolean  /  boolean  false    everything extending  Number  / primitive number types  0    everything extending  java.util.Date  0  (=  01.01.1970 )    Java 8 date types  1970-01-01T00:00:00.000Z     If a column is a primary key or has a unique constraint, a value that is unique to that column \n(but may be the same as in other unique columns) is generated.     Data type  Unique default value  Max number of unique values      String  \"A\" ,  \"B\" , ...,  \"Z\" ,  \"AA\" ,  \"AB\"  ...  2^64    char  /  Character  Unicode Character starting with  \\u0001  up until  \\uffff  (2^16)-1 = 65,535    boolean  /  boolean  false , then  true  2    everything extending  Number  / primitive number types  0 ,  1 ,  2 , ...  2^64    everything extending  java.util.Date  Counting up milliseconds since unix epoch, starting at  0  until year 8099    Java 8 date types  Counting up milliseconds since unix epoch, starting at  0  until year 8099",
            "title": "Default default value strategy"
        },
        {
            "location": "/customization/runtime/default_value_strategy/#pluggable-default-value-strategy",
            "text": "The  PluggableDefaultValueStrategy  has a list of  PluggableDefaultValueProvider s. When a default value needs to be\ngenerated, it checks whether a provider can provide a default value for the required data type / table / column. \nThe values from all eligible providers are then collected and the first not-null value is returned as the default value.\nIf no eligible provider is found or all return  null ,  null  gets returned. Even if the column is nullable \n( notNull == false ), a not-null value is preferred.  The following providers are bundles with RedG:     Class name  Description      ConstantStringProvider  Provides a constant String which can be set by the user.    ConstantValueProvider  Provides a constant value for a certain data type. Returns the value if  value.getClass()  equals the exact required type.    StaticNumberProvider  Provides a static number.    IncrementingNumberProvider  Provides an incrementing number. The start value can be specified. The counter is incremented for each column separately. Ideal for index columns.    StaticDateProvider  Takes a  java.util.Date  as a parameter and returns it for  every  java date type.    CurrentDateProvider  Returns the current date / time for  every  java date type.    ConditionalProvider  Encapsulates another provider and will only return its value if the regular expressions for table & column name match.    CustomConditionalProvider  A conditional provider that is even more flexible that the  ConditionalProvider . Is used by the builder system.    DefaultDefaultValueProvider  A provider encapsulating the  DefaultDefaultValueStrategy . Use for fallback purposes.     You can use the  PluggableDefaultValueStrategy.Builder()  class to easily build a highly customized system:  PluggableDefaultValueStrategy   strategy   =   new   PluggableDefaultValueStrategy . Builder () \n     . use ( new   IncrementingNumberProvider ()). when ( columnName ( contains ( \"_ID\" ))) \n     . use ( new   StaticNumberProvider ( 42 )) \n     . useDefault ()   // shortcut for a DefaultDefaultValueProvider, perfect as fallback \n     . build ();   Take a look at the Javadoc for  com.btc.redg.runtime.defaultvalues.pluggable.buildermatchers.Matchers  and  com.btc.redg.runtime.defaultvalues.pluggable.buildermatchers.Conditions  for all available conditions to use in the  .when()  part. As the  .when()  method \nexpects a  Predicate<ColumnModel> , you can easily implement a custom system.",
            "title": "Pluggable default value strategy"
        },
        {
            "location": "/customization/runtime/default_value_strategy/#custom-provider-implementation",
            "text": "Implementing a custom provider is easy. Simply implement the  PluggableDefaultValueProvider  interface and implement\nboth the  getDefaultValue  and  willProvide  method. The  willProvide  method should return  true  if  getDefaultValue \ncan and should produce a default value for the current column and data type.",
            "title": "Custom provider implementation"
        },
        {
            "location": "/customization/runtime/default_value_strategy/#custom-implementation",
            "text": "Custom default value strategies have to implement the  DefaultValueStrategy  interface.  If  notNull  is  true  and  null  is returned, RedG will fail. RedG does not perform further checks on the value\ngenerated by this method. You have full control and responsibility.  public   interface   DefaultValueStrategy   { \n     < T >   T   getDefaultValue ( ColumnModel   columnModel ,   Class < T >   type );  }",
            "title": "Custom implementation"
        },
        {
            "location": "/customization/runtime/sql_values_formatter/",
            "text": "SQL values formatter\n\u00b6\n\n\nThe SQL values formatter defines how attribute / column values have to be represented in the SQL \nINSERT\n string\ngenerated by RedG. RedG offers a default formatter \nDefaultSQLValuesFormatter\n that can turn the most common data \ntypes into valid SQL. If you are using uncommon or custom data types, you have to provide your own implementation.\n\n\n\n\nNote\n\n\nIf you are not generating SQL \nINSERT\n statements with the \ngenerateSQLStatements()\n method, you can ignore\nthe SQL values formatter and take a look at the \n\nPreparedStatement parameter setter\n\n\n\n\nDefault SQL values formatter\n\u00b6\n\n\nThe default formatter provided by RedG formats the input like described in the following table. (Empty fields in the \ntype columns mean that RedG does not check that type)\n\n\n\n\n\n\n\n\nSQL type\n\n\nJava type\n\n\nFormatting\n\n\n\n\n\n\n\n\n\n\nVARCHAR\n &\nVARCHAR2\n\n\n\n\ntoString()\n gets called on value and single quotation marks get escaped. Escaped string gets wrapped in single quotation marks.\n\n\n\n\n\n\nDECIMAL\n & \nNUMBER\n\n\nBoolean\n\n\n1\n for \ntrue\n, \n0\n for false.\n\n\n\n\n\n\nDECIMAL\n & \nNUMBER\n\n\n\n\ntoString()\n gets called on value. This works for numbers, as they all implement a correct toString() method. No precision checks are performed.\n\n\n\n\n\n\n\n\njava.util.Date\n\n\nA timestamp gets constructed from the unix timestamp and inserted as a string using the \nTO_TIMESTAMP(string, format)\n SQL function.\n\n\n\n\n\n\n\n\nTemporalAccessor\n\n\nThe temporal value gets formatted and inserted as a string using the \nTO_TIMESTAMP(string, format)\n SQL function.\n\n\n\n\n\n\n\n\nJava API\n\u00b6\n\n\nIf you need your own formatter, simply implement the \nSQLValuesFormatter\n interface. The \nformatValues\n method gets called\nfor every value that has to be formatted (so every attribute in every entity).\n\n\npublic\n \ninterface\n \nSQLValuesFormatter\n \n{\n\n\n    \n<\nT\n>\n \nString\n \nformatValue\n(\nT\n \nvalue\n,\n \nString\n \nsqlDataType\n,\n \nString\n \nfullTableName\n,\n \nString\n \ntableName\n,\n \nString\n \ncolumnName\n);\n\n\n}",
            "title": "SQL values formatter"
        },
        {
            "location": "/customization/runtime/sql_values_formatter/#sql-values-formatter",
            "text": "The SQL values formatter defines how attribute / column values have to be represented in the SQL  INSERT  string\ngenerated by RedG. RedG offers a default formatter  DefaultSQLValuesFormatter  that can turn the most common data \ntypes into valid SQL. If you are using uncommon or custom data types, you have to provide your own implementation.   Note  If you are not generating SQL  INSERT  statements with the  generateSQLStatements()  method, you can ignore\nthe SQL values formatter and take a look at the  PreparedStatement parameter setter",
            "title": "SQL values formatter"
        },
        {
            "location": "/customization/runtime/sql_values_formatter/#default-sql-values-formatter",
            "text": "The default formatter provided by RedG formats the input like described in the following table. (Empty fields in the \ntype columns mean that RedG does not check that type)     SQL type  Java type  Formatting      VARCHAR  & VARCHAR2   toString()  gets called on value and single quotation marks get escaped. Escaped string gets wrapped in single quotation marks.    DECIMAL  &  NUMBER  Boolean  1  for  true ,  0  for false.    DECIMAL  &  NUMBER   toString()  gets called on value. This works for numbers, as they all implement a correct toString() method. No precision checks are performed.     java.util.Date  A timestamp gets constructed from the unix timestamp and inserted as a string using the  TO_TIMESTAMP(string, format)  SQL function.     TemporalAccessor  The temporal value gets formatted and inserted as a string using the  TO_TIMESTAMP(string, format)  SQL function.",
            "title": "Default SQL values formatter"
        },
        {
            "location": "/customization/runtime/sql_values_formatter/#java-api",
            "text": "If you need your own formatter, simply implement the  SQLValuesFormatter  interface. The  formatValues  method gets called\nfor every value that has to be formatted (so every attribute in every entity).  public   interface   SQLValuesFormatter   { \n\n     < T >   String   formatValue ( T   value ,   String   sqlDataType ,   String   fullTableName ,   String   tableName ,   String   columnName );  }",
            "title": "Java API"
        },
        {
            "location": "/customization/runtime/prepared_statement_parameter_setter/",
            "text": "PreparedStatement parameter setter\n\u00b6\n\n\nThe PreparedStatement parameter setter is used by RedG set the column values for the \nPreparedStatement\n. It can be used\nto convert a custom data type into a type the JDBC driver can understand.\n\n\n\n\nNote\n\n\nIf you are not using PreparedStatements with the \ninsertDataIntoDatabase()\n method, you can ignore\nthe PreparedStatement parameter setter and take a look at the \n\nSQL values formatter\n\n\n\n\nDefault PreparedStatement parameter setter\n\u00b6\n\n\nThe \nDefaultPreparedStatementSetter\n only calls \ntoString()\n on the value if the JDBC type is one of \n\nTypes.CHAR, Types.VARCHAR, Types.LONGNVARCHAR\n. Every other value is passed to the statement without modification.\n\n\nThis works for most standard java types and depending on your JDBC driver it might even work for the new Java time \ntypes. Consult the documentation of your JDBC driver for more information on supported types.\n\n\nJava API\n\u00b6\n\n\nIf you need to implement your own setter, implement the \nPreparedStatementParameterSetter\n interface.\n\n\nInside of this method you should transform the object if needed. The \nAttributeMetaInfo\n provide you with metadata about\nthe object you are processing. After transforming the object, set it as the parameter on the passed \nstatement\n.\n\n\n\n\nCaution\n\n\nOnly call \nstatement.set...()\n with the index parameter specified in \nparameterIndex\n. RedG performs no further checks\nwhether you actually set the right parameter (or any at all).\n\n\n\n\n@FunctionalInterface\n\n\npublic\n \ninterface\n \nPreparedStatementParameterSetter\n \n{\n\n\n    \nvoid\n \nsetParameter\n(\nPreparedStatement\n \nstatement\n,\n \nint\n \nparameterIndex\n,\n \nObject\n \nobject\n,\n \nAttributeMetaInfo\n \nattributeMetaInfo\n,\n \nfinal\n \nConnection\n \nconnection\n)\n \nthrows\n \nSQLException\n;\n\n\n}",
            "title": "PreparedStatement parameter setter"
        },
        {
            "location": "/customization/runtime/prepared_statement_parameter_setter/#preparedstatement-parameter-setter",
            "text": "The PreparedStatement parameter setter is used by RedG set the column values for the  PreparedStatement . It can be used\nto convert a custom data type into a type the JDBC driver can understand.   Note  If you are not using PreparedStatements with the  insertDataIntoDatabase()  method, you can ignore\nthe PreparedStatement parameter setter and take a look at the  SQL values formatter",
            "title": "PreparedStatement parameter setter"
        },
        {
            "location": "/customization/runtime/prepared_statement_parameter_setter/#default-preparedstatement-parameter-setter",
            "text": "The  DefaultPreparedStatementSetter  only calls  toString()  on the value if the JDBC type is one of  Types.CHAR, Types.VARCHAR, Types.LONGNVARCHAR . Every other value is passed to the statement without modification.  This works for most standard java types and depending on your JDBC driver it might even work for the new Java time \ntypes. Consult the documentation of your JDBC driver for more information on supported types.",
            "title": "Default PreparedStatement parameter setter"
        },
        {
            "location": "/customization/runtime/prepared_statement_parameter_setter/#java-api",
            "text": "If you need to implement your own setter, implement the  PreparedStatementParameterSetter  interface.  Inside of this method you should transform the object if needed. The  AttributeMetaInfo  provide you with metadata about\nthe object you are processing. After transforming the object, set it as the parameter on the passed  statement .   Caution  Only call  statement.set...()  with the index parameter specified in  parameterIndex . RedG performs no further checks\nwhether you actually set the right parameter (or any at all).   @FunctionalInterface  public   interface   PreparedStatementParameterSetter   { \n\n     void   setParameter ( PreparedStatement   statement ,   int   parameterIndex ,   Object   object ,   AttributeMetaInfo   attributeMetaInfo ,   final   Connection   connection )   throws   SQLException ;  }",
            "title": "Java API"
        },
        {
            "location": "/customization/runtime/dummy_factory/",
            "text": "Dummy factory\n\u00b6\n\n\nThis section describes how to modify the default behaviour of RedG's dummy data generation mechanism. For an explanation \nand a guide on how to use this mechanism, check \nthis\n out.\n\n\nThere are two main reasons to modify or extend the existing dummy generation system:\n\n\n\n\nYou want to modify the generated dummy entities\n\n\nRedG cannot generate the dummy entities for some reason\n\n\n\n\nIf the latter occurs, feel free to open an \nissue\n and we might try to \nimplement support for your case.\n\n\nImplement own DummyFactory\n\u00b6\n\n\nIf you need to, you can always implement your own \nDummyFactory\n. Here are a few tips when implementing your custom factory:\n\n\n\n\nRemember to take care of all transitive dependencies.\n\n\nAbstain from using user-generated entities already within RedG as dummies. Dummies should be entities your factory generated.\n\n\nImplement \nisDummy\n correctly, or features like the visualization will not work properly.\n\n\n\n\npublic\n \ninterface\n \nDummyFactory\n \n{\n\n\n    \n<\nT\n \nextends\n \nRedGEntity\n>\n \nT\n \ngetDummy\n(\nAbstractRedG\n \nredG\n,\n \nClass\n<\nT\n>\n \ndummyClass\n);\n\n\n    \nboolean\n \nisDummy\n(\nRedGEntity\n \nentity\n);\n\n\n}",
            "title": "Dummy factory"
        },
        {
            "location": "/customization/runtime/dummy_factory/#dummy-factory",
            "text": "This section describes how to modify the default behaviour of RedG's dummy data generation mechanism. For an explanation \nand a guide on how to use this mechanism, check  this  out.  There are two main reasons to modify or extend the existing dummy generation system:   You want to modify the generated dummy entities  RedG cannot generate the dummy entities for some reason   If the latter occurs, feel free to open an  issue  and we might try to \nimplement support for your case.",
            "title": "Dummy factory"
        },
        {
            "location": "/customization/runtime/dummy_factory/#implement-own-dummyfactory",
            "text": "If you need to, you can always implement your own  DummyFactory . Here are a few tips when implementing your custom factory:   Remember to take care of all transitive dependencies.  Abstain from using user-generated entities already within RedG as dummies. Dummies should be entities your factory generated.  Implement  isDummy  correctly, or features like the visualization will not work properly.   public   interface   DummyFactory   { \n\n     < T   extends   RedGEntity >   T   getDummy ( AbstractRedG   redG ,   Class < T >   dummyClass ); \n\n     boolean   isDummy ( RedGEntity   entity );  }",
            "title": "Implement own DummyFactory"
        },
        {
            "location": "/compatibility/",
            "text": "Compatibility\n\u00b6\n\n\nRedG is able to work with the most common database systems. All you need is a JDBC driver.\nThe Code Generator internally uses \nSchemaCrawler\n which supports a \n\nwide range of database systems\n. You'll probably need an extra \nSchemaCrawler plugin, so consult the table below or see \nMaven Central\n for a full list.\n\n\n\n\n\n\n\n\nDBMS\n\n\nNecessary extra dependency\n\n\nExample project\n\n\n\n\n\n\n\n\n\n\nH2\n\n\nDependency included in RedG\n\n\nredg-examples/redg-example-h2\n\n\n\n\n\n\nOracle\n\n\nus.fatehi:schemacrawler-oracle:14.16.01\n\n\nredg-examples/redg-example-oracle\n\n\n\n\n\n\nIBM DB2\n\n\nus.fatehi:schemacrawler-db2:14.16.01\n\n\nNo example, support untested\n\n\n\n\n\n\nMS SQL Server\n\n\nus.fatehi:schemacrawler-sqlserver:14.16.01\n\n\nNo example, support untested\n\n\n\n\n\n\nMySQL\n\n\nus.fatehi:schemacrawler-mysql:14.16.01\n\n\nredg-examples/redg-example-mysql\n\n\n\n\n\n\nMariaDB\n\n\nus.fatehi:schemacrawler-mariadb:14.16.01\n\n\nNo example, untested, probably like MySQL\n\n\n\n\n\n\nPostgreSQL\n\n\nus.fatehi:schemacrawler-postgresql:14.16.01\n\n\nredg-examples/redg-example-postgres\n\n\n\n\n\n\nSybase IQ\n\n\nus.fatehi:schemacrawler-sybaseiq:14.16.01\n\n\nNo example, support untested\n\n\n\n\n\n\n\n\nAfter the code is generated, it can be used to insert data into basically every DBMS with proper SQL support. When you insert the data directly\nwith JDBC, the driver needs proper support for \nsetObject\n, when generating SQL statements you might have to implement your own \nInsertValuesFormatter\n,\nso RedG uses the correct functions for e.g. string to date conversion.\n\n\nIf you run into issues with a certain DBMS or just want to tell us that it works, feel free to open an issue or contact us.",
            "title": "Compatibility"
        },
        {
            "location": "/compatibility/#compatibility",
            "text": "RedG is able to work with the most common database systems. All you need is a JDBC driver.\nThe Code Generator internally uses  SchemaCrawler  which supports a  wide range of database systems . You'll probably need an extra \nSchemaCrawler plugin, so consult the table below or see  Maven Central  for a full list.     DBMS  Necessary extra dependency  Example project      H2  Dependency included in RedG  redg-examples/redg-example-h2    Oracle  us.fatehi:schemacrawler-oracle:14.16.01  redg-examples/redg-example-oracle    IBM DB2  us.fatehi:schemacrawler-db2:14.16.01  No example, support untested    MS SQL Server  us.fatehi:schemacrawler-sqlserver:14.16.01  No example, support untested    MySQL  us.fatehi:schemacrawler-mysql:14.16.01  redg-examples/redg-example-mysql    MariaDB  us.fatehi:schemacrawler-mariadb:14.16.01  No example, untested, probably like MySQL    PostgreSQL  us.fatehi:schemacrawler-postgresql:14.16.01  redg-examples/redg-example-postgres    Sybase IQ  us.fatehi:schemacrawler-sybaseiq:14.16.01  No example, support untested     After the code is generated, it can be used to insert data into basically every DBMS with proper SQL support. When you insert the data directly\nwith JDBC, the driver needs proper support for  setObject , when generating SQL statements you might have to implement your own  InsertValuesFormatter ,\nso RedG uses the correct functions for e.g. string to date conversion.  If you run into issues with a certain DBMS or just want to tell us that it works, feel free to open an issue or contact us.",
            "title": "Compatibility"
        },
        {
            "location": "/about/license/",
            "text": "License\n\u00b6\n\n\nThis page provides a quick overview of the different open source licenses used by the RedG projects.\n\n\n\n\nNote\n\n\nThis is only an overview. For detailed information, check out the \nLICENSE\n (or \nLICENSE.txt\n) file in the code repositories.\n\n\n\n\nRedG library\n\u00b6\n\n\nThe main RedG library is available under the \nApache 2.0 License\n.\n\n\nRedG visualizer\n\u00b6\n\n\nThe RedG visualizer tool is available under the \nApache 2.0 License\n.\n\n\nRedG documentation\n\u00b6\n\n\n\n\nUnless stated otherwise, this whole documentation is licensed under a \n\nCreative Commons Attribution-ShareAlike 4.0 International License",
            "title": "License"
        },
        {
            "location": "/about/license/#license",
            "text": "This page provides a quick overview of the different open source licenses used by the RedG projects.   Note  This is only an overview. For detailed information, check out the  LICENSE  (or  LICENSE.txt ) file in the code repositories.",
            "title": "License"
        },
        {
            "location": "/about/license/#redg-library",
            "text": "The main RedG library is available under the  Apache 2.0 License .",
            "title": "RedG library"
        },
        {
            "location": "/about/license/#redg-visualizer",
            "text": "The RedG visualizer tool is available under the  Apache 2.0 License .",
            "title": "RedG visualizer"
        },
        {
            "location": "/about/license/#redg-documentation",
            "text": "Unless stated otherwise, this whole documentation is licensed under a  Creative Commons Attribution-ShareAlike 4.0 International License",
            "title": "RedG documentation"
        }
    ]
}